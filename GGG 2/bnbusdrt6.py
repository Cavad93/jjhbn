# -*- coding: utf-8 -*-
"""
Live paper-trading –¥–ª—è PancakeSwap Prediction (BNB):
- –†–µ–∞–ª—å–Ω—ã–µ rounds/—Ç–∞–π–º–∏–Ω–≥–∏ —Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ Prediction V2 (BSC mainnet)
- –¶–µ–Ω—ã/–æ–±—ä—ë–º—ã: Binance Spot /api/v3/klines (–±–µ–∑ –∫–ª—é—á–µ–π)
- –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: —Ñ–∏—á–∏ (Momentum/VWAP/Keltner/Bollinger/ATR-chop + Vol Z) -> softmax + EMA/Super Smoother
- NN-–∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä: –æ–Ω–ª–∞–π–Ω –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (–æ–±—É—á–∞–µ–º –ø–æ —Ñ–∞–∫—Ç—É –∏—Å—Ö–æ–¥–∞)

- +++ ML-–ê–ù–°–ê–ú–ë–õ–¨:
    –ß–µ—Ç—ã—Ä–µ ¬´—ç–∫—Å–ø–µ—Ä—Ç–∞¬ª –≤—ã–¥–∞—é—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å UP –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º—É –≤–µ–∫—Ç–æ—Ä—É —Ñ–∏—á (—Å–º. ExtendedMLFeatures):
      1) XGBoost (+ ADWIN-–≥–µ–π—Ç–∏–Ω–≥).
      2) RandomForest + CalibratedClassifierCV (sigmoid), –±–∞—Ç—á-–¥–æ–æ–±—É—á–µ–Ω–∏–µ + ADWIN-–≥–µ–π—Ç–∏–Ω–≥.
      3) River Adaptive Random Forest (–æ–Ω–ª–∞–π–Ω) + ADWIN-–≥–µ–π—Ç–∏–Ω–≥.
      4) NNExpert ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è MLP (1 —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π, tanh + sigmoid), –±–∞—Ç—á-–¥–æ–æ–±—É—á–µ–Ω–∏–µ, –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π + ADWIN-–≥–µ–π—Ç–∏–Ω–≥.
    –ù–∞–¥ –Ω–∏–º–∏ ‚Äî –ú–ï–¢–ê-–æ—Ü–µ–Ω—â–∏–∫: –æ–Ω–ª–∞–π–Ω –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–æ –ª–æ–≥–∏—Ç–∞–º [p_xgb,p_rf,p_arf,p_nn,p_base] + –¥–æ–ø. —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.

    –†–µ–∂–∏–º—ã:
      * SHADOW: –≤—Å–µ —É—á–∞—Ç—Å—è/–º–æ–Ω–∏—Ç–æ—Ä—è—Ç—Å—è, –Ω–æ –≤ —Å—Ç–∞–≤–∫–∞—Ö –ù–ï —É—á–∞—Å—Ç–≤—É—é—Ç.
      * ACTIVE: –≤ —Å—Ç–∞–≤–∫–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¢–û–õ–¨–ö–û p_final –æ—Ç –º–µ—Ç–∞-–æ—Ü–µ–Ω—â–∏–∫–∞ (–±–µ–∑ —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Å –±–∞–∑–æ–π).
    –ü–µ—Ä—Å–∏—Å—Ç: –º–æ–¥–µ–ª–∏/—Å–æ—Å—Ç–æ—è–Ω–∏—è/—Å–∫–µ–π–ª–µ—Ä—ã/–≤–µ—Å–∞.

- –ú–µ–Ω–µ–¥–∂–º–µ–Ω—Ç: —Å—Ç–∞—Ä—Ç 2 BNB, —Å—Ç–∞–≤–∫–∞:
    * –ø–µ—Ä–≤—ã–µ 500 —Å–¥–µ–ª–æ–∫ ‚Äî —Ñ–∏–∫—Å. 1% –∫–∞–ø–∏—Ç–∞–ª–∞;
    * –¥–∞–ª–µ–µ ‚Äî 1/2 Kelly, –Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ 0.5%..3% –∏ –∫—ç–ø –Ω–∞ —Ä–∞—É–Ω–¥ ‚â§3% –∫–∞–ø–∏—Ç–∞–ª–∞.
- –ì–∞–∑/—É—á—ë—Ç/—Ç–µ–ª–µ–≥–∞/EV-–≥–µ–π—Ç: –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
- EV-–ø–æ—Ä–æ–≥ p_thr:
    * p_thr = 0.51, –ø–æ–∫–∞ –Ω–µ—Ç 500 –∑–∞–∫—Ä—ã—Ç—ã—Ö —Å–¥–µ–ª–æ–∫ –ò–õ–ò –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π –∑–∞–∫—Ä—ã—Ç–æ–π —Å–¥–µ–ª–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å;
    * –∏–Ω–∞—á–µ ‚Äî –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π EV-–ø–æ—Ä–æ–≥ —Å —É—á—ë—Ç–æ–º –≥–∞–∑–∞ –∏ payout.

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ –ø–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º:
- xgboost ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (—ç–∫—Å–ø–µ—Ä—Ç XGB).
- scikit-learn ‚Äî –¥–ª—è RandomForest + –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ (—ç–∫—Å–ø–µ—Ä—Ç RF) –∏ StandardScaler.
- river ‚Äî –¥–ª—è ADWIN –∏ ARF (—ç–∫—Å–ø–µ—Ä—Ç ARF –∏ –≥–µ–π—Ç–∏–Ω–≥).
–ï—Å–ª–∏ –ª–∏–±—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç ‚Äî —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç/–≥–µ–π—Ç–∏–Ω–≥ –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç.
"""

import os
import csv
import math
import time
import json
import pickle
import numpy as np
import pandas as pd
from web3 import Web3, HTTPProvider     # ‚Üê –ü–ï–†–ï–ú–ï–°–¢–ò–õ–ò –°–Æ–î–ê, –í –°–ê–ú–û–ï –ù–ê–ß–ê–õ–û!
try:
    from web3.middleware import geth_poa_middleware  # –¥–ª—è BSC/PoA
    HAVE_POA = True
except Exception:
    HAVE_POA = False

# --- numeric guards ---
def _is_finite_num(x) -> bool:
    try:
        v = float(x)
        return math.isfinite(v)
    except Exception:
        return False

def _as_float(x, default=float("nan")):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ float —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π None, pd.NA, np.nan"""
    try:
        # –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ None –∏ pd.NA
        if x is None:
            return default
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ pandas NA (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å pandas < 2.0)
        if hasattr(x, '__class__') and x.__class__.__name__ == 'NAType':
            return default
        
        v = float(x)
        return v if math.isfinite(v) else default
    except (TypeError, ValueError):
        return default


from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict, Any
from gating_no_r import compute_p_thr_no_r
from no_r_auto import pick_no_r_mode
from delta_daily import DeltaDaily

from proj_scenarios import try_send_projection

from html import escape
from requests import RequestException
# –≤–≤–µ—Ä—Ö—É bnbusdrt6.py
from prob_calibrators import make_calibrator, _BaseCal

from performance_metrics import PerfMonitor

# === –ù–û–í–û–ï: –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ p –∏ rÃÇ-—Ç–∞–±–ª–∏—Ü–∞, EV-–≥–µ–π—Ç –ø–æ ¬´–º–∞—Ä–∂–µ –∫ —Ä—ã–Ω–∫—É¬ª ===
from ctx_calibration import p_ctx_calibrated
from rhat_quantile2d import RHat2D
from ev_margin_gate import loss_margin_q, p_thr_from_ev

from error_logger import setup_error_logging, log_exception, get_logger

from dotenv import load_dotenv; load_dotenv()


# === GAS PRICE FALLBACK: –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ===
gas_price_history = []  # –∏—Å—Ç–æ—Ä–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 20 —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≥–∞–∑–∞
MAX_GAS_HISTORY = 20    # —Ä–∞–∑–º–µ—Ä —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ –¥–ª—è –º–µ–¥–∏–∞–Ω—ã

# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π error-–ª–æ–≥ (GGG/errors.log)
setup_error_logging(log_dir=".", filename="errors.log")



def _proj_mark_once(path: str, day: str) -> bool:
    import json, os
    try:
        st = {}
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                st = json.load(f)
        if st.get("last_day") == day:
            return False
        st["last_day"] = day
        with open(path, "w", encoding="utf-8") as f:
            json.dump(st, f)
    except Exception:
        pass
    return True


from daily_report import try_send as try_send_daily

# /report: –ª—ë–≥–∫–∏–π —Å–ª—É—à–∞—Ç–µ–ª—å –∫–æ–º–∞–Ω–¥
from report_cmd import start_report_listener

from datetime import datetime, timezone
# --- NEW: addons ---
from microstructure import MicrostructureClient


# --- FIX: —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∏–º–ø–æ—Ä—Ç ZoneInfo –¥–ª—è Python 3.8/3.9+ ---
try:
    from zoneinfo import ZoneInfo  # Python 3.9+
except Exception:
    try:
        from backports.zoneinfo import ZoneInfo  # –¥–ª—è Python < 3.9
    except Exception:
        ZoneInfo = None  # fallback, –µ—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è

def _get_proj_tz():
    # —Å—Ç–∞—Ä–∞–µ–º—Å—è –≤–µ—Ä–Ω—É—Ç—å Europe/Berlin; –µ—Å–ª–∏ –Ω–µ—Ç –±–∞–∑—ã —á–∞—Å–æ–≤—ã—Ö –ø–æ—è—Å–æ–≤ ‚Äî –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º—Å—è –Ω–∞ UTC
    if ZoneInfo is not None:
        try:
            return ZoneInfo("Europe/Berlin")
        except Exception:
            pass
    # –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ
    print("[proj] warning: tz database unavailable; using UTC")
    return timezone.utc

# —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –ø—Ä–æ–µ–∫—Ü–∏–∏ –∏ —Ñ–∞–π–ª-–º–∞—Ä–∫–µ—Ä "—Ä–∞–∑ –≤ –¥–µ–Ω—å"
PROJ_TZ = _get_proj_tz()
PROJ_STATE_PATH = os.path.join(os.path.dirname(__file__), "proj_state.json")

# === –ù–û–í–û–ï: –∞–¥—Ä–µ—Å –∫–æ—à–µ–ª—å–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–∞–ª–∞–Ω—Å–∞ ===
WALLET_ADDRESS = os.getenv("WALLET_ADDRESS", "").strip()
PAPER_TRADING = not bool(WALLET_ADDRESS)  # –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞

if PAPER_TRADING:
    print("[init] üìÑ PAPER TRADING mode (no WALLET_ADDRESS)")
    WALLET_ADDRESS = None
else:
    WALLET_ADDRESS = Web3.to_checksum_address(WALLET_ADDRESS)
    print(f"[init] üí∞ REAL TRADING mode - Wallet: {WALLET_ADDRESS}")

from futures_ctx import FuturesContext
from pool_features import PoolFeaturesCtx
from extra_features import realized_metrics, jump_flag_from_rv_bv_rq, amihud_illiq, kyle_lambda
from extra_features import intraday_time_features, idio_features, GasHistory, pack_vector

from r_hat_improved import (
    estimate_r_hat_improved,
    analyze_r_hat_accuracy,
    adaptive_quantile
)

import requests


def fmtf(x, nd=4, dash="‚Äî"):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ —Å nd –∑–Ω–∞–∫–∞–º–∏ –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç '‚Äî'."""
    try:
        if x is None:
            return dash
        xf = float(x)
        if math.isnan(xf) or math.isinf(xf):
            return dash
        return f"{xf:.{nd}f}"
    except Exception:
        return dash

def fmt_pct(x, nd=2, dash="‚Äî"):
    """–ü—Ä–æ—Ü–µ–Ω—Ç—ã: 12.34% –∏–ª–∏ '‚Äî'."""
    s = fmtf(x, nd=nd, dash=dash)
    return s if s == dash else f"{s}%"

def update_capital_atomic(capital_state, new_capital: float, ts: int, csv_row: dict) -> float:
    """
    –ê—Ç–æ–º–∞—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–∞–ø–∏—Ç–∞–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ CSV.
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: —Å–Ω–∞—á–∞–ª–∞ –∫–∞–ø–∏—Ç–∞–ª, –ø–æ—Ç–æ–º CSV.
    –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥–µ—Ç –Ω–µ —Ç–∞–∫, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª.
    """
    try:
        # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–ø–∏—Ç–∞–ª –∞—Ç–æ–º–∞—Ä–Ω–æ —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_path = capital_state.path + ".tmp"
        with open(temp_path, 'w') as f:
            json.dump({"capital": new_capital, "ts": ts}, f)
            f.flush()
            os.fsync(f.fileno())
        os.replace(temp_path, capital_state.path)
        
        # –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∞ –ø–∏—à–µ–º –≤ CSV
        try:
            append_trade_row(CSV_PATH, csv_row)  # ‚Üê –ò–°–ü–†–ê–í–õ–ï–ù–û
        except Exception as e:
            print(f"[csv ] write failed but capital saved: {e}")
        
        return new_capital
    except Exception as e:
        print(f"[capital] save failed: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        return capital_state.load()

def get_gas_price_with_fallback(w3: Web3) -> int:
    global gas_price_history
    try:
        price = w3.eth.gas_price
        gas_price_history.append(price)
        if len(gas_price_history) > MAX_GAS_HISTORY:
            gas_price_history.pop(0)
        return price
    except Exception:
        if gas_price_history:
            median_price = int(np.median(gas_price_history))
            multiplier = 1.2
            return int(median_price * multiplier)
        return 5_000_000_000


def fmt_prob(x):
    """–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ p‚àà[0,1] –¥–æ 4 –∑–Ω–∞–∫–æ–≤ –∏–ª–∏ '‚Äî'."""
    return fmtf(x, nd=4)




def _tail_df(path, n=300):
    try:
        df = _read_csv_df(path)  # —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å —ç—Ç–æ—Ç —Ä–∏–¥–µ—Ä
        df = df.dropna(subset=["outcome"])
        return df.sort_values("settled_ts").tail(n).copy()
    except Exception:
        return None

# bnbusdrt6.py
def rolling_calib_error(path: str, n: int = 200) -> float:
    """–°—Ä–µ–¥–Ω—è—è |y - p_side| –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º n —Å–µ—Ç—Ç–ª–∞–º –∫–∞–∫ –ø—Ä–æ–∫—Å–∏ ECE/Brier."""
    df = _tail_df(path, n)
    if df is None or df.empty:
        return 0.10
    # –±–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    side = df.get("side")
    p_up = pd.to_numeric(df.get("p_up"), errors="coerce")
    y = (df.get("outcome") == "win").astype(float)

    mask = side.astype(str).str.upper().isin(["UP", "DOWN"]) & p_up.notna() & y.notna()
    if not mask.any():
        return 0.10

    side_u = side[mask].astype(str).str.upper()
    p_u = p_up[mask].astype(float).to_numpy()
    y_u = y[mask].astype(float).to_numpy()

    p_side = np.where(side_u == "UP", p_u, 1.0 - p_u)
    p_side = np.clip(p_side, 1e-6, 1 - 1e-6)

    err = np.abs(y_u - p_side)
    m = float(np.mean(err)) if np.isfinite(err).all() else float(np.nanmean(err))
    if not math.isfinite(m):
        return 0.10
    return m


def adaptive_kelly_cap(edge, recent_wr, calib_error, vol_scale):
    """
    –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∫–∞–ø –¥–ª—è Kelly fraction
    
    Args:
        edge: —Ç–µ–∫—É—â–∏–π edge (p_side - 1/r_hat)
        recent_wr: –≤–∏–Ω—Ä–µ–π—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Å–¥–µ–ª–æ–∫
        calib_error: –æ—à–∏–±–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        vol_scale: –º–∞—Å—à—Ç–∞–± –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
    """
    # –ë–∞–∑–æ–≤—ã–π –∫–∞–ø –Ω–∞ –æ—Å–Ω–æ–≤–µ edge
    if edge > 0.10:
        base_cap = 0.020  # 2.0% –ø—Ä–∏ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–º edge
    elif edge > 0.08:
        base_cap = 0.015  # 1.5%
    elif edge > 0.05:
        base_cap = 0.012  # 1.2%
    elif edge > 0.03:
        base_cap = 0.008  # 0.8%
    else:
        base_cap = 0.005  # 0.5%
    
    # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ –≤–∏–Ω—Ä–µ–π—Ç—É
    if recent_wr >= 0.58:
        wr_mult = 1.3  # –º–æ–∂–µ–º –±—ã—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ
    elif recent_wr >= 0.56:
        wr_mult = 1.15
    elif recent_wr >= 0.54:
        wr_mult = 1.0
    else:
        wr_mult = 0.85  # –æ—Å—Ç–æ—Ä–æ–∂–Ω–µ–µ –ø—Ä–∏ –Ω–∏–∑–∫–æ–º WR
    
    # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ
    calib_mult = 1.1 if calib_error < 0.03 else (0.9 if calib_error > 0.07 else 1.0)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ –º–∞—Å—à—Ç–∞–±—ã
    final_cap = base_cap * wr_mult * calib_mult * vol_scale
    
    return float(np.clip(final_cap, 0.003, 0.025))  # 0.3% - 2.5%


def adaptive_delta_protect(recent_wr, calib_error, n_trades):
    """
    –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è Œ¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    
    Args:
        recent_wr: –≤–∏–Ω—Ä–µ–π—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Å–¥–µ–ª–æ–∫
        calib_error: –æ—à–∏–±–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ (ECE)
        n_trades: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
    """
    base_delta = 0.03
    
    # –ú–∞—Å—à—Ç–∞–± –ø–æ –≤–∏–Ω—Ä–µ–π—Ç—É (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º WR)
    if recent_wr >= 0.58:
        wr_scale = 0.7  # —Å–Ω–∏–∂–∞–µ–º –∑–∞—â–∏—Ç—É –ø—Ä–∏ –æ—Ç–ª–∏—á–Ω–æ–º WR
    elif recent_wr >= 0.56:
        wr_scale = 0.85
    elif recent_wr >= 0.54:
        wr_scale = 1.0  # –±–∞–∑–æ–≤—ã–π
    elif recent_wr >= 0.52:
        wr_scale = 1.2
    else:
        wr_scale = 1.4  # –ø–æ–≤—ã—à–∞–µ–º –ø—Ä–∏ –ø–ª–æ—Ö–æ–º WR
    
    # –ú–∞—Å—à—Ç–∞–± –ø–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ (—Ö–æ—Ä–æ—à–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ ‚Üí –º–µ–Ω—å—à–µ –∑–∞—â–∏—Ç—ã)
    if calib_error < 0.03:
        calib_scale = 0.9
    elif calib_error < 0.05:
        calib_scale = 1.0
    else:
        calib_scale = 1.15
    
    # –ú–∞—Å—à—Ç–∞–± –ø–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–±–æ–ª—å—à–µ —Å–¥–µ–ª–æ–∫ ‚Üí –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
    activity_scale = 1.0 if n_trades >= 20 else 1.1
    
    delta_eff = base_delta * wr_scale * calib_scale * activity_scale
    return float(np.clip(delta_eff, 0.02, 0.08))


def realized_sigma_g(path: str, n: int = 200) -> float:
    """–°—Ç–¥.–∫–≤. –ª–æ–≥-—Ä–æ—Å—Ç–∞ –Ω–∞ —Å–¥–µ–ª–∫—É –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º n."""
    df = _tail_df(path, n)
    if df is None or df.empty: return 0.01
    cb = pd.to_numeric(df["capital_before"], errors="coerce").to_numpy()
    ca = pd.to_numeric(df["capital_after"],  errors="coerce").to_numpy()
    mask = np.isfinite(cb) & np.isfinite(ca) & (cb>0) & (ca>0)
    if not np.any(mask): return 0.01
    g = np.log(ca[mask] / cb[mask])
    return float(np.std(g, ddof=1))


# --- end helpers ---



# +++ –î–û–ë–ê–í–õ–ï–ù–û –¥–ª—è –ø—Ä–æ–≤–µ—Ä–æ–∫ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏:
from state_safety import (
    atomic_save_json, safe_load_json, sane_vec, sane_prob,
    file_sha256, atomic_write_bytes
)


_TG_FAILS = 0  # —Å—á—ë—Ç—á–∏–∫ –ø–æ–¥—Ä—è–¥ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–æ–∫ (—á—Ç–æ–±—ã –Ω–µ –≤–µ—à–∞—Ç—å –±–æ—Ç–∞)

_TG_MUTED_UNTIL = 0.0    # unix-ts –¥–æ –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–ª—á–∏–º
_TG_LAST_ERR = ""        # –ø–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–∏—á–∏–Ω–∞

from dataclasses import dataclass

# NEW: –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –º–µ—Ç—ã
from meta_ctx import build_regime_ctx, pack_ctx

# --- –¥–æ–±–∞–≤–∏–ª–∏ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø–æ—Å—Ç-–∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –º–µ—Ç–∞-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ ---
from collections import deque
from calib.selector import CalibratorSelector  # <‚Äî –Ω–∞—à —Å–µ–ª–µ–∫—Ç–æ—Ä –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞

from meta_cem_mc import MetaCEMMC, LambdaMARTMetaLite, ProbBlender  # ‚Üê NEW

# –£–ë–ò–†–ê–ï–ú –î–£–ë–õ–ò–†–£–Æ–©–ò–ï –ò–ú–ü–û–†–¢–´ - –æ–Ω–∏ —É–∂–µ –µ—Å—Ç—å –≤ –Ω–∞—á–∞–ª–µ!
# import numpy as np        # ‚Üê –£–ë–†–ê–¢–¨
# import pandas as pd       # ‚Üê –£–ë–†–ê–¢–¨
# from web3 import Web3, HTTPProvider    # ‚Üê –£–ë–†–ê–¢–¨ (–¥—É–±–ª–∏–∫–∞—Ç)
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# --- Telegram config (globals) ---
# --- Telegram config (globals) ---
from typing import Final
import threading  # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏


# --- –±—É—Ñ–µ—Ä—ã ¬´—Å—ã—Ä—ã—Ö¬ª p_meta –∏ –∏—Å—Ö–æ–¥–æ–≤ –¥–ª—è –æ–∫–Ω–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ ---
_CALIB_P_META = deque(maxlen=20000)  # p_meta_raw –¥–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
_CALIB_Y_META = deque(maxlen=20000)  # outcome: 1=win, 0=loss

TG_TOKEN: Final[str] = os.getenv("TG_TOKEN", "").strip()
# –í–∞–∂–Ω–æ: –¥–ª—è —á–∞—Ç–æ–≤/–∫–∞–Ω–∞–ª–æ–≤ ID –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, -100...).
def _env_int(name: str, default: int = 0) -> int:
    try:
        raw = os.getenv(name, str(default)).strip()
        return int(raw) if raw else default
    except Exception:
        return default

TG_CHAT_ID: Final[int] = _env_int("TG_CHAT_ID", 0)
TG_API: Final[str] = f"https://api.telegram.org/bot{TG_TOKEN}"

_REPORT_THREAD = None  # –ø–æ—Ç–æ–∫ —Å–ª—É—à–∞—Ç–µ–ª—è /report; –ø–æ–¥–Ω–∏–º–∞–µ–º –º–∞–∫—Å–∏–º—É–º –æ–¥–∏–Ω


# –°–µ—Å—Å–∏—è —Å —Ä–µ—Ç—Ä–∞—è–º–∏ (—á—Ç–æ–±—ã tg_send –±—ã–ª —É—Å—Ç–æ–π—á–∏–≤–µ–µ)
SESSION = requests.Session()
_adapter = HTTPAdapter(
    max_retries=Retry(
        total=3,                # 3 –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö
        backoff_factor=0.3,     # 0.3s, 0.6s, 1.2s
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=frozenset(["GET", "POST"])
    )
)
SESSION.mount("https://", _adapter)
SESSION.mount("http://", _adapter)

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äî ¬´–≤–∫–ª—é—á—ë–Ω –ª–∏¬ª Telegram
# =============================
# Telegram
# =============================
def tg_enabled() -> bool:
    # –≤–∫–ª—é—á–µ–Ω–æ + –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã (–∏–∑ ENV –∏–ª–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç)
    has_token = bool((TG_TOKEN if 'TG_TOKEN' in globals() else "") or
                     (TELEGRAM_BOT_TOKEN if 'TELEGRAM_BOT_TOKEN' in globals() else ""))
    has_chat  = bool((TG_CHAT_ID if 'TG_CHAT_ID' in globals() else 0) or
                     (TELEGRAM_CHAT_ID if 'TELEGRAM_CHAT_ID' in globals() else ""))
    return bool(TELEGRAM_ENABLED and has_token and has_chat)




from wr_pnl_tracker import StatsTracker, RestState, RestConfig
from reserve_fund import ReserveFund
import math
from requests.exceptions import Timeout as ReqTimeout, ReadTimeout, ConnectionError as ReqConnError
from web3.exceptions import TimeExhausted


# =============================
# ML –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# =============================
HAVE_XGB = False
HAVE_RIVER = False
HAVE_SKLEARN = False
try:
    import xgboost as xgb  # –±—É—Å—Ç–∏–Ω–≥ + –∑–∞–≥—Ä—É–∑–∫–∞/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    HAVE_XGB = True
except Exception:
    pass

try:
    from river.drift import ADWIN  # –¥–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–µ–π—Ñ–∞
    from river import forest as river_forest
    HAVE_RIVER = True
except Exception:
    ADWIN = None
    river_forest = None
    HAVE_RIVER = False

try:
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.calibration import CalibratedClassifierCV
    from sklearn.preprocessing import StandardScaler
    HAVE_SKLEARN = True
except Exception:
    # sklearn –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –¥–∞—ë–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é "–∑–∞–≥–ª—É—à–∫—É" StandardScaler
    class StandardScaler:
        def fit(self, X, y=None): return self
        def transform(self, X):    return X
        def fit_transform(self, X, y=None): return X
    HAVE_SKLEARN = False

# -----------------------------
# –ü–ê–†–ê–ú–ï–¢–†–´
# -----------------------------
START_CAPITAL_BNB = 2.0
BET_FRACTION = 0.01  # legacy

SYMBOL = "BNBUSDT"
BINANCE_INTERVAL = "1m"
BINANCE_LIMIT = 1000

CSV_PATH = "trades_prediction.csv"
DELTA_STATE_PATH = "delta_state.json"   # ‚Üê –Ω–æ–≤–æ–µ
CSV_SHADOW_PATH = "trades_shadow.csv"   # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ –∑–¥–µ—Å—å (–Ω—É–∂–Ω–æ –ø—Ä–∏ init DeltaDaily)
MIN_TRADES_FOR_DELTA = 50  # –ú–∏–Ω–∏–º—É–º —Å–¥–µ–ª–æ–∫ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ delta

# –ê–Ω—Ç–∏-—Å–ø–∞–º/—Ç–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è oracleCalled
MAX_WAIT_POLLS = 20
WAIT_PRINT_EVERY = 5

# ¬´–±–æ–ª–æ—Ç–æ¬ª ATR
ATR_LEN = 14
ATR_SMOOTH = 50
USE_PCT_CHOP = True
CHOP_PCT = 20.0
CHOP_RATIO = 0.6

# –§–∏—á–∏
M1, M2, M3 = 1, 3, 5
VWAP_LOOK = 10
KC_LEN = 20
KC_MULT = 2.0
BB_LEN = 20
BB_Z = 1.2
VOL_LEN = 50
VOL_BOOST = 0.15
RB_LEN = 20
USE_LORENTZ = True
C_M, C_S, C_B, C_R = 2.5, 3.0, 2.0, 1.6

# –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
SMOOTH_N = 8
USE_SUPER_SMOOTHER = True
SS_LEN = 8

# --- OU –î–û–ë–ê–í–ö–ò ---
OU_SKEW_USE = True
OU_SKEW_DT_UNIT = 60.0
OU_SKEW_DECAY = 0.997
OU_SKEW_THR = 0.15
OU_SKEW_LAMBDA_MAX = 0.45
OU_SKEW_Z_CLIP = 3.0

LOGIT_OU_USE = True
LOGIT_OU_HALF_LIFE_SEC = 120.0
LOGIT_OU_MU_BETA = 0.985
LOGIT_OU_Z_CLIP = 5.5
# -------------------------------------

# NN (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä)
NN_USE = True
ETA = 0.02
L2 = 0.002
BLEND_NN = 0.35
W_CLIP = 10.0
G_CLIP = 1.0

# Walk-Forward –≤–µ—Å–∞
WF_USE = True
WF_ETA = 0.02
WF_L2 = 0.003
WF_G_CLIP = 1.0
WF_W_CLIP = 7.0
WF_WEIGHTS_PATH = "wf_weights.json"
WF_INIT_W = [0.35, 0.20, 0.20, 0.25]

# Triple Screen –≠–ª–¥–µ—Ä–∞
ELDER_HTF = "15min"
ELDER_MID = "5min"
ELDER_ALPHA = 0.60
STOCH_LEN = 14
STOCH_OS = 20.0
STOCH_OB = 80.0

# –ì–∞–∑
GAS_USED_BET = 93_132
GAS_USED_CLAIM = 86_500

# –¢—Ä–µ–∂–µ—Ä–∏-—Ñ–∏–∏
TREASURY_FEE = 0.03

# --- –ù–æ–≤–æ–µ: —Ç–∞–π–º–∏–Ω–≥ –∏ –∑–∞—â–∏—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
GUARD_SECONDS   = 30      # —Ä–µ—à–∞–µ–º —Å—É–¥—å–±—É —Å—Ç–∞–≤–∫–∏ —Ç–æ–ª—å–∫–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 15—Å –¥–æ lock
SEND_WIN_LOW    = 12      # ¬´–æ–∫–Ω–æ –æ—Ç–ø—Ä–∞–≤–∫–∏¬ª: –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ (–¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏; —Å–µ–π—á–∞—Å paper)
SEND_WIN_HIGH   = 8       # –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ (–¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏; —Å–µ–π—á–∞—Å paper)
DELTA_PROTECT   = 0.03    # Œ¥ ‚Äî —Å—Ç—Ä–∞—Ö–æ–≤–æ–π –∑–∞–∑–æ—Ä –ø–æ–≤–µ—Ä—Ö EV-–ø–æ—Ä–æ–≥–∞
USE_STRESS_R15  = True    # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–µ—Å—Å –ø–æ –º–µ–¥–∏–∞–Ω–Ω–æ–º—É –ø—Ä–∏—Ç–æ–∫—É –∑–∞ 15—Å



# –ö–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫—Ç–∏–≤—ã
USE_CROSS_ASSETS = True
CROSS_SYMBOLS = ["BTCUSDT", "ETHUSDT"]
STABLE_SYMBOLS = ["USDCUSDT", "FDUSDUSDT", "TUSDUSDT"]
CROSS_SHIFT_BARS = 0
CROSS_ALPHA = 0.50
CROSS_W_MOM = 0.18
CROSS_W_VWAP = 0.12
STABLE_W_MOM = 0.06
STABLE_W_VWAP = 0.04

# –°–¢–ê–í–ö–ê: –∂—ë—Å—Ç–∫–∏–π –∫—ç–ø –Ω–∞ —Ä–∞—É–Ω–¥
MAX_STAKE_FRACTION = 0.01  # ‚â§3% –∫–∞–ø–∏—Ç–∞–ª–∞

TELEGRAM_BOT_TOKEN = os.getenv("TG_BOT_TOKEN", "").strip()
TELEGRAM_CHAT_ID   = os.getenv("TG_CHAT_ID", "").strip()

TELEGRAM_ENABLED   = True

TG_MUTE_AFTER      = 3       # –ø–æ—Å–ª–µ —Å–∫–æ–ª—å–∫–∏—Ö —Ñ–µ–π–ª–æ–≤ —É—Ö–æ–¥–∏–º –≤ mute
TG_COOLDOWN_S      = 300     # –±–∞–∑–æ–≤—ã–π –∫—É–ª–¥–∞—É–Ω (—Å–µ–∫) –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–±—ã
TG_PROBE_EVERY_S   = 30      # –≤ mute: –∫–∞–∫ —á–∞—Å—Ç–æ ¬´–ø—Ä–æ—â—É–ø—ã–≤–∞—Ç—å¬ª –ª–∏–Ω–∏—é

# –º–æ—Å—Ç –∫ —Å—Ç–∞—Ä—ã–º –∏–º–µ–Ω–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç tg_send()
TG_TOKEN = TELEGRAM_BOT_TOKEN
TG_CHAT_ID = TELEGRAM_CHAT_ID
TG_API = f"https://api.telegram.org/bot{TG_TOKEN}"

# RPC
# RPC
RPC_URLS = [
    "https://bsc-dataseed.bnbchain.org",
    "https://bsc-dataseed1.bnbchain.org",
    "https://bsc-dataseed2.bnbchain.org",
]
RPC_REQUEST_KW = {"timeout": 8}  # –∫–æ—Ä–æ—á–µ, —á–µ–º –ø—Ä–µ–∂–Ω–∏–µ 20s ‚Äî –º–µ–Ω—å—à–µ –∑–∞–≤–∏—Å–∞–Ω–∏–π

PREDICTION_ADDR = Web3.to_checksum_address("0x18B2A687610328590Bc8F2e5fEdDe3b582A49cdA")

PREDICTION_ABI = json.loads(r"""
[
  {"inputs":[],"name":"currentEpoch","outputs":[{"internalType":"uint256","name":"","type":"uint256"}],"stateMutability":"view","type":"function"},
  {"inputs":[{"internalType":"uint256","name":"epoch","type":"uint256"}],"name":"rounds","outputs":[
    {"internalType":"uint256","name":"epoch","type":"uint256"},
    {"internalType":"uint256","name":"startTimestamp","type":"uint256"},
    {"internalType":"uint256","name":"lockTimestamp","type":"uint256"},
    {"internalType":"uint256","name":"closeTimestamp","type":"uint256"},
    {"internalType":"int256","name":"lockPrice","type":"int256"},
    {"internalType":"int256","name":"closePrice","type":"int256"},
    {"internalType":"uint256","name":"lockOracleId","type":"uint256"},
    {"internalType":"uint256","name":"closeOracleId","type":"uint256"},
    {"internalType":"uint256","name":"totalAmount","type":"uint256"},
    {"internalType":"uint256","name":"bullAmount","type":"uint256"},
    {"internalType":"uint256","name":"bearAmount","type":"uint256"},
    {"internalType":"uint256","name":"rewardBaseCalAmount","type":"uint256"},
    {"internalType":"uint256","name":"rewardAmount","type":"uint256"},
    {"internalType":"bool","name":"oracleCalled","type":"bool"}
  ],"stateMutability":"view","type":"function"},
  {"inputs":[],"name":"intervalSeconds","outputs":[{"internalType":"uint256","name":"","type":"uint256"}],"stateMutability":"view","type":"function"},
  {"inputs":[],"name":"bufferSeconds","outputs":[{"internalType":"uint256","name":"","type":"uint256"}],"stateMutability":"view","type":"function"},
  {"inputs":[],"name":"minBetAmount","outputs":[{"internalType":"uint256","name":"","type":"uint256"}],"stateMutability":"view","type":"function"}
]
""")

# =============================
# HTTP session —Å —Ä–µ—Ç—Ä–∞—è–º–∏
# =============================
def make_requests_session():
    s = requests.Session()
    retry = Retry(
        total=5, backoff_factor=0.4, status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"]
    )
    s.mount("https://", HTTPAdapter(max_retries=retry))
    s.mount("http://",  HTTPAdapter(max_retries=retry))
    return s

SESSION: requests.Session = make_requests_session()

import atexit
atexit.register(lambda: SESSION.close())


# =============================
# –£–¢–ò–õ–ò–¢–´ Web3 / Binance
# =============================
# =============================
# ‚Ä¶ Web3 / Binance
# =============================
def connect_web3() -> Web3:
    for url in RPC_URLS:
        # –∫–æ—Ä–æ—á–µ —Ç–∞–π–º–∞—É—Ç –∏ –µ–¥–∏–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        w3 = Web3(HTTPProvider(url, request_kwargs=RPC_REQUEST_KW))
        try:
            # –¥–ª—è BSC (PoA) –≤–∞–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å middleware
            if HAVE_POA:
                try:
                    w3.middleware_onion.inject(geth_poa_middleware, layer=0)
                except Exception:
                    # –µ—Å–ª–∏ —É–∂–µ –≤—Å—Ç–∞–≤–ª–µ–Ω ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                    pass

            ok = False
            if hasattr(w3, "is_connected"):
                ok = w3.is_connected()
            elif hasattr(w3, "isConnected"):
                ok = w3.isConnected()
            if ok:
                return w3
        except Exception:
            pass
    raise RuntimeError("–Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ BSC RPC")



def connect_web3_resilient(retries=9999):
    delay = 1.0
    for _ in range(retries):
        try:
            return connect_web3()
        except Exception as e:
            print(f"[init] RPC connect failed: {e}; retrying in {delay:.1f}s")
            time.sleep(delay)
            delay = min(delay * 1.7, 30)
    raise RuntimeError("RPC connect: exhausted retries")

def get_gas_price_wei(w3: Web3) -> int:
    return w3.eth.gas_price

def get_prediction_contract(w3: Web3):
    return w3.eth.contract(address=PREDICTION_ADDR, abi=PREDICTION_ABI)

def get_min_bet_bnb(c) -> float:
    try:
        wei = int(c.functions.minBetAmount().call())
        return wei / 1e18
    except Exception:
        return 0.0

def binance_klines(symbol: str, interval: str, start_ms: int, end_ms: int) -> pd.DataFrame:
    url = "https://api.binance.com/api/v3/klines"
    params = dict(symbol=symbol, interval=interval, startTime=start_ms, endTime=end_ms, limit=BINANCE_LIMIT)
    out = []
    while True:
        r = SESSION.get(url, params=params, timeout=20)
        if r.status_code == 400:
            return pd.DataFrame()
        r.raise_for_status()
        rows = r.json()
        if not rows:
            break
        out += rows
        last_open = rows[-1][0]
        if last_open >= end_ms or len(rows) < BINANCE_LIMIT:
            break
        params["startTime"] = last_open + 1
        time.sleep(0.2)
    if not out:
        return pd.DataFrame()
    df = pd.DataFrame(out, columns=[
        "open_time","open","high","low","close","volume","close_time",
        "qav","trades","taker_base","taker_quote","ignore"
    ])
    df["open_time"]  = pd.to_datetime(df["open_time"], unit="ms", utc=True)
    df["close_time"] = pd.to_datetime(df["close_time"], unit="ms", utc=True)
    for col in ["open","high","low","close","volume"]:
        df[col] = df[col].astype(float)
    return df[["open_time","close_time","open","high","low","close","volume"]].set_index("close_time")

def ensure_klines_cover(df: Optional[pd.DataFrame], symbol: str, interval: str, need_until_ms: int, back_hours: int = 8) -> pd.DataFrame:
    if df is not None and not df.empty:
        have_last_ms = int(df.index[-1].timestamp() * 1000)
        if have_last_ms >= need_until_ms - 30_000:
            return df
    end_ms = need_until_ms
    start_ms = end_ms - back_hours * 3600 * 1000
    new_df = binance_klines(symbol, interval, start_ms, end_ms)
    return new_df

def ensure_klines_cover_map(df_map: Dict[str, Optional[pd.DataFrame]], symbols: List[str], interval: str, need_until_ms: int, back_hours: int = 8) -> Dict[str, pd.DataFrame]:
    out: Dict[str, pd.DataFrame] = {}
    for s in symbols:
        try:
            cur = df_map.get(s)
            out[s] = ensure_klines_cover(cur, s, interval, need_until_ms, back_hours)
        except Exception:
            out[s] = pd.DataFrame()
    return out

def nearest_close_price_ms(symbol: str, ts_ms: int) -> Optional[float]:
    df = binance_klines(symbol, "1m", ts_ms - 3*60_000, ts_ms + 2*60_000)
    if df is None or df.empty:
        return None
    tgt = pd.to_datetime(ts_ms, unit="ms", utc=True)
    i = df.index.get_indexer([tgt], method="pad")[0]
    if i == -1:
        return float(df["close"].iloc[0])
    return float(df["close"].iloc[i])

# =============================
# –ü–†–û–í–ï–†–ö–ê –ë–ê–õ–ê–ù–°–ê –ö–û–®–ï–õ–¨–ö–ê
# =============================
# =============================
# –ü–†–û–í–ï–†–ö–ê –ë–ê–õ–ê–ù–°–ê (PAPER/REAL)
# =============================
def get_wallet_balance(w3: Web3, account_address: Optional[str], paper_capital: float) -> float:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –±–∞–ª–∞–Ω—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞:
    - PAPER mode (account_address=None): –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª –∏–∑ paper_capital
    - REAL mode: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–æ—à–µ–ª—å–∫–∞ —á–µ—Ä–µ–∑ Web3
    
    Args:
        w3: Web3 instance
        account_address: –∞–¥—Ä–µ—Å –∫–æ—à–µ–ª—å–∫–∞ (None –¥–ª—è paper mode)
        paper_capital: —Ç–µ–∫—É—â–∏–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª (–¥–ª—è paper mode)
    
    Returns:
        float: –±–∞–ª–∞–Ω—Å –≤ BNB
    """
    # PAPER TRADING: –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª
    if account_address is None:
        return paper_capital
    
    # REAL TRADING: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
    try:
        balance_wei = w3.eth.get_balance(account_address)
        return balance_wei / 1e18
    except Exception as e:
        print(f"[wallet] real balance check failed: {e}")
        return 0.0  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π fallback –ø—Ä–∏ –æ—à–∏–±–∫–µ RPC


# =============================
# –¢–µ—Ö–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã/—Ñ–∏—á–∏
# =============================
def ema(series: pd.Series, n: int) -> pd.Series:
    return series.ewm(span=n, adjust=False).mean()

def sma(series: pd.Series, n: int) -> pd.Series:
    return series.rolling(n, min_periods=1).mean()

def stdev(series: pd.Series, n: int) -> pd.Series:
    return series.rolling(n, min_periods=1).std(ddof=0)

def true_range(df: pd.DataFrame) -> pd.Series:
    prev_close = df["close"].shift(1)
    tr = pd.DataFrame({
        "hl": df["high"] - df["low"],
        "hc": (df["high"] - prev_close).abs(),
        "lc": (df["low"] - prev_close).abs()
    }).max(axis=1)
    return tr

def rma(x: pd.Series, n: int) -> pd.Series:
    alpha = 1.0 / float(n)
    r = x.copy()
    if len(x) == 0:
        return x
    r.iloc[0] = x.iloc[:n].mean() if len(x) >= n else x.iloc[0]
    for i in range(1, len(x)):
        r.iloc[i] = alpha * x.iloc[i] + (1 - alpha) * r.iloc[i-1]
    return r

def atr_wilder(df: pd.DataFrame, n: int) -> pd.Series:
    return rma(true_range(df), n)

def atr(df: pd.DataFrame, n: int) -> pd.Series:
    return ema(true_range(df), n)

def lorentz(x: np.ndarray, c: float) -> np.ndarray:
    return x / (1.0 + (x / c) ** 2)

def _tanh(x: np.ndarray) -> np.ndarray:
    return np.tanh(x)

def norm_feat(x: np.ndarray, gain: float, c: float, use_lorentz: bool) -> np.ndarray:
    return lorentz(x, c) if use_lorentz else _tanh(gain * x)

def sigmoid(x: float) -> float:
    x = max(min(x, 60.0), -60.0)
    return 1.0 / (1.0 + math.exp(-x))

def softmax2(z_up: float, z_dn: float) -> Tuple[float, float]:
    m = max(z_up, z_dn)
    e_up = math.exp(z_up - m)
    e_dn = math.exp(z_dn - m)
    s = e_up + e_dn
    return e_up / s, e_dn / s

def session_vwap(df: pd.DataFrame, src: pd.Series) -> pd.Series:
    day = df.index.tz_convert("UTC").date
    grp = pd.Series(day, index=df.index)
    pv = (src * df["volume"]).groupby(grp).cumsum()
    vv = (df["volume"]).groupby(grp).cumsum().replace(0.0, np.nan)
    vwap = (pv / vv).ffill()
    return vwap

def rsi(series: pd.Series, n: int = 14) -> pd.Series:
    delta = series.diff().fillna(0.0)
    up = delta.clip(lower=0.0)
    dn = (-delta).clip(lower=0.0)
    rs = rma(up, n) / (rma(dn, n) + 1e-12)
    return 100.0 - (100.0 / (1.0 + rs))

def ema_pair_spread(series: pd.Series, fast: int, slow: int) -> pd.Series:
    return ema(series, fast) - ema(series, slow)

class EhlersSuperSmoother:
    def __init__(self, period: int):
        self.period = max(3, int(period))
        a1 = math.exp(-math.sqrt(2.0) * math.pi / self.period)
        self.c2 = 2.0 * a1 * math.cos(math.sqrt(2.0) * math.pi / self.period)
        self.c3 = -a1 * a1
        self.c1 = 1.0 - self.c2 - self.c3
        self.y1 = None
        self.y2 = None
        self.x1 = None

    def update(self, x: float) -> float:
        if self.y1 is None:
            self.y1 = x
            self.y2 = x
            self.x1 = x
            return x
        y = self.c1 * 0.5 * (x + (self.x1 if self.x1 is not None else x)) + self.c2 * self.y1 + self.c3 * self.y2
        self.y2, self.y1 = self.y1, y
        self.x1 = x
        return float(y)

# ========= OU HELPERS =========
def _phi_a_from_ols(n: float, Sx: float, Sy: float, Sxx: float, Sxy: float) -> Tuple[Optional[float], Optional[float]]:
    den = (n * Sxx - Sx * Sx)
    if den <= 1e-12:
        return None, None
    phi = (n * Sxy - Sx * Sy) / den
    a = (Sy - phi * Sx) / n
    return phi, a

class OUOnlineSkew:
    def __init__(self, dt_unit: float = 60.0, decay: float = 0.997):
        self.dt_unit = float(dt_unit)
        self.decay = float(decay)
        self.n = 0.0
        self.Sx = 0.0
        self.Sy = 0.0
        self.Sxx = 0.0
        self.Sxy = 0.0
        self.Syy = 0.0
        self.last_x = None

    def update_pair(self, x_prev: float, x_now: float):
        d = self.decay
        self.n = d * self.n + 1.0
        self.Sx = d * self.Sx + x_prev
        self.Sy = d * self.Sy + x_now
        self.Sxx = d * self.Sxx + x_prev * x_prev
        self.Sxy = d * self.Sxy + x_prev * x_now
        self.Syy = d * self.Syy + x_now * x_now
        self.last_x = x_now

    def _params(self) -> Optional[Tuple[float, float, float]]:
        if self.n < 20:
            return None
        phi, a = _phi_a_from_ols(self.n, self.Sx, self.Sy, self.Sxx, self.Sxy)
        if phi is None:
            return None
        phi = float(np.clip(phi, 1e-6, 0.999999))
        a = float(a)
        sse_over_n = (self.Syy
                      - 2.0 * a * self.Sy
                      - 2.0 * phi * self.Sxy
                      + 2.0 * a * phi * self.Sx
                      + (a * a) * self.n
                      + (phi * phi) * self.Sxx) / max(1.0, self.n)
        var_eps = max(1e-8, float(sse_over_n))
        kappa = -math.log(phi) / self.dt_unit
        if not math.isfinite(kappa) or kappa <= 0:
            return None
        mu = a / (1.0 - phi)
        denom = (1.0 - math.exp(-2.0 * kappa * self.dt_unit))
        sigma2 = max(1e-12, 2.0 * kappa * var_eps / max(1e-12, denom))
        return kappa, mu, sigma2

    def prob_above_zero(self, x_now: float, horizon_sec: float) -> Optional[Tuple[float, float]]:
        pars = self._params()
        if pars is None:
            return None
        kappa, mu, sigma2 = pars
        dt = max(0.0, float(horizon_sec))
        expk = math.exp(-kappa * dt)
        m = mu + (x_now - mu) * expk
        v = (sigma2 / (2.0 * kappa)) * (1.0 - math.exp(-2.0 * kappa * dt))
        s = max(1e-12, math.sqrt(v))
        z = (0.0 - m) / s
        p = 0.5 * math.erfc(z / math.sqrt(2.0))
        strength = 1.0 - expk
        return float(np.clip(p, 1e-6, 1.0 - 1e-6)), float(np.clip(strength, 0.0, 1.0))

class LogitOUSmoother:
    def __init__(self, half_life_sec: float = 120.0, mu_beta: float = 0.985, z_clip: float = 5.5):
        self.kappa = math.log(2.0) / max(1e-3, half_life_sec)
        self.mu = 0.0
        self.beta = float(np.clip(mu_beta, 0.0, 1.0))
        self.z_clip = float(z_clip)

    def update_mu(self, z_now: float):
        self.mu = self.beta * self.mu + (1.0 - self.beta) * z_now

    def predict_future(self, z_now: float, horizon_sec: float) -> float:
        dt = max(0.0, float(horizon_sec))
        expk = math.exp(-self.kappa * dt)
        z_now = float(np.clip(z_now, -self.z_clip, self.z_clip))
        z_pred = self.mu + (z_now - self.mu) * expk
        return float(np.clip(z_pred, -self.z_clip, self.z_clip))

# =============================

@dataclass
class RoundInfo:
    epoch: int
    start_ts: int
    lock_ts: int
    close_ts: int
    lock_price: float
    close_price: float
    bull_amount: float
    bear_amount: float
    reward_base: float
    reward_amt: float
    oracle_called: bool

    @property
    def payout_ratio(self) -> Optional[float]:
        if self.oracle_called and self.reward_base > 0:
            return self.reward_amt / self.reward_base
        return None

class OnlineLogReg:
    def __init__(self, eta=ETA, l2=L2, w_clip=W_CLIP, g_clip=G_CLIP, state_path: str = "calib_logreg_state.json"):
        self.w = np.zeros(5, dtype=float)  # 4 features + bias
        self.eta = eta
        self.l2 = l2
        self.w_clip = w_clip
        self.g_clip = g_clip
        self.state_path = state_path
        self._load()

    def _load(self):
        try:
            with open(self.state_path, "r") as f:
                obj = json.load(f)
            w = obj.get("w", [])
            if isinstance(w, list) and len(w) == len(self.w):
                self.w = np.array(w, dtype=float)
        except Exception:
            pass

    def save(self):
        try:
            with open(self.state_path, "w") as f:
                json.dump({"w": self.w.tolist()}, f)
        except Exception:
            pass

    def predict(self, phi: np.ndarray) -> float:
        z = float(np.dot(self.w, phi))
        return sigmoid(z)

    def update(self, phi: np.ndarray, y: float):
        p = self.predict(phi)
        g = p - y
        g = max(min(g, self.g_clip), -self.g_clip)
        grad = g * phi + self.l2 * self.w
        self.w -= self.eta * grad
        self.w = np.clip(self.w, -self.w_clip, self.w_clip)

class WalkForwardWeighter:
    def __init__(self, eta=WF_ETA, l2=WF_L2, g_clip=WF_G_CLIP, w_clip=WF_W_CLIP, path=WF_WEIGHTS_PATH):
        self.eta = eta
        self.l2 = l2
        self.g_clip = g_clip
        self.w_clip = w_clip
        self.path = path
        self.w = np.array(WF_INIT_W, dtype=float)
        self.load()

    def load(self):
        try:
            with open(self.path, "r") as f:
                data = json.load(f)
                if "w" in data and len(data["w"]) == 4:
                    self.w = np.array(data["w"], dtype=float)
        except Exception:
            pass

    def save(self):
        try:
            with open(self.path, "w") as f:
                json.dump({"w": self.w.tolist()}, f)
        except Exception:
            pass

    def predict_prob(self, phi_diff: np.ndarray) -> float:
        z = float(np.dot(self.w, phi_diff))
        return sigmoid(z)

    def update(self, phi_diff: np.ndarray, y_up: float):
        p = self.predict_prob(phi_diff)
        g = p - y_up
        g = max(min(g, self.g_clip), -self.g_clip)
        grad = g * phi_diff + self.l2 * self.w
        self.w -= self.eta * grad
        self.w = np.clip(self.w, -self.w_clip, self.w_clip)

# --------- –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ rounds ----------
# --- BSC Prediction helpers ---
def get_round(w3: Web3, c, epoch: int, retries: int = 2) -> Optional[RoundInfo]:
    """
    –ù–∞–¥—ë–∂–Ω—ã–π –≤—ã–∑–æ–≤ rounds(epoch) —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ä–µ—Ç—Ä–∞—è–º–∏ –∏ backoff.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç RoundInfo –∏–ª–∏ None (—á—Ç–æ–±—ã —Ü–∏–∫–ª –º–æ–≥ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ä–∞—É–Ω–¥ –ø—Ä–∏ RPC-–ø—Ä–æ–±–ª–µ–º–∞—Ö).
    """
    for i in range(retries + 1):
        try:
            r = c.functions.rounds(epoch).call()
            return RoundInfo(
        epoch=int(r[0]),
        start_ts=int(r[1]),
        lock_ts=int(r[2]),
        close_ts=int(r[3]),
        lock_price=float(r[4]),
        close_price=float(r[5]),
        bull_amount=float(r[9]),
        bear_amount=float(r[10]),
        reward_base=float(r[11]),
        reward_amt=float(r[12]),
        oracle_called=bool(r[13])
            )
        except (ReqTimeout, ReadTimeout, ReqConnError, TimeExhausted) as e:
            backoff = 0.5 * (2 ** i)
            print(f"[rpc ] timeout on rounds({epoch}), retry in {backoff:.1f}s ({e.__class__.__name__})")
            time.sleep(backoff)
        except KeyboardInterrupt:
            # –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º ‚Äî –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–µ—Ç–µ–≤—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
            raise
        except Exception as e:
            print(f"[rpc ] error on rounds({epoch}): {e}")
            break
    return None  # —Å–∏–≥–Ω–∞–ª –Ω–∞–≤–µ—Ä—Ö: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞—É–Ω–¥

def get_current_epoch(w3, c):
    return c.functions.currentEpoch().call()

# --------- —Ñ–∏—á–∏ –∏–∑ —Å–≤–µ—á–µ–π ----------
def features_from_binance(df: pd.DataFrame) -> Dict[str, pd.Series]:
    ln_hl = np.log(df["high"] / df["low"]).clip(lower=1e-12)
    sigP = np.sqrt((1.0 / (4.0 * np.log(2.0))) * (ln_hl ** 2))
    ln_co = np.log(df["close"] / df["open"]).fillna(0.0)
    sigGK = np.sqrt(np.maximum(0.0, 0.5 * (ln_hl ** 2) - (2.0 * np.log(2.0) - 1.0) * (ln_co ** 2)))
    ln_hc = np.log(df["high"] / df["close"]).clip(lower=1e-12)
    ln_ho = np.log(df["high"] / df["open"]).clip(lower=1e-12)
    ln_lc = np.log(df["low"] / df["close"]).clip(lower=1e-12)
    ln_lo = np.log(df["low"] / df["open"]).clip(lower=1e-12)
    rsVar = ln_hc * ln_ho + ln_lc * ln_lo
    sigRS = np.sqrt(np.maximum(0.0, rsVar))
    sigRB = pd.Series((sigP + sigGK + sigRS) / 3.0, index=df.index)
    sigRB = ema(sigRB, RB_LEN)
    normGain = 1.0 / np.maximum(sigRB.values, 1e-10)

    atr_series = atr_wilder(df, ATR_LEN)
    atr_sma = sma(atr_series, ATR_SMOOTH)

    r1 = np.log(df["close"] / df["close"].shift(M1)).fillna(0.0)
    r2 = np.log(df["close"] / df["close"].shift(M2)).fillna(0.0)
    r3 = np.log(df["close"] / df["close"].shift(M3)).fillna(0.0)
    Mraw = 0.6 * r1 + 0.3 * r2 + 0.1 * r3
    M_up = norm_feat(Mraw.values * normGain, 2.5, C_M, USE_LORENTZ)
    M_dn = norm_feat(-Mraw.values * normGain, 2.5, C_M, USE_LORENTZ)

    tp = (df["high"] + df["low"] + df["close"]) / 3.0
    vwap = session_vwap(df, tp)
    vslp = ((vwap - vwap.shift(VWAP_LOOK)) / vwap.replace(0.0, np.nan)).fillna(0.0)
    S_up = norm_feat(vslp.values * normGain, 3.0, C_S, USE_LORENTZ)
    S_dn = norm_feat(-vslp.values * normGain, 3.0, C_S, USE_LORENTZ)

    basisKC = ema(df["close"], KC_LEN)
    rngKC = atr_wilder(df, KC_LEN)
    upKC = basisKC + KC_MULT * rngKC
    dnKC = basisKC - KC_MULT * rngKC
    distUp = ((df["close"] - upKC) / (KC_MULT * rngKC.replace(0, np.nan))).replace([np.inf, -np.inf], 0.0).fillna(0.0)
    distDn = ((dnKC - df["close"]) / (KC_MULT * rngKC.replace(0, np.nan))).replace([np.inf, -np.inf], 0.0).fillna(0.0)
    B_up = norm_feat(distUp.values, 2.0, C_B, USE_LORENTZ)
    B_dn = norm_feat(distDn.values, 2.0, C_B, USE_LORENTZ)

    bb_basis = sma(df["close"], BB_LEN)
    bb_dev = stdev(df["close"], BB_LEN).replace(0.0, np.nan)
    Zs = ((df["close"] - bb_basis) / bb_dev).replace([np.inf, -np.inf], 0.0).fillna(0.0)

    R_up = norm_feat(np.maximum(0.0, -Zs - BB_Z).values, 1.6, C_R, USE_LORENTZ)
    R_dn = norm_feat(np.maximum(0.0,  Zs - BB_Z).values, 1.6, C_R, USE_LORENTZ)

    vol_usd = df["volume"] * df["close"]
    vMean = sma(vol_usd, VOL_LEN)
    vStd = stdev(vol_usd, VOL_LEN).replace(0.0, np.nan)
    volZ = ((vol_usd - vMean) / vStd).replace([np.inf, -np.inf], 0.0).fillna(0.0)
    volAmp = np.clip(1.0 + VOL_BOOST * np.maximum(0.0, volZ.values), 0.8, 1.8)

    return dict(
        M_up=pd.Series(M_up, index=df.index),
        M_dn=pd.Series(M_dn, index=df.index),
        S_up=pd.Series(S_up, index=df.index),
        S_dn=pd.Series(S_dn, index=df.index),
        B_up=pd.Series(B_up, index=df.index),
        B_dn=pd.Series(B_dn, index=df.index),
        R_up=pd.Series(R_up, index=df.index),
        R_dn=pd.Series(R_dn, index=df.index),
        atr=pd.Series(atr_series, index=df.index),
        atr_sma=pd.Series(atr_sma, index=df.index),
        volAmp=pd.Series(volAmp, index=df.index),
        close=df["close"],
        open=df["open"],
        high=df["high"],
        low=df["low"],
        Zs=Zs,
    )

def _index_pad(series: pd.Series, t: pd.Timestamp) -> Optional[int]:
    idx = series.index.get_indexer([t], method="pad")
    return None if idx[0] == -1 else int(idx[0])

def _np_percentile_linear(arr: np.ndarray, q: float) -> float:
    try:
        return float(np.percentile(arr, q, method="linear"))
    except TypeError:
        return float(np.percentile(arr, q, interpolation="linear"))

def is_chop_at_time(feats: Dict[str, pd.Series], tstamp: pd.Timestamp) -> bool:
    end_loc = _index_pad(feats["atr"], tstamp)
    if end_loc is None:
        return True
    start_loc = max(0, end_loc - ATR_SMOOTH + 1)
    window_atr = feats["atr"].iloc[start_loc:end_loc + 1].dropna()
    if window_atr.empty:
        return True
    atr_now = float(feats["atr"].iloc[end_loc])
    if USE_PCT_CHOP:
        pct = _np_percentile_linear(window_atr.values, CHOP_PCT)
        return atr_now <= pct
    else:
        atr_sma_val = float(feats["atr_sma"].iloc[end_loc])
        return atr_now < atr_sma_val * CHOP_RATIO

# ============== Triple Screen / Elder ==============
def resample_ohlc(df: pd.DataFrame, rule: str) -> pd.DataFrame:
    agg = {"open": "first","high": "max","low": "min","close": "last","volume": "sum"}
    out = df[["open", "high", "low", "close", "volume"]].resample(rule, label="right", closed="right").agg(agg)
    return out.dropna(how="any")

def macd_hist(close: pd.Series, fast=12, slow=26, sig=9) -> pd.Series:
    macd = ema(close, fast) - ema(close, slow)
    signal = ema(macd, sig)
    return macd - signal

def stoch_k(df: pd.DataFrame, n: int = 14) -> pd.Series:
    ll = df["low"].rolling(n, min_periods=1).min()
    hh = df["high"].rolling(n, min_periods=1).max()
    return 100.0 * (df["close"] - ll) / (hh - ll + 1e-12)

def to_logit(p: float) -> float:
    p = min(max(p, 1e-6), 1.0 - 1e-6)
    return math.log(p / (1.0 - p))

def from_logit(z: float) -> float:
    z = max(min(z, 60.0), -60.0)
    return 1.0 / (1.0 + math.exp(-z))

def elder_logit_adjust(df_1m: pd.DataFrame, tstamp: pd.Timestamp, p_up_hat: float) -> float:
    try:
        htf = resample_ohlc(df_1m, ELDER_HTF)
        if htf.empty:
            return p_up_hat
        i = htf.index.get_indexer([tstamp], method="pad")[0]
        if i <= 0:
            return p_up_hat
        hist = macd_hist(htf["close"])
        sgn = 1.0 if hist.iloc[i-1] > 0 else (-1.0 if hist.iloc[i-1] < 0 else 0.0)

        mtf = resample_ohlc(df_1m, ELDER_MID)
        if mtf.empty:
            return p_up_hat
        j = mtf.index.get_indexer([tstamp], method="pad")[0]
        if j <= 0:
            return p_up_hat
        k = float(stoch_k(mtf, STOCH_LEN).iloc[j-1])
        rng = max(1.0, (STOCH_OB - STOCH_OS))
        t = float(np.clip((k - STOCH_OS)/rng, 0.0, 1.0))
        pullback = 1.0 - 2.0 * t  # [-1..1]

        z = to_logit(p_up_hat) + ELDER_ALPHA * (sgn * pullback)
        return from_logit(z)
    except Exception:
        return p_up_hat

# ====== –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏–∑ —Ñ–∏—á (+ –∞–≤—Ç–æ-–≤–µ—Å–∞ WF) ======
def prob_up_down_at_time(feats: Dict[str, pd.Series], tstamp: pd.Timestamp, w_dyn: Optional[np.ndarray] = None) -> Tuple[float, float, Dict[str, float]]:
    i = _index_pad(feats["M_up"], tstamp)
    if i is None:
        return 0.5, 0.5, {}
    M_up = float(feats["M_up"].iloc[i]); M_dn = float(feats["M_dn"].iloc[i])
    S_up = float(feats["S_up"].iloc[i]); S_dn = float(feats["S_dn"].iloc[i])
    B_up = float(feats["B_up"].iloc[i]); B_dn = float(feats["B_dn"].iloc[i])
    R_up = float(feats["R_up"].iloc[i]); R_dn = float(feats["R_dn"].iloc[i])
    volAmp = float(feats["volAmp"].iloc[i])

    if w_dyn is None or len(w_dyn) != 4:
        w_mom, w_vwp, w_brk, w_rev = 0.35, 0.20, 0.20, 0.25
    else:
        w_mom, w_vwp, w_brk, w_rev = [float(x) for x in w_dyn]
        # –∞–Ω—Ç–∏-—É—Å—É—à–∫–∞: –µ—Å–ª–∏ ||w|| —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞ ‚Äî –æ—Ç–∫–∞—Ç –∫ —Å—Ç–∞—Ä—Ç–æ–≤—ã–º
        if float(np.linalg.norm([w_mom, w_vwp, w_brk, w_rev])) < 0.15:
            w_mom, w_vwp, w_brk, w_rev = 0.35, 0.20, 0.20, 0.25


    Z_up = (w_mom * M_up * volAmp) + (w_vwp * S_up) + (w_brk * B_up) + (w_rev * R_up)
    Z_dn = (w_mom * M_dn * volAmp) + (w_vwp * S_dn) + (w_brk * B_dn) + (w_rev * R_dn)
    P_up, P_dn = softmax2(Z_up, Z_dn)

    phi_wf = np.array([
        (M_up - M_dn) * volAmp,
        (S_up - S_dn),
        (B_up - B_dn),
        (R_up - R_dn)
    ], dtype=float)
    return P_up, P_dn, {"phi_wf0": phi_wf[0], "phi_wf1": phi_wf[1], "phi_wf2": phi_wf[2], "phi_wf3": phi_wf[3]}

# ====== –ö—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤—ã ======
def features_for_symbols(df_map: Dict[str, pd.DataFrame]) -> Dict[str, Dict[str, pd.Series]]:
    out: Dict[str, Dict[str, pd.Series]] = {}
    for sym, df in df_map.items():
        if df is not None and not df.empty:
            try:
                out[sym] = features_from_binance(df)
            except Exception:
                pass
    return out

def _idx_with_shift(series: pd.Series, tstamp: pd.Timestamp, shift_bars: int = 0) -> Optional[int]:
    i = _index_pad(series, tstamp)
    if i is None:
        return None
    i = int(i) - int(shift_bars)
    if i < 0 or i >= len(series):
        return None
    return i

def cross_up_down_contrib(feats_map: Dict[str, Dict[str, pd.Series]],
                          tstamp: pd.Timestamp,
                          symbols: List[str],
                          w_mom: float,
                          w_vwap: float,
                          shift_bars: int = 0) -> Tuple[float, float]:
    z_up_sum, z_dn_sum = 0.0, 0.0
    for sym in symbols:
        f = feats_map.get(sym)
        if not f:
            continue
        i = _idx_with_shift(f["M_up"], tstamp, shift_bars)
        if i is None:
            continue
        vA = float(f["volAmp"].iloc[i])
        M_up = float(f["M_up"].iloc[i]); M_dn = float(f["M_dn"].iloc[i])
        S_up = float(f["S_up"].iloc[i]); S_dn = float(f["S_dn"].iloc[i])
        z_up = (w_mom * M_up * vA) + (w_vwap * S_up)
        z_dn = (w_mom * M_dn * vA) + (w_vwap * S_dn)
        z_up_sum += z_up
        z_dn_sum += z_dn
    return z_up_sum, z_dn_sum

# =============================
# –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ñ–∞–±—Ä–∏–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
# =============================
class ExtendedMLFeatures:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π x-–≤–µ–∫—Ç–æ—Ä –ø–æ–¥ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (XGB/RF/ARF/NN) –∏–∑ –º–∏–Ω—É—Ç–Ω—ã—Ö —Ñ–∏—á –∏ ¬´—Å—ã—Ä—ã—Ö¬ª OHLC:
      - –±–∞–∑–æ–≤—ã–µ –¥–∏—Ñ—Ñ—ã (Mom/VWAP/Keltner/Bollinger)
      - BB z-score, Keltner position/width
      - ATR –Ω–æ—Ä–º. / wick imbalance
      - RSI, —Ç—Ä–µ–Ω–¥ RSI (slope)
      - –ø–∞—Ä–Ω—ã–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ü–∏–∏ (—É–º–µ—Ä–µ–Ω–Ω–æ)
    """
    def __init__(self, use_interactions: bool = True):
        self.use_interactions = use_interactions
        base_dim = 11
        inter_dim = 3 if use_interactions else 0
        self.dim = base_dim + inter_dim  # 14 –ø—Ä–∏ use_interactions=True

    def _keltner(self, df: pd.DataFrame) -> Tuple[pd.Series, pd.Series]:
        basis = ema(df["close"], KC_LEN)
        rng = atr_wilder(df, KC_LEN)
        return basis, rng

    def build(self, df_1m: pd.DataFrame, feats: Dict[str, pd.Series], tstamp: pd.Timestamp) -> np.ndarray:
        i = _index_pad(feats["M_up"], tstamp)
        if i is None:
            return np.zeros(self.dim, dtype=float)

        m_diff = float(feats["M_up"].iloc[i] - feats["M_dn"].iloc[i])
        s_diff = float(feats["S_up"].iloc[i] - feats["S_dn"].iloc[i])
        b_diff = float(feats["B_up"].iloc[i] - feats["B_dn"].iloc[i])
        r_diff = float(feats["R_up"].iloc[i] - feats["R_dn"].iloc[i])

        z_bb = float(feats.get("Zs", pd.Series(index=df_1m.index, dtype=float)).iloc[i])

        basisKC, rngKC = self._keltner(df_1m)
        kc_pos = float(((df_1m["close"].iloc[i] - basisKC.iloc[i]) / (KC_MULT * rngKC.iloc[i] + 1e-12)))
        kc_w = float((KC_MULT * rngKC.iloc[i]) / max(1e-9, df_1m["close"].iloc[i]))

        atr_now = float(feats["atr"].iloc[i])
        atr_sma_now = float(feats["atr_sma"].iloc[i])
        atr_norm = float(atr_now / (atr_sma_now + 1e-12))

        rsi_series = rsi(df_1m["close"], 14).fillna(50.0)
        rsi_now = float(rsi_series.iloc[i])
        rsi_norm = (rsi_now - 50.0) / 50.0
        i_prev = max(0, i - 3)
        trend_rsi = float((rsi_series.iloc[i] - rsi_series.iloc[i_prev]) / 100.0)

        hi = float(df_1m["high"].iloc[i]); lo = float(df_1m["low"].iloc[i])
        op = float(df_1m["open"].iloc[i]); cl = float(df_1m["close"].iloc[i])
        rng = max(1e-12, hi - lo)
        up_w = hi - max(op, cl)
        dn_w = min(op, cl) - lo
        wick_imb = float((up_w - dn_w) / rng)

        feats_vec = [
            m_diff, s_diff, b_diff, r_diff,
            z_bb, kc_pos, atr_norm, rsi_norm,
            wick_imb, trend_rsi, kc_w
        ]
        if self.use_interactions:
            feats_vec += [
                m_diff * s_diff,
                m_diff * rsi_norm,
                s_diff * kc_pos,
            ]
        x = np.array(feats_vec, dtype=float)
        x = np.nan_to_num(x, nan=0.0, posinf=5.0, neginf=-5.0)
        x = np.clip(x, -5.0, 5.0)
        return x

# =============================
# CSV / KPI

# =============================
CSV_COLUMNS = [
    "settled_ts","epoch","side","p_up",
    "p_meta_raw","p_meta2_raw","p_blend","blend_w","calib_src",
    "p_thr_used","p_thr_src","edge_at_entry",
    "stake","gas_bet_bnb","gas_claim_bnb",
    "gas_price_bet_gwei","gas_price_claim_gwei",
    "outcome","pnl","capital_before","capital_after",
    "lock_ts","close_ts","lock_price","close_price","payout_ratio","up_won",
    "r_hat_used","r_hat_source","r_hat_error_pct"  # ‚Üê –ù–û–í–û–ï
]



# üëá –ï–¥–∏–Ω–∞—è —Å—Ö–µ–º–∞ —Ç–∏–ø–æ–≤ –¥–ª—è –Ω–∞—à–∏—Ö CSV
CSV_DTYPES = {
    "settled_ts":           "Int64",
    "epoch":                "Int64",
    "side":                 "string",
    "p_up":                 "float64",
    "p_meta_raw":           "float64",
    "p_meta2_raw":          "float64",   # ‚Üê NEW
    "p_blend":              "float64",   # ‚Üê NEW
    "blend_w":              "float64",   # ‚Üê NEW                       # ‚Üê –î–û–ë–ê–í–ò–õ–ò
    "calib_src":            "string", 
    "p_thr_used":           "float64",
    "p_thr_src":            "string",
    "edge_at_entry":        "float64",
    "stake":                "float64",
    "gas_bet_bnb":          "float64",
    "gas_claim_bnb":        "float64",
    "gas_price_bet_gwei":   "float64",
    "gas_price_claim_gwei": "float64",
    "outcome":              "string",    # ‚Üê –≤–∞–∂–Ω–æ: —Å—Ç—Ä–æ–∫–∞
    "pnl":                  "float64",
    "capital_before":       "float64",
    "capital_after":        "float64",
    "lock_ts":              "Int64",
    "close_ts":             "Int64",
    "lock_price":           "float64",
    "close_price":          "float64",
    "payout_ratio":         "float64",
    "up_won":               "boolean",
    "r_hat_used":           "float64",      # ‚Üê –ù–û–í–û–ï
    "r_hat_source":         "string",       # ‚Üê –ù–û–í–û–ï
    "r_hat_error_pct":      "float64",      # ‚Üê –ù–û–í–û–ï   # ‚Üê –≤–∞–∂–Ω–æ: –ª–æ–≥–∏—á–µ—Å–∫–∏–π
}

# --- –ü–æ—Ä–æ–≥ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è Œ¥ –æ—Ç —Ç—é–Ω–µ—Ä–∞ ---
MIN_TRADES_FOR_DELTA = 500  # –¥–æ —ç—Ç–æ–≥–æ —á–∏—Å–ª–∞ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ Œ¥ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ 0.000

def _settled_trades_count(path: str) -> int:
    """
    –°—á–∏—Ç–∞–µ—Ç –ö–û–õ–ò–ß–ï–°–¢–í–û –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (win/loss/draw) –≤ trades CSV.
    –≠—Ç–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã —Ä–µ—à–∏—Ç—å: –≤–∫–ª—é—á–∞—Ç—å –ª–∏ Œ¥ –∏–∑ —Ç—é–Ω–µ—Ä–∞ –∏–ª–∏ –¥–µ—Ä–∂–∞—Ç—å 0.000.
    """
    try:
        df = _read_csv_df(path)
        if df is None or df.empty:
            return 0
        out = df.get("outcome")
        if out is None:
            return 0
        # outcome —Ö—Ä–∞–Ω–∏—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞; —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ win/loss/draw
        out = out.astype("string").str.lower()
        return int(out.isin(["win", "loss", "draw"]).sum())
    except Exception:
        return 0



def _coerce_csv_dtypes(df: pd.DataFrame) -> pd.DataFrame:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–∏–ø—ã —Å—Ç–æ–ª–±—Ü–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ CSV_DTYPES (–º—è–≥–∫–æ, –±–µ–∑ –ø–∞–¥–µ–Ω–∏–π)."""
    
    # ‚úÖ –ó–∞–º–µ–Ω—è–µ–º pd.NA –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    obj_like = list(df.select_dtypes(include=["object", "string"]).columns)
    if obj_like:
        df[obj_like] = df[obj_like].fillna("")  # –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ —á–µ–º .where()
    
    for col, dtype in CSV_DTYPES.items():
        # bnbusdrt6.py  (—Ñ—É–Ω–∫—Ü–∏—è _coerce_csv_dtypes)
        if col not in df.columns:
            # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º np.nan –≤–º–µ—Å—Ç–æ pd.NA
            if dtype in ("float64", "Int64"):
                df[col] = np.nan
            elif dtype == "boolean":
                # –±—ã–ª–æ: df[col] = pd.Series(dtype="boolean")  ‚Üê –¥–ª–∏–Ω–∞ 0 ‚Üí —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω —Å –∏–Ω–¥–µ–∫—Å–æ–º df
                df[col] = pd.Series([pd.NA]*len(df), dtype="boolean")
            else:
                df[col] = ""
            continue

        
        try:
            if dtype in ("float64",):
                df[col] = pd.to_numeric(df[col], errors="coerce")
                df[col] = df[col].fillna(np.nan).astype(dtype)
            elif dtype in ("Int64",):
                df[col] = pd.to_numeric(df[col], errors="coerce")
                # ‚úÖ Int64 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç pd.NA, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ —á–µ—Ä–µ–∑ astype
                df[col] = df[col].astype("Int64")
            # bnbusdrt6.py  (—Ñ—É–Ω–∫—Ü–∏—è _coerce_csv_dtypes)
            elif dtype == "boolean":
                # –ù–∞–¥—ë–∂–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ —Å—Ç–∞—Ä—ã—Ö CSV:
                # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 'True'/'False', '1'/'0', 't'/'f', 'y'/'n', 'yes'/'no' (—Ä–µ–≥–∏—Å—Ç—Ä/–ø—Ä–æ–±–µ–ª—ã –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º)
                s_str = df[col].astype("string").str.strip().str.lower()
                _map = {
                    "true": True, "false": False,
                    "1": True, "0": False,
                    "t": True, "f": False,
                    "y": True, "n": False,
                    "yes": True, "no": False,
                }
                df[col] = pd.Series(s_str.map(_map), dtype="boolean")
            else:
                df[col] = df[col].astype(dtype)
        except Exception as e:
            print(f"[warn] failed to coerce {col} to {dtype}: {e}")
            pass
    
    return df

def ensure_csv_header(path: str):
    if not os.path.exists(path):
        with open(path, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(CSV_COLUMNS)

def append_trade_row(path: str, row: Dict):
    ensure_csv_header(path)
    with open(path, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow([row.get(col, "") for col in CSV_COLUMNS])


# ========= SHADOW CSV (–¥–ª—è off-policy Œ¥) =========
def ensure_shadow_header(path: str):
    if not os.path.exists(path):
        with open(path, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(CSV_COLUMNS)

def append_shadow_row(path: str, row: Dict):
    ensure_shadow_header(path)
    with open(path, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow([row.get(col, "") for col in CSV_COLUMNS])
        

def try_settle_shadow_rows(path: str, w3: Web3, c, cur_epoch: int) -> None:
    """–ó–∞–∫—Ä—ã—Ç—å —Ç–µ–Ω–µ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ (outcome –ø—É—Å—Ç) –¥–ª—è —É–∂–µ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —ç–ø–æ—Ö (< cur_epoch)."""
    if not os.path.exists(path):
        return

    df = _read_csv_df(path)
    if df.empty:
        return

    # –û—Ç–∫—Ä—ã—Ç—ã–µ —Ç–µ–Ω–∏: outcome –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/–ø—É—Å—Ç –∏ epoch < cur_epoch
    outcome_series = df.get("outcome")
    if outcome_series is None:
        return

    open_mask = (
        outcome_series.isna() |
        (outcome_series.astype(str).str.len() == 0)
    ) & (pd.to_numeric(df["epoch"], errors="coerce") < int(cur_epoch))

    if not bool(open_mask.any()):
        return

    changed_any = False

    for idx, row in df.loc[open_mask].iterrows():
        try:
            # --- –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –≥–µ—Ç—Ç–µ—Ä—ã —á–∏—Å–µ–ª ---
            def _sf(x, default=0.0):
                """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ float —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π pd.NA"""
                try:
                    # ‚úÖ –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ pd.NA (–¥–ª—è pandas < 2.0)
                    if pd.isna(x):  # —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è pd.NA, –∏ –¥–ª—è np.nan
                        return default
                    
                    v = float(pd.to_numeric(x, errors="coerce"))
                    return v if math.isfinite(v) else default
                except (TypeError, ValueError):
                    return default

            epoch = int(pd.to_numeric(row.get("epoch"), errors="coerce"))
            rd = get_round(w3, c, epoch)
            if not rd or not getattr(rd, "oracle_called", False):
                # –†–∞—É–Ω–¥ –µ—â—ë –Ω–µ –∑–∞–∫—Ä—ã—Ç ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∑–∂–µ
                continue

            side = str(row.get("side", "UP")).upper()
            stake = _sf(row.get("stake", 0.0), 0.0)

            up_won   = (rd.close_price > rd.lock_price)
            down_won = (rd.close_price < rd.lock_price)
            draw     = (rd.close_price == rd.lock_price)

            # –ì–∞–∑ –∏–∑ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤ —Ç–µ–Ω–∏ –∑–Ω–∞—á–µ–Ω–∏–π
            gb = _sf(row.get("gas_bet_bnb", 0.0), 0.0)    # bet gas
            gc = _sf(row.get("gas_claim_bnb", 0.0), 0.0)  # claim gas

            # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤—ã–ø–ª–∞—Ç; –µ—Å–ª–∏ –ø—É—Å—Ç/–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º 1.9 –∫–∞–∫ –¥–µ—Ñ–æ–ª—Ç
            ratio = _sf(getattr(rd, "payout_ratio", None), 1.9)
            if not math.isfinite(ratio) or ratio <= 0:
                ratio = 1.9

            # --- PnL —Å —É—á—ë—Ç–æ–º –≥–∞–∑–∞ (off-policy) ---
            if draw:
                pnl = -(gb + gc)
                outcome = "draw"
            else:
                win = (up_won and side == "UP") or (down_won and side == "DOWN")
                if win:
                    pnl = stake * (ratio - 1.0) - (gb + gc)
                    outcome = "win"
                else:
                    pnl = -stake - gb
                    outcome = "loss"

            # --- –ø–æ–ø–æ–ª–Ω—è–µ–º –æ–∫–Ω–æ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞ –º–µ—Ç–∞-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π ---
            # --- –ø–æ–ø–æ–ª–Ω—è–µ–º –æ–∫–Ω–æ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞ –º–µ—Ç–∞-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π ---
            try:
                if outcome in ("win", "loss"):
                    # —Å—ã—Ä–æ–µ p_meta_raw, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ–ª–æ–∂–∏–ª–∏ –≤ bets[epoch] –ø—Ä–∏ —Ä–µ—à–µ–Ω–∏–∏
                    p_logged_raw = float(b.get("p_meta_raw", b.get("p_up", float('nan'))))
                    _CALIB_P_META.append(p_logged_raw)
                    _CALIB_Y_META.append(1 if outcome == "win" else 0)
                    # –æ–±–Ω–æ–≤–∏–º –æ–Ω–ª–∞–π–Ω-–º–µ–Ω–µ–¥–∂–µ—Ä (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
                    if os.getenv("CALIB_ENABLE","1")=="1":
                        settled_ts = int(time.time())
                        globals()["_CALIB_MGR"].update(p_logged_raw, 1 if outcome=="win" else 0, settled_ts)
            except Exception:
                pass


            # --- –ó–∞–ø–æ–ª–Ω—è–µ–º


            # --- –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–æ–ª—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–º df ---
            df.at[idx, "outcome"]       = outcome
            df.at[idx, "pnl"]           = pnl
            df.at[idx, "settled_ts"]    = int(time.time())
            df.at[idx, "lock_ts"]       = getattr(rd, "lock_ts", None)
            df.at[idx, "close_ts"]      = getattr(rd, "close_ts", None)
            df.at[idx, "lock_price"]    = getattr(rd, "lock_price", float("nan"))
            df.at[idx, "close_price"]   = getattr(rd, "close_price", float("nan"))
            df.at[idx, "payout_ratio"]  = ratio
            df.at[idx, "up_won"]        = bool(up_won)

            # –ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π capital_after –¥–ª—è –æ—Ñ—Ñ-–ø–æ–ª–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
            cap_before = _sf(row.get("capital_before", float("nan")), float("nan"))
            if math.isfinite(cap_before):
                df.at[idx, "capital_after"] = cap_before + pnl

            changed_any = True

        except Exception as e:
            print(f"[shadow] settle error for epoch={row.get('epoch')} : {e}")

    if changed_any:
        df.to_csv(path, index=False, encoding="utf-8-sig")



def _read_csv_df(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        empty = pd.DataFrame({c: pd.Series(np.nan, dtype=CSV_DTYPES.get(c, "string")) for c in CSV_COLUMNS})
        return empty
    
    # ‚úÖ –ß–∏—Ç–∞–µ–º –ë–ï–ó dtype="string" –∏ —Å—Ä–∞–∑—É –∑–∞–º–µ–Ω—è–µ–º pd.NA
    df = pd.read_csv(path, keep_default_na=True, encoding="utf-8-sig")
    
    # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –∑–∞–º–µ–Ω–∏—Ç—å pd.NA –Ω–∞ np.nan –î–û –ª—é–±—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    df = df.fillna(np.nan)  # –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ —á–µ–º .replace()
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—á–∏—Å—Ç–∫–∞
    for col in df.select_dtypes(include=["object"]).columns:
        df[col] = df[col].replace({"<NA>": np.nan, "NaN": np.nan, "nan": np.nan, "None": np.nan, "": np.nan})
    
    return _coerce_csv_dtypes(df)


def upgrade_csv_schema_if_needed(path: str) -> None:
    if not os.path.exists(path):
        return
    import pandas as pd
    try:
        df = pd.read_csv(path, encoding="utf-8-sig")
    except Exception:
        return
    need_cols = {"p_thr_used","p_thr_src","edge_at_entry","p_meta_raw","p_meta2_raw","p_blend","blend_w","calib_src"}  # ‚Üê NEW
    missing = [c for c in need_cols if c not in df.columns]
    if not missing:
        return
    # –¥–æ–±–∞–≤–∏–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º
    for c in missing:
        if c in ("p_thr_src","calib_src"):
            df[c] = ""
        else:
            df[c] = float("nan")
    # —É–ø–æ—Ä—è–¥–æ—á–∏–º –ø–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ
    cols = [c for c in CSV_COLUMNS if c in df.columns] + [c for c in CSV_COLUMNS if c not in df.columns]
    df = df.reindex(columns=cols)
    df.to_csv(path, index=False, encoding="utf-8-sig")


def _period_return_pct(df: pd.DataFrame, start_ts: int, now_ts: int) -> Optional[float]:
    if df.empty:
        return None
    df = df.sort_values("settled_ts")
    df_in = df[df["settled_ts"] >= start_ts]
    if df_in.empty:
        return None
    before_df = df[df["settled_ts"] < start_ts]
    if not before_df.empty:
        base_cap = float(before_df.iloc[-1]["capital_after"])
    else:
        base_cap = float(df_in.iloc[0]["capital_before"])
    end_cap = float(df.iloc[-1]["capital_after"])
    if base_cap <= 0:
        return None
    return (end_cap - base_cap) / base_cap * 100.0

def compute_extended_stats_from_csv(path: str) -> Dict[str, Any]:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å —Ä–∏—Å–∫-–º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º"""
    df = _read_csv_df(path)
    if df.empty:
        return dict(total=0, wins=0, losses=0, winrate=None, roi_24h=None, roi_7d=None, roi_30d=None,
                   max_dd=None, profit_factor=None, current_streak=None, avg_edge=None,
                   avg_win=None, avg_loss=None, win_loss_ratio=None, sharpe=None,
                   last_trade_ago_min=None, skip_stats=None, gas_efficiency=None)
    
    df = df.dropna(subset=["outcome"])
    df_tr = df[df["outcome"].isin(["win","loss"])]
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    wins = int((df_tr["outcome"] == "win").sum())
    losses = int((df_tr["outcome"] == "loss").sum())
    total = wins + losses
    winrate = (wins / total * 100.0) if total > 0 else None
    
    now_ts = int(time.time())
    roi_24 = _period_return_pct(df, now_ts - 24*3600, now_ts)
    roi_7d = _period_return_pct(df, now_ts - 7*24*3600, now_ts)
    roi_30 = _period_return_pct(df, now_ts - 30*24*3600, now_ts)
    
    # === –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò ===
    
    # 1. Max Drawdown
    max_dd = None
    dd_peak = None
    dd_trough = None
    try:
        caps = pd.to_numeric(df_tr["capital_after"], errors="coerce").dropna()
        if len(caps) > 0:
            peak = caps.iloc[0]
            max_drawdown = 0.0
            peak_val = peak
            trough_val = peak
            for cap in caps:
                if cap > peak:
                    peak = cap
                    peak_val = cap
                dd = (cap - peak) / peak if peak > 0 else 0.0
                if dd < max_drawdown:
                    max_drawdown = dd
                    trough_val = cap
            max_dd = max_drawdown * 100.0
            dd_peak = float(peak_val)
            dd_trough = float(trough_val)
    except Exception:
        pass
    
    # 2. Profit Factor
    profit_factor = None
    try:
        pnls = pd.to_numeric(df_tr["pnl"], errors="coerce").dropna()
        wins_sum = pnls[pnls > 0].sum()
        losses_sum = abs(pnls[pnls < 0].sum())
        if losses_sum > 0:
            profit_factor = wins_sum / losses_sum
    except Exception:
        pass
    
    # 3. Current Streak
    current_streak = None
    try:
        outcomes = df_tr["outcome"].tail(20).tolist()
        if outcomes:
            last = outcomes[-1]
            count = 1
            for i in range(len(outcomes)-2, -1, -1):
                if outcomes[i] == last:
                    count += 1
                else:
                    break
            current_streak = f"{count}{'W' if last == 'win' else 'L'}"
    except Exception:
        pass
    
    # 4. Average Edge
    avg_edge = None
    edge_realized = None
    try:
        edges = pd.to_numeric(df_tr["edge_at_entry"], errors="coerce").dropna()
        if len(edges) > 0:
            avg_edge = float(edges.mean())
            # –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π edge = —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –≤–∏–Ω—Ä–µ–π—Ç vs –æ–∂–∏–¥–∞–µ–º—ã–π
            if winrate is not None and len(edges) > 0:
                expected_wr = (edges.mean() + 0.5) * 100  # –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞
                edge_realized = winrate - expected_wr
    except Exception:
        pass
    
    # 5. Avg Win/Loss
    avg_win = None
    avg_loss = None
    win_loss_ratio = None
    try:
        pnls = pd.to_numeric(df_tr["pnl"], errors="coerce").dropna()
        wins_pnl = pnls[pnls > 0]
        losses_pnl = pnls[pnls < 0]
        if len(wins_pnl) > 0:
            avg_win = float(wins_pnl.mean())
        if len(losses_pnl) > 0:
            avg_loss = float(losses_pnl.mean())
        if avg_win and avg_loss and avg_loss != 0:
            win_loss_ratio = avg_win / abs(avg_loss)
    except Exception:
        pass
    
    # 6. Sharpe Ratio (24h, annualized)
    sharpe = None
    try:
        df_24h = df_tr[pd.to_numeric(df_tr["settled_ts"], errors="coerce") >= (now_ts - 24*3600)]
        if len(df_24h) >= 10:
            pnls = pd.to_numeric(df_24h["pnl"], errors="coerce").dropna()
            caps = pd.to_numeric(df_24h["capital_before"], errors="coerce").dropna()
            if len(pnls) > 0 and len(caps) > 0:
                returns = (pnls / caps).dropna()
                if len(returns) >= 10 and returns.std() > 0:
                    # –ê–Ω–Ω—É–∞–ª–∏–∑–∞—Ü–∏—è: ‚àö(365*24*60/5) –¥–ª—è 5-–º–∏–Ω—É—Ç–Ω—ã—Ö —Ä–∞—É–Ω–¥–æ–≤
                    periods_per_year = 365 * 24 * 60 / 5
                    sharpe = (returns.mean() / returns.std()) * np.sqrt(periods_per_year)
    except Exception:
        pass
    
    # 7. Last Trade Time
    last_trade_ago_min = None
    try:
        last_ts = pd.to_numeric(df_tr["settled_ts"], errors="coerce").dropna().iloc[-1]
        last_trade_ago_min = (now_ts - last_ts) / 60.0
    except Exception:
        pass
    
    # 8. Skip Statistics
    skip_stats = None
    try:
        all_rows = df.copy()
        skipped = all_rows[all_rows["outcome"].isin(["skipped"])]
        total_epochs = len(all_rows)
        skip_count = len(skipped)
        if total_epochs > 0:
            skip_rate = skip_count / total_epochs * 100
            skip_stats = {
                "total": skip_count,
                "rate": skip_rate,
                "reasons": {}
            }
            # –ü–æ–¥—Å—á—ë—Ç –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ reason)
            # –≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ CSV, –ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å—Ç–∏–º –¥–µ—Ç–∞–ª–∏
    except Exception:
        pass
    
    # 9. Gas Efficiency
    gas_efficiency = None
    try:
        gas_bet = pd.to_numeric(df_tr["gas_bet_bnb"], errors="coerce").dropna()
        gas_claim = pd.to_numeric(df_tr["gas_claim_bnb"], errors="coerce").dropna()
        stakes = pd.to_numeric(df_tr["stake"], errors="coerce").dropna()
        if len(gas_bet) > 0 and len(stakes) > 0:
            total_gas = (gas_bet + gas_claim).mean()
            avg_stake = stakes.mean()
            if avg_stake > 0:
                gas_efficiency = {
                    "avg_gas": float(total_gas),
                    "gas_stake_ratio": float(total_gas / avg_stake * 100)
                }
    except Exception:
        pass
    
    return dict(
        total=total, wins=wins, losses=losses, winrate=winrate,
        roi_24h=roi_24, roi_7d=roi_7d, roi_30d=roi_30,
        max_dd=max_dd, dd_peak=dd_peak, dd_trough=dd_trough,
        profit_factor=profit_factor,
        current_streak=current_streak,
        avg_edge=avg_edge, edge_realized=edge_realized,
        avg_win=avg_win, avg_loss=avg_loss, win_loss_ratio=win_loss_ratio,
        sharpe=sharpe,
        last_trade_ago_min=last_trade_ago_min,
        skip_stats=skip_stats,
        gas_efficiency=gas_efficiency
    )


def compute_stats_from_csv(path: str) -> Dict[str, Optional[float]]:
    df = _read_csv_df(path)
    if df.empty:
        return dict(total=0, wins=0, losses=0, winrate=None, roi_24h=None, roi_7d=None, roi_30d=None)
    df = df.dropna(subset=["outcome"])
    df_tr = df[df["outcome"].isin(["win","loss"])]
    wins = int((df_tr["outcome"] == "win").sum())
    losses = int((df_tr["outcome"] == "loss").sum())
    total = wins + losses
    winrate = (wins / total * 100.0) if total > 0 else None

    now_ts = int(time.time())
    roi_24 = _period_return_pct(df, now_ts - 24*3600, now_ts)
    roi_7d = _period_return_pct(df, now_ts - 7*24*3600, now_ts)
    roi_30 = _period_return_pct(df, now_ts - 30*24*3600, now_ts)

    return dict(total=total, wins=wins, losses=losses, winrate=winrate, roi_24h=roi_24, roi_7d=roi_7d, roi_30d=roi_30)

def print_stats(stats: Dict[str, Optional[float]]):
    wr = "‚Äî" if stats["winrate"] is None else f"{stats['winrate']:.2f}%"
    r24 = "‚Äî" if stats["roi_24h"] is None else f"{stats['roi_24h']:.2f}%"
    r7  = "‚Äî" if stats["roi_7d"]  is None else f"{stats['roi_7d']:.2f}%"
    r30 = "‚Äî" if stats["roi_30d"] is None else f"{stats['roi_30d']:.2f}%"
    print(f"[stats] trades={stats['total']}  wins={stats['wins']}  losses={stats['losses']}  winrate={wr}  "
          f"ROI: 24h={r24} | 7d={r7} | 30d={r30}")

def last3_ev_estimates(path: str) -> Tuple[Optional[float], Optional[float], Optional[float]]:
    df = _read_csv_df(path)
    if df.empty:
        return None, None, None
    df = df.dropna(subset=["outcome"]).sort_values("settled_ts")
    df = df[df["outcome"].isin(["win","loss","draw"])]
    tail = df.tail(3)
    r_vals = pd.to_numeric(tail.get("payout_ratio", pd.Series(dtype=float)), errors="coerce").dropna().values
    gb_vals = pd.to_numeric(tail.get("gas_bet_bnb", pd.Series(dtype=float)), errors="coerce").dropna().values
    gc_vals = pd.to_numeric(tail.get("gas_claim_bnb", pd.Series(dtype=float)), errors="coerce").dropna().values
    r_med = float(np.median(r_vals)) if len(r_vals) else None
    gb_med = float(np.median(gb_vals)) if len(gb_vals) else None
    gc_med = float(np.median(gc_vals)) if len(gc_vals) else None
    return r_med, gb_med, gc_med


def r_ewma_by_side(path: str, side_up: bool, alpha: float = 0.25,
                   max_epoch_exclusive: Optional[int] = None) -> Optional[float]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ rÃÇ –±–µ–∑ –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è: EWMA(Œª=alpha) –ø–æ payout_ratio –ø—Ä–æ—à–ª—ã—Ö —Å–µ—Ç—Ç–ª–æ–≤ –Ω–∞ –Ω—É–∂–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ.
    """
    df = _read_csv_df(path)
    if df.empty:
        return None
    df = df.dropna(subset=["outcome"]).sort_values("settled_ts")
    df = df[df["outcome"].isin(["win","loss","draw"])]
    if max_epoch_exclusive is not None and "epoch" in df.columns:
        try:
            df = df[df["epoch"] < int(max_epoch_exclusive)]
        except Exception:
            pass
    if df.empty:
        return None
    side_series = df.get("side", pd.Series(dtype="string")).astype(str).str.upper()
    df = df[side_series == ("UP" if side_up else "DOWN")]
    if df.empty:
        return None
    r = pd.to_numeric(df.get("payout_ratio", pd.Series(dtype=float)), errors="coerce").dropna()
    if r.empty:
        return None
    # EWMA —Å alpha=Œª (adjust=False, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥–ª—è–¥—ã–≤–∞—Ç—å –Ω–∞–∑–∞–¥ ¬´–ø–æ-—Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏¬ª)
    ew = r.ewm(alpha=float(alpha), adjust=False).mean()
    val = float(ew.iloc[-1])
    if not np.isfinite(val) or val <= 1.0:
        return None
    return val


def r_tod_percentile(path: str, side_up: bool, hour_utc: Optional[int] = None, q: float = 0.50,
                     max_epoch_exclusive: Optional[int] = None) -> Optional[float]:
    """
    –ë—ç–∫–∞–ø-–æ—Ü–µ–Ω–∫–∞ rÃÇ: –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å payout_ratio –ø–æ —Ç–µ–∫—É—â–µ–º—É —á–∞—Å—É —Å—É—Ç–æ–∫ (UTC) –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ.
    –ï—Å–ª–∏ –≤—ã–±–æ—Ä–∫–∞ —á–∞—Å–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞, –±–µ—Ä—ë–º –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –ø–æ –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏.
    """
    df = _read_csv_df(path)
    if df.empty:
        return None
    df = df.dropna(subset=["outcome"]).sort_values("settled_ts")
    df = df[df["outcome"].isin(["win","loss","draw"])]
    if max_epoch_exclusive is not None and "epoch" in df.columns:
        try:
            df = df[df["epoch"] < int(max_epoch_exclusive)]
        except Exception:
            pass
    if df.empty:
        return None
    side_series = df.get("side", pd.Series(dtype="string")).astype(str).str.upper()
    df = df[side_series == ("UP" if side_up else "DOWN")]
    if df.empty:
        return None

    ts_col = None
    for c in ["lock_ts", "open_ts", "settled_ts"]:
        if c in df.columns:
            ts_col = c
            break
    if ts_col is None:
        return None

    ts = pd.to_numeric(df[ts_col], errors="coerce")
    df = df.assign(_ts=ts)
    df = df[np.isfinite(df["_ts"])]
    if df.empty:
        return None

    hours = pd.to_datetime(df["_ts"], unit="s", utc=True).dt.hour
    df = df.assign(_hour=hours)

    if hour_utc is None:
        try:
            hour_utc = int(pd.Timestamp.utcnow().hour)
        except Exception:
            hour_utc = 0

    same_hour = df[df["_hour"] == int(hour_utc)]
    r_ser = pd.to_numeric(same_hour.get("payout_ratio", pd.Series(dtype=float)), errors="coerce").dropna()
    if r_ser.size < 5:
        r_ser = pd.to_numeric(df.get("payout_ratio", pd.Series(dtype=float)), errors="coerce").dropna()
    if r_ser.empty:
        return None

    q = float(min(max(q, 0.0), 1.0))
    val = float(np.quantile(r_ser.to_numpy(), q))
    if not np.isfinite(val) or val <= 1.0:
        return None
    return val


def rolling_winrate_laplace(path: str, n: int = 50, max_epoch_exclusive: Optional[int] = None) -> Optional[float]:
    """
    Laplace-—Å–≥–ª–∞–∂—ë–Ω–Ω—ã–π –≤–∏–Ω—Ä–µ–π—Ç –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º n –∑–∞–∫—Ä—ã—Ç—ã–º —Å–¥–µ–ª–∫–∞–º –î–û —Ç–µ–∫—É—â–µ–≥–æ —Ä–∞—É–Ω–¥–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ [0,1] –∏–ª–∏ None, –µ—Å–ª–∏ –≤—ã–±–æ—Ä–∫–∞ –ø—É—Å—Ç–∞.
    """
    df = _read_csv_df(path)
    if df.empty:
        return None
    df = df.dropna(subset=["outcome"]).sort_values("settled_ts")
    df = df[df["outcome"].isin(["win","loss"])]
    if max_epoch_exclusive is not None and "epoch" in df.columns:
        try:
            df = df[df["epoch"] < int(max_epoch_exclusive)]
        except Exception:
            pass
    if df.empty:
        return None
    tail = df.tail(int(n))
    wins = int((tail["outcome"] == "win").sum())
    total = int(len(tail))
    if total <= 0:
        return None
    # Laplace smoothing: (wins + 1) / (total + 2)
    return (wins + 1.0) / (total + 2.0)

# –ù–û–í–û–ï: –º–∞—Å—à—Ç–∞–± –≤ –ø—Ä–æ—Å–∞–¥–∫–µ ‚Äî f ‚Üê f * max(0.25, 1 - DD/0.30)
def _dd_scale_factor(path: str) -> float:
    try:
        df = _read_csv_df(path)
    except Exception:
        return 1.0
    if df.empty:
        return 1.0
    df = df.sort_values("settled_ts")
    eq = pd.to_numeric(df.get("capital_after", pd.Series(dtype=float)), errors="coerce").dropna().to_numpy()
    if eq.size == 0:
        return 1.0
    peak = float(np.nanmax(eq))
    last = float(eq[-1])
    if peak <= 0:
        return 1.0
    dd = max(0.0, (peak - last) / peak)
    return float(max(0.25, 1.0 - dd / 0.30))


def implied_payout_ratio(side_up: bool, rd: RoundInfo, fee: float = TREASURY_FEE) -> Optional[float]:
    total = float(rd.bull_amount + rd.bear_amount)
    side_amt = float(rd.bull_amount if side_up else rd.bear_amount)
    if side_amt <= 0.0 or total <= 0.0:
        return None
    return (total / side_amt) * (1.0 - fee)


# === KPI: —á–∏—Å–ª–æ –∑–∞–∫—Ä—ã—Ç—ã—Ö –∏ ¬´—Ç–∏—à–∏–Ω–∞¬ª 1—á ===
def settled_trades_count(path: str) -> int:
    df = _read_csv_df(path)
    if df.empty:
        return 0
    df = df.dropna(subset=["outcome"])
    df = df[df["outcome"].isin(["win","loss","draw"])]
    return int(len(df))

def had_trade_in_last_hours(path: str, hours: float = 1.0) -> bool:
    df = _read_csv_df(path)
    if df.empty:
        return False
    df = df.dropna(subset=["outcome"])
    df = df[df["outcome"].isin(["win","loss","draw"])]
    if df.empty:
        return False
    now_ts = int(time.time())
    cutoff = now_ts - int(hours * 3600)
    ts = pd.to_numeric(df.get("settled_ts", pd.Series(dtype=float)), errors="coerce").dropna()
    return bool((ts >= cutoff).any())

def count_trades_last_hour(path: str, hours: float = 1.0) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å."""
    df = _read_csv_df(path)
    if df.empty:
        return 0
    df = df.dropna(subset=["outcome"])
    df = df[df["outcome"].isin(["win","loss","draw"])]
    if df.empty:
        return 0
    now_ts = int(time.time())
    cutoff = now_ts - int(hours * 3600)
    ts = pd.to_numeric(df.get("settled_ts", pd.Series(dtype=float)), errors="coerce").dropna()
    return int((ts >= cutoff).sum())

# =============================
# –ü–ï–†–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–¨ –ö–ê–ü–ò–¢–ê–õ–ê
# =============================
def _restore_capital_from_csv(path: str) -> Optional[float]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç capital_after –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ CSV.
    –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–π ‚Äî –ø—ã—Ç–∞–µ—Ç—Å—è –≤–∑—è—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é capital_before.
    –ï—Å–ª–∏ CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/–ø—É—Å—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None.
    """
    try:
        df = _read_csv_df(path)
        if df.empty:
            return None
        # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å outcome –∏ capital_after
        df2 = df.dropna(subset=["outcome", "capital_after"])
        df2 = df2[df2["outcome"].isin(["win","loss","draw"])]
        if not df2.empty:
            cap = float(df2.iloc[-1]["capital_after"])
            if math.isfinite(cap) and cap > 0:
                return cap
        # –§–æ–ª–±—ç–∫ ‚Äî capital_before
        df3 = df.dropna(subset=["capital_before"])
        if not df3.empty:
            cap = float(df3.iloc[-1]["capital_before"])
            if math.isfinite(cap) and cap > 0:
                return cap
        return None
    except Exception as e:
        get_logger().warning("failed to restore capital from CSV", exc_info=True)
        return None


class CapitalState:
    def __init__(self, path: str = "capital_state.json"):
        self.path = path

    def load(self, default: float) -> float:
        try:
            with open(self.path, "r") as f:
                obj = json.load(f)
            cap = float(obj.get("capital", default))
            if not math.isfinite(cap) or cap <= 0:
                return default
            return cap
        except Exception:
            return default

    def save(self, capital: float, ts: Optional[int] = None) -> None:
        try:
            obj = {"capital": float(capital), "ts": int(ts or time.time())}
            with open(self.path, "w") as f:
                json.dump(obj, f)
        except Exception as e:
            get_logger().error("failed to save capital_state", exc_info=True)



# =============================
# Telegram
def tg_enabled() -> bool:
    # –≤–∫–ª—é—á–µ–Ω–æ + –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã (–∏–∑ ENV –∏–ª–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç)
    has_token = bool((TG_TOKEN if 'TG_TOKEN' in globals() else '') or
                     (TELEGRAM_BOT_TOKEN if 'TELEGRAM_BOT_TOKEN' in globals() else ''))
    has_chat  = bool((TG_CHAT_ID if 'TG_CHAT_ID' in globals() else 0) or
                     (TELEGRAM_CHAT_ID if 'TELEGRAM_CHAT_ID' in globals() else ''))
    return bool(TELEGRAM_ENABLED and has_token and has_chat)



# --- Telegram helpers ---
def _html_safe_allow_basic(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤—Å—ë, –Ω–æ —Ä–∞–∑—Ä–µ—à–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç—ã –º–æ–∂–µ—à—å –æ—Å—Ç–∞–≤–∏—Ç—å –≤ —à–∞–±–ª–æ–Ω–µ:
    <b>, </b>, <i>, </i>, <code>, </code>, <pre>, </pre>.
    –í–ê–ñ–ù–û: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (—á–∏—Å–ª–∞, –º–∞—Å—Å–∏–≤—ã) –≤—Å—Ç–∞–≤–ª—è–π "—Å—ã—Ä—ã–º–∏" ‚Äî —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏—Ö —ç–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç.
    """
    s = escape(text, quote=False)  # –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç &, <, > –≤ —Å—É—â–Ω–æ—Å—Ç–∏
    # –†–∞–∑—Ä–µ—à–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ç–µ–≥–∏ –æ–±—Ä–∞—Ç–Ω–æ (–µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –≤ —à–∞–±–ª–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ —Å—Ç—Ä–æ–∫–∏)
    allow = {
        "&lt;b&gt;": "<b>", "&lt;/b&gt;": "</b>",
        "&lt;i&gt;": "<i>", "&lt;/i&gt;": "</i>",
        "&lt;code&gt;": "<code>", "&lt;/code&gt;": "</code>",
        "&lt;pre&gt;": "<pre>", "&lt;/pre&gt;": "</pre>",
    }
    for k, v in allow.items():
        s = s.replace(k, v)
    return s

def tg_send(text: str, html: bool = True, **kwargs) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ TG. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é HTML-—Ä–µ–∂–∏–º —Å –∞–≤—Ç–æ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True/False, –Ω–µ –±—Ä–æ—Å–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏—è (—á—Ç–æ–±—ã –Ω–µ —Ä–æ–Ω—è—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª).
    """
    global _TG_FAILS, _TG_MUTED_UNTIL, _TG_LAST_ERR
    # --- –º–æ—Å—Ç: –±–µ—Ä—ë–º —Ç–æ–∫–µ–Ω/—á–∞—Ç –ª–∏–±–æ –∏–∑ ENV (TG_*), –ª–∏–±–æ –∏–∑ –∫–æ–Ω—Å—Ç–∞–Ω—Ç (TELEGRAM_*) ---
    token = (TG_TOKEN.strip() if 'TG_TOKEN' in globals() and TG_TOKEN else
             (TELEGRAM_BOT_TOKEN.strip() if 'TELEGRAM_BOT_TOKEN' in globals() and TELEGRAM_BOT_TOKEN else ""))
    chat_id = (TG_CHAT_ID if 'TG_CHAT_ID' in globals() and TG_CHAT_ID else
               (int(str(TELEGRAM_CHAT_ID).strip()) if 'TELEGRAM_CHAT_ID' in globals() and TELEGRAM_CHAT_ID else 0))

    # —Ä–∞–Ω–Ω–∏–π –≤—ã—Ö–æ–¥: –¢–µ–ª–µ–≥–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞ –∏–ª–∏ –Ω–µ—Ç —Ç–æ–∫–µ–Ω–∞/—á–∞—Ç–∞
    if not TELEGRAM_ENABLED or not token or not chat_id:
        return False

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    now = time.time()

    # cooldown/half-open –≤–º–µ—Å—Ç–æ –≤–µ—á–Ω–æ–≥–æ mute
    if _TG_FAILS >= TG_MUTE_AFTER:
        if now < _TG_MUTED_UNTIL:
            print(f"[tg ] muted; until {time.strftime('%H:%M:%S', time.localtime(_TG_MUTED_UNTIL))} ({_TG_LAST_ERR})")
            return False
        # half-open: —Ä–∞–∑—Ä–µ—à–∞–µ–º –æ–¥–Ω—É –ø—Ä–æ–±—É

    try:
        if html:
            payload = {
                "chat_id": chat_id,  # ‚Üê –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π chat_id
                "text": _html_safe_allow_basic(text),
                "parse_mode": "HTML",
                "disable_web_page_preview": True,
            }
        else:
            payload = {
                "chat_id": chat_id,  # ‚Üê –∏ –∑–¥–µ—Å—å —Ç–æ–∂–µ
                "text": text,
                "disable_web_page_preview": True,
            }

        r = SESSION.post(url, json=payload, timeout=(3.05, 5))
        if r.status_code == 400 and html:
            payload.pop("parse_mode", None)
            payload["text"] = text
            r = SESSION.post(url, json=payload, timeout=(3.05, 5))
        if r.status_code >= 400:
            try:
                desc = r.json().get("description", r.text)
            except Exception:
                desc = r.text
            raise RequestException(f"{r.status_code} {desc}")
        _TG_FAILS = 0
        _TG_MUTED_UNTIL = 0.0
        _TG_LAST_ERR = ""
        return True


    except RequestException as e:
        _TG_FAILS += 1
        _TG_LAST_ERR = str(e)
        if _TG_FAILS >= TG_MUTE_AFTER:
            _TG_MUTED_UNTIL = time.time() + TG_COOLDOWN_S
            print(f"[tg ] muted after {_TG_FAILS} fails for {TG_COOLDOWN_S}s ({_TG_LAST_ERR})")
            return False
        else:
            print(f"[tg ] send failed ({_TG_FAILS}/{TG_MUTE_AFTER}): {_TG_LAST_ERR}")
        return False



# --- TG utils: HTML escape + —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ –¥–ª—è 4096-–ª–∏–º–∏—Ç–∞
def _tg_html_escape(s: str) -> str:
    if s is None: return ""
    # –ú–∏–Ω–∏–º—É–º: &, <, >. –ö–∞–≤—ã—á–∫–∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è <pre><code>
    return s.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")

def tg_send_chunks(text: str, chat_id: str = TELEGRAM_CHAT_ID, parse_mode: str = "HTML"):
    """
    –î—Ä–æ–±–∏—Ç –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è < 4096 —Å–∏–º–≤–æ–ª–æ–≤ –∏ —à–ª—ë—Ç –ø–æ —á–∞—Å—Ç—è–º.
    """
    if not TELEGRAM_ENABLED:
        return
    MAX = 4000  # –∑–∞–ø–∞—Å –æ—Ç 4096 –∏–∑-–∑–∞ HTML-—ç–Ω—Ç–∏—Ç–∏
    parts = [text[i:i+MAX] for i in range(0, len(text), MAX)] or [text]
    for idx, part in enumerate(parts, 1):
        suffix = f" ({idx}/{len(parts)})" if len(parts) > 1 else ""
        try:
            tg_send(part + suffix, html=(str(parse_mode).upper() == "HTML"))
        except Exception as e:
            # –Ω–µ –≤–∞–ª–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∏–∑-–∑–∞ —Ç–µ–ª–µ–≥–∏
            print(f"[tg ] send failed: {e}")
            continue

def notify_ev_decision(title: str,
                       epoch: int,
                       side_txt: str,
                       p_side: float,
                       p_thr: float,
                       p_thr_src: str,
                       r_hat: float,
                       gb_hat: float,
                       gc_hat: float,
                       stake: float,
                       delta15: float = None,
                       extra_lines: list = None,
                       delta_eff: float | None = None):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Å –ø–æ–ª–Ω—ã–º —Ä–∞–∑–±–æ—Ä–æ–º –ø–æ—Ä–æ–≥–∞.
    """
    try:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        d = _as_float(DELTA_PROTECT if (delta_eff is None) else delta_eff, 0.0)
        p_side = _as_float(p_side, 0.5)
        p_thr = _as_float(p_thr, 0.5)
        r_hat = _as_float(r_hat, 1.9)
        gb_hat = _as_float(gb_hat, 0.0)
        gc_hat = _as_float(gc_hat, 0.0)
        stake = _as_float(stake, 0.0)

        head = f"<b>{_tg_html_escape(str(title))}</b> ‚Äî epoch <code>{int(epoch)}</code>\n"
        lines = [
            f"side:       {str(side_txt)}",
            f"p_side:     {p_side:.4f}",
            f"p_thr:      {p_thr:.4f}  [{str(p_thr_src)}]",
            f"p_thr+Œ¥:    {(p_thr + d):.4f}  (Œ¥={d:.2f})",
            f"edge:       {p_side - (p_thr + d):+.4f}",
            f"r_hat:      {r_hat:.6f}",
            f"gb_hat:     {gb_hat:.8f}  (BNB)",
            f"gc_hat:     {gc_hat:.8f}  (BNB)",
            f"S (stake):  {stake:.6f}    (BNB)",
        ]
        
        if USE_STRESS_R15 and delta15 is not None:
            _d = _as_float(delta15, 0.0)
            if _d > 1e6:
                _d /= 1e18
            if math.isfinite(_d):
                lines.append(f"Œî15_med:   {_d:.6f}  (BNB)")

        if extra_lines:
            for x in extra_lines:
                if x:
                    lines.append(str(x))

        block = "<pre><code>" + _tg_html_escape("\n".join(lines)) + "</code></pre>"
        tg_send_chunks(head + block, parse_mode="HTML")
    except Exception as e:
        print(f"[tg ] notify_ev_decision failed: {e}")


def _fmt_pct(x: Optional[float]) -> str:
    if x is None or not isinstance(x, (float, int)) or not math.isfinite(float(x)):
        return "‚Äî"
    return f"{x:.2f}%"

def _period_winrate(df: pd.DataFrame, start_ts: int, end_ts: int) -> Optional[float]:
    sub = df[(df["settled_ts"] >= start_ts) & (df["settled_ts"] < end_ts)]
    sub = sub[sub["outcome"].isin(["win","loss"])]
    n = len(sub)
    if n == 0:
        return None
    wins = int((sub["outcome"] == "win").sum())
    return wins / n * 100.0

def winrate_explanation(path: str) -> str:
    df = _read_csv_df(path)
    if df.empty:
        return "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ: –¥–∞–Ω–Ω—ã—Ö –µ—â—ë –Ω–µ—Ç."
    now_ts = int(time.time())
    last24 = _period_winrate(df, now_ts - 24*3600, now_ts)
    prev24 = _period_winrate(df, now_ts - 48*3600, now_ts - 24*3600)
    note_parts = []
    if last24 is None:
        return "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ: –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24—á –Ω–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö —Å–¥–µ–ª–æ–∫."
    if prev24 is None:
        note_parts.append("–ë–∞–∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—É—Å—Ç–∞—è ‚Äî —Å–º–æ—Ç—Ä–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–µ 24—á.")
        prev24 = last24
    diff = last24 - prev24
    direction = "–≤—ã—Ä–æ—Å" if diff > 0 else ("—É–ø–∞–ª" if diff < 0 else "–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
    note_parts.append(f"–í–∏–Ω—Ä–µ–π—Ç {direction} –Ω–∞ {abs(diff):.2f} –ø.–ø. (—Ç–µ–∫—É—â–∏–µ 24—á: {last24:.2f}%, –ø—Ä–µ–¥—ã–¥—É—â–∏–µ 24—á: {prev24:.2f}%).")
    def _avg(series):
        s = pd.to_numeric(series, errors="coerce").dropna()
        return float(s.mean()) if len(s) else None
    cur_df = df[(df["settled_ts"] >= now_ts - 24*3600) & (df["outcome"].isin(["win","loss"]))]
    prv_df = df[(df["settled_ts"] >= now_ts - 48*3600) & (df["settled_ts"] < now_ts - 24*3600) & (df["outcome"].isin(["win","loss"]))]
    avg_p_cur = _avg(cur_df.get("p_up", pd.Series(dtype=float)))
    avg_p_prv = _avg(prv_df.get("p_up", pd.Series(dtype=float)))
    med_r_cur = pd.to_numeric(cur_df.get("payout_ratio", pd.Series(dtype=float)), errors="coerce").dropna()
    med_r_cur = float(np.median(med_r_cur)) if len(med_r_cur) else None
    med_r_prv = pd.to_numeric(prv_df.get("payout_ratio", pd.Series(dtype=float)), errors="coerce").dropna()
    med_r_prv = float(np.median(med_r_prv)) if len(med_r_prv) else None
    n_cur = len(cur_df)
    if avg_p_cur is not None and avg_p_prv is not None and abs(avg_p_cur - avg_p_prv) >= 0.01:
        note_parts.append(f"–°—Ä–µ–¥–Ω—è—è p_up –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –Ω–∞ {avg_p_cur-avg_p_prv:+.3f} (–±—ã–ª–æ {avg_p_prv:.3f} ‚Üí —Å—Ç–∞–ª–æ {avg_p_cur:.3f}).")
    if med_r_cur is not None and med_r_prv is not None and abs(med_r_cur - med_r_prv) >= 0.02:
        note_parts.append(f"–ú–µ–¥–∏–∞–Ω–Ω—ã–π payout –∏–∑–º–µ–Ω–∏–ª—Å—è –Ω–∞ {med_r_cur-med_r_prv:+.2f} (–±—ã–ª–æ {med_r_prv:.2f} ‚Üí —Å—Ç–∞–ª–æ {med_r_cur:.2f}).")
    if n_cur < 10:
        note_parts.append(f"–í—ã–±–æ—Ä–∫–∞ –∑–∞ 24—á –º–∞–ª–∞ (n={n_cur}), –≤–æ–∑–º–æ–∂–µ–Ω —à—É–º.")
    return " ".join(note_parts)

def build_stats_message(stats: Dict[str, Optional[float]]) -> str:
    wr = "‚Äî" if stats["winrate"] is None else f"{stats['winrate']:.2f}%"
    r24 = "‚Äî" if stats["roi_24h"] is None else f"{stats['roi_24h']:.2f}%"
    r7  = "‚Äî" if stats["roi_7d"]  is None else f"{stats['roi_7d']:.2f}%"
    r30 = "‚Äî" if stats["roi_30d"] is None else f"{stats['roi_30d']:.2f}%"
    wins = stats.get("wins", 0)
    losses = stats.get("losses", 0)
    total = stats.get("total", 0)

    # Reserve balance
    try:
        from reserve_fund import ReserveFund
        _reserve_path = os.path.join(os.path.dirname(__file__), "reserve_state.json")
        _rf = ReserveFund(path=_reserve_path)
        reserve_line = f"Reserve: <b>{_rf.balance:.6f} BNB</b>\n"
    except Exception:
        reserve_line = ""
    
    # rÃÇ accuracy
    r_hat_line = ""
    try:
        from r_hat_improved import analyze_r_hat_accuracy
        acc = analyze_r_hat_accuracy(CSV_PATH, n=200)
        if acc and acc.get("n_samples", 0) >= 20:
            mae = acc["mae_pct"]
            bias = acc["bias_pct"]
            n = acc["n_samples"]
            r_hat_line = f"rÃÇ accuracy: MAE={mae:.1f}%, bias={bias:+.1f}% (n={n})\n"
    except Exception:
        pass
    
    # === –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò ===
    
    # Max Drawdown
    dd_line = ""
    if stats.get("max_dd") is not None:
        dd = stats["max_dd"]
        peak = stats.get("dd_peak", 0)
        trough = stats.get("dd_trough", 0)
        dd_line = f"Max DD: <b>{dd:+.2f}%</b> (peak: {peak:.3f} ‚Üí trough: {trough:.3f})\n"
    
    # Profit Factor & Win/Loss
    pf_line = ""
    if stats.get("profit_factor"):
        pf = stats["profit_factor"]
        pf_line = f"Profit Factor: <b>{pf:.2f}</b>"
        if stats.get("avg_win") and stats.get("avg_loss"):
            avg_w = stats["avg_win"]
            avg_l = stats["avg_loss"]
            wl_ratio = stats.get("win_loss_ratio", 0)
            pf_line += f" | Avg W/L: {avg_w:+.4f} / {avg_l:+.4f} ({wl_ratio:.2f}x)\n"
        else:
            pf_line += "\n"
    
    # Current Streak & Last Trade
    streak_line = ""
    if stats.get("current_streak"):
        streak = stats["current_streak"]
        streak_line = f"Streak: <b>{streak}</b>"
        if stats.get("last_trade_ago_min") is not None:
            ago = stats["last_trade_ago_min"]
            if ago < 60:
                streak_line += f" | Last: {ago:.0f}m ago"
            else:
                streak_line += f" | Last: {ago/60:.1f}h ago"
        streak_line += "\n"
    
    # Average Edge
    edge_line = ""
    if stats.get("avg_edge") is not None:
        edge = stats["avg_edge"]
        edge_line = f"Avg Edge: <b>{edge:+.4f}</b>"
        if stats.get("edge_realized") is not None:
            realized = stats["edge_realized"]
            edge_line += f" (—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: {realized:+.1f} –ø.–ø.)"
        edge_line += "\n"
    
    # Sharpe Ratio
    sharpe_line = ""
    if stats.get("sharpe") is not None:
        sharpe = stats["sharpe"]
        sharpe_line = f"Sharpe (24h): <b>{sharpe:.2f}</b>\n"
    
    # Gas Efficiency
    gas_line = ""
    if stats.get("gas_efficiency"):
        ge = stats["gas_efficiency"]
        gas_line = f"Gas: {ge['avg_gas']:.6f} BNB/trade ({ge['gas_stake_ratio']:.2f}% of stake)\n"
    
    msg = (f"<b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</b>\n"
           f"Trades: {total} | Wins: {wins} | Losses: {losses}\n"
           f"Winrate: <b>{wr}</b>\n"
           f"ROI: 24h={r24} | 7d={r7} | 30d={r30}\n"
           f"{reserve_line}"
           f"{dd_line}"
           f"{pf_line}"
           f"{streak_line}"
           f"{edge_line}"
           f"{sharpe_line}"
           f"{gas_line}"
           f"{r_hat_line}")
    return msg


def send_round_snapshot(prefix: str, extra_lines: List[str]):
    stats_dict = compute_extended_stats_from_csv(CSV_PATH)
    stats_msg = build_stats_message(stats_dict)
    explain = winrate_explanation(CSV_PATH)
    text = f"{prefix}\n" + "\n".join(extra_lines) + "\n\n" + stats_msg + f"<i>{explain}</i>"
    tg_send(text)

# =============================
# ML: –ö–û–ù–§–ò–ì–ò
# =============================
@dataclass
class MLConfig:
    # –æ–±—â–∏–µ –ø–æ—Ä–æ–≥–∏ –≥–µ–π—Ç–∏–Ω–≥–∞ (–∫–∞–∫ –±—ã–ª–æ)
    min_ready: int = 80
    enter_wr: float = 3.0
    exit_wr: float = 1.0
    retrain_every: int = 40
    adwin_delta: float = 0.002
    max_memory: int = 3000          # –ò–ó–ú–ï–ù–ï–ù–û: –±—ã–ª–æ 5000
    train_window: int = 3000        # –ò–ó–ú–ï–ù–ï–ù–û: –±—ã–ª–æ 1500

    # XGB
    xgb_model_path: str = "gb_model.json"
    xgb_scaler_path: str = "gb_scaler.pkl"
    xgb_state_path: str = "gb_state.json"
    xgb_cal_path: str = "gb_cal.pkl"                 # üëà –ù–û–í–û–ï
    xgb_calibration_method: str = "platt"   
    xgb_max_depth: int = 4
    xgb_eta: float = 0.08
    xgb_subsample: float = 0.9
    xgb_colsample_bytree: float = 0.9
    xgb_min_child_weight: int = 2
    xgb_rounds_cold: int = 60
    xgb_rounds_warm: int = 30

    # RF
    rf_model_path: str = "rf_calibrated.pkl"
    rf_state_path: str = "rf_state.json"
    rf_n_estimators: int = 300
    rf_max_depth: Optional[int] = None
    rf_min_samples_leaf: int = 2
    rf_calibration_method: str = "sigmoid"  # 'sigmoid' –∏–ª–∏ 'isotonic'

    # ARF (River)
    arf_state_path: str = "arf_state.json"
    arf_model_path: str = "arf_model.pkl"
    arf_cal_path: str = "arf_cal.pkl"                # üëà –ù–û–í–û–ï
    arf_calibration_method: str = "platt"
    arf_n_models: int = 10
    arf_max_depth: Optional[int] = None

    # NN Expert (MLP)
    nn_state_path: str = "nn_state.json"
    nn_model_path: str = "nn_model.pkl"
    nn_scaler_path: str = "nn_scaler.pkl"
    nn_hidden: int = 16
    nn_eta: float = 0.01
    nn_l2: float = 0.0005
    nn_epochs: int = 30
    nn_retrain_every: int = 40
    nn_calib_every: int = 200

    # META
    meta_state_path: str = "meta_state.json"
    meta_eta: float = 0.05
    meta_l2: float = 0.001
    meta_w_clip: float = 8.0
    meta_g_clip: float = 1.0

    # NEW: –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –≥–µ–π—Ç–∏–Ω–≥
    meta_gating_mode: str = "soft"   # "soft" | "exp4"
    meta_alpha_mix: float = 1.0      # –≤–µ—Å —Å–º–µ—Å–∏ –ª–æ–≥–∏—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    meta_gate_eta: float = 0.02      # —à–∞–≥ –¥–ª—è Wg (soft)
    meta_gate_l2: float = 0.0005     # L2 –¥–ª—è Wg
    meta_gate_clip: float = 5.0      # –∫–ª–∏–ø –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ Wg

    # EXP4 –≤–∞—Ä–∏–∞–Ω—Ç (–ø–æ —Ñ–∞–∑–∞–º)
    meta_exp4_eta: float = 0.10      # —Ç–µ–º–ø –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤ EXP4
    meta_exp4_phases: int = 6        # —á–∏—Å–ª–æ —Ñ–∞–∑ (—Å–º. phase_from_ctx)

    use_two_window_drop: bool = False
# =============================
# ====== –§–ê–ó–û–í–ê–Ø –ü–ê–ú–Ø–¢–¨ / –ö–ê–õ–ò–ë–†–û–í–ö–ê ======
# ====== –§–ê–ó–û–í–ê–Ø –ü–ê–ú–Ø–¢–¨ / –ö–ê–õ–ò–ë–†–û–í–ö–ê ======
    use_phase_memory: bool = True
    phase_count: int = 6
    phase_memory_cap: int = 3000    # –ò–ó–ú–ï–ù–ï–ù–û: –±—ã–ª–æ 10_000
    phase_min_ready: int = 150
    phase_mix_global_share: float = 0.30   # –µ—Å–ª–∏ < phase_min_ready: –¥–æ–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ö–≤–æ—Å—Ç–∞
    phase_hysteresis_s: int = 300     
    meta_use_cma_es: bool = True  # ‚Üê –≤–∫–ª—é—á–∞–µ–º CMA-ES     # –∑–∞–ª–∏–ø–∞–Ω–∏–µ —Ñ–∞–∑—ã (–∞–Ω—Ç–∏-–¥—Ä–æ–∂—å)
    meta_weight_decay_days: float = 30.0  # –ø–µ—Ä–∏–æ–¥ –ø–æ–ª—É—Ä–∞—Å–ø–∞–¥–∞ –¥–ª—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –∑–∞–±—ã–≤–∞–Ω–∏—è (–≤ –¥–Ω—è—Ö)
    phase_state_path: str = "phase_state.json"

    # –¥–ª—è —Ñ–∞–π–ª–æ–≤ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–æ–≤ –ø–æ —Ñ–∞–∑–µ (–±—É–¥–µ–º –∞–ø–µ–ª–ª–∏—Ä–æ–≤–∞—Ç—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –ø—É—Ç—è–º)
    # —É XGB/NN: base_path ‚Üí base_path_ph{œÜ}.pkl
    # Cross-validation parameters
    cv_enabled: bool = True
    cv_n_splits: int = 5              # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤
    cv_embargo_pct: float = 0.02      # 2% gap –º–µ–∂–¥—É train/test
    cv_purge_pct: float = 0.01        # 1% purge –ø–µ—Ä–µ–¥ test
    cv_min_train_size: int = 200      # –º–∏–Ω–∏–º—É–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    cv_bootstrap_n: int = 1000        # –∏—Ç–µ—Ä–∞—Ü–∏–π bootstrap –¥–ª—è CI
    cv_confidence: float = 0.95       # —É—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è (95%)
    cv_min_improvement: float = 0.02  # –º–∏–Ω–∏–º—É–º +2% –¥–ª—è –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
    
    # Validation tracking
    cv_oof_window: int = 500          # –æ–∫–Ω–æ out-of-fold predictions
    cv_check_every: int = 50          # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ N –ø—Ä–∏–º–µ—Ä–æ–≤


# ===== –§–∏–ª—å—Ç—Ä —Ñ–∞–∑—ã —Å –≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å–æ–º =====
class PhaseFilter:
    def __init__(self, hysteresis_s: int = 300):
        self.hysteresis_s = int(max(0, hysteresis_s))
        self.last_phase: Optional[int] = None
        self.last_change_ts: Optional[int] = None

    def update(self, phase_raw: int, now_ts: int) -> int:
        # –ø–µ—Ä–≤—ã–π —Ä–∞–∑ ‚Äî –ø—Ä–∏–Ω—è—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        if self.last_phase is None:
            self.last_phase, self.last_change_ts = int(phase_raw), int(now_ts)
            return self.last_phase
        # –µ—Å–ª–∏ –Ω–æ–≤–∞—è —Ñ–∞–∑–∞ = —Å—Ç–∞—Ä–∞—è ‚Äî –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–∏–º –≤—Ä–µ–º—è
        if int(phase_raw) == int(self.last_phase):
            self.last_change_ts = int(now_ts)
            return self.last_phase
        # –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ –º–∞–ª–æ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî ¬´–∑–∞–ª–∏–ø–∞–µ–º¬ª
        if self.last_change_ts is not None and (now_ts - self.last_change_ts) < self.hysteresis_s:
            return self.last_phase
        # –∏–Ω–∞—á–µ –ø–æ–∑–≤–æ–ª–∏–º —Å–º–µ–Ω–∏—Ç—å—Å—è
        self.last_phase = int(phase_raw)
        self.last_change_ts = int(now_ts)
        return self.last_phase


# –ë–∞–∑–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
# =============================
class _BaseExpert:
    def proba_up(self, x_raw: np.ndarray, reg_ctx: Optional[dict] = None) -> tuple[Optional[float], str]:
        raise NotImplementedError
    def record_result(self, x_raw: np.ndarray, y_up: int, used_in_live: bool, p_pred: Optional[float] = None, reg_ctx: Optional[dict] = None) -> None:
        raise NotImplementedError
    def maybe_train(self, ph: Optional[int] = None, reg_ctx: Optional[dict] = None) -> None:
        pass
    def status(self) -> Dict[str, str]:
        return {"mode":"DISABLED", "wr":"‚Äî", "n":"0", "enabled":"False"}
# =============================

# ---------- XGB ----------
class XGBExpert(_BaseExpert):
    def __init__(self, cfg: MLConfig):
        self.cfg = cfg
        self.enabled = HAVE_XGB
        self.mode = "SHADOW"

        # –º–æ–¥–µ–ª—å XGBoost
        self.booster = None
        # —Å–∫–µ–π–ª–µ—Ä
        self.scaler: Optional[StandardScaler] = None
        # –¥–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–µ–π—Ñ–∞
        self.adwin = ADWIN(delta=self.cfg.adwin_delta) if HAVE_RIVER else None

        # ===== –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å (—Ö–≤–æ—Å—Ç) =====
        self.X: List[List[float]] = []
        self.y: List[int] = []
        self.new_since_train = 0

        # ===== —Ñ–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å =====
        self.P = int(self.cfg.phase_count)  # 6 —Ñ–∞–∑
        self.X_ph: Dict[int, List[List[float]]] = {p: [] for p in range(self.P)}
        self.y_ph: Dict[int, List[int]] = {p: [] for p in range(self.P)}
        self.new_since_train_ph: Dict[int, int] = {p: 0 for p in range(self.P)}
        self._last_seen_phase: int = 0

        # ===== —Ñ–∞–∑–æ–≤—ã–µ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä—ã =====
        self.cal_ph: Dict[int, Optional[_BaseCal]] = {p: None for p in range(self.P)}
        self.cal_global: Optional[_BaseCal] = None  # –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

        # —Ö–∏—Ç—ã/–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        self.shadow_hits: List[int] = []
        self.active_hits: List[int] = []

        # Cross-validation tracking (per phase)
        self.cv_oof_preds: Dict[int, deque] = {p: deque(maxlen=cfg.cv_oof_window) for p in range(self.P)}
        self.cv_oof_labels: Dict[int, deque] = {p: deque(maxlen=cfg.cv_oof_window) for p in range(self.P)}
        self.cv_metrics: Dict[int, Dict] = {p: {} for p in range(self.P)}
        self.cv_last_check: Dict[int, int] = {p: 0 for p in range(self.P)}
        
        # Validation mode tracking
        self.validation_passed: Dict[int, bool] = {p: False for p in range(self.P)}

        self.n_feats: Optional[int] = None

        # –∑–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞ (–≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ) –∏ —Å—Ç–µ–π—Ç–æ–≤
        try:
            self.cal_global = _BaseCal.load(self.cfg.xgb_cal_path)
        except Exception:
            self.cal_global = None

        self._load_all()

        # –≤—Å–ø–æ–º–æ–≥–∞–ª–∫–∞ –¥–ª—è –ø—É—Ç–µ–π —Ñ–∞–∑–æ–≤—ã—Ö –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–æ–≤
        import os as _os
        self._cal_path = lambda base, ph: f"{_os.path.splitext(base)[0]}_ph{ph}{_os.path.splitext(base)[1]}"

        # –ø–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–∑–æ–≤—ã–µ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä—ã
        for p in range(self.P):
            try:
                self.cal_ph[p] = _BaseCal.load(self._cal_path(self.cfg.xgb_cal_path, p))
            except Exception:
                self.cal_ph[p] = None


    def _load_all(self):
        try:
            if os.path.exists(self.cfg.xgb_state_path):
                with open(self.cfg.xgb_state_path, "r") as f:
                    st = json.load(f)

                # –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
                self.mode = st.get("mode", "SHADOW")
                self.shadow_hits = st.get("shadow_hits", [])[-1000:]
                self.active_hits = st.get("active_hits", [])[-1000:]
                self.n_feats = st.get("n_feats", None)

                # üëá –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
                self.X = st.get("X", [])
                self.y = st.get("y", [])

                X_ph = st.get("X_ph", {})
                y_ph = st.get("y_ph", {})
                if isinstance(X_ph, dict) and isinstance(y_ph, dict):
                    self.X_ph = {int(k): v for k, v in X_ph.items()}
                    self.y_ph = {int(k): v for k, v in y_ph.items()}

                # —Å—á—ë—Ç—á–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ —Ñ–∞–∑–∞–º
                self.new_since_train_ph = {p: 0 for p in range(self.P)}
                if isinstance(st.get("new_since_train_ph"), dict):
                    for k, v in st["new_since_train_ph"].items():
                        try:
                            self.new_since_train_ph[int(k)] = int(v)
                        except Exception:
                            pass

                self._last_seen_phase = int(st.get("_last_seen_phase", 0))

                # –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–±—Ä–µ–∑–∫–∏
                mm = getattr(self.cfg, "max_memory", None)
                if isinstance(mm, int) and mm > 0 and len(self.X) > mm:
                    self.X = self.X[-mm:]
                    self.y = self.y[-mm:]

                cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
                for p in range(self.P):
                    if len(self.X_ph.get(p, [])) > cap:
                        self.X_ph[p] = self.X_ph[p][-cap:]
                        self.y_ph[p] = self.y_ph[p][-cap:]
        except Exception:
            pass

        # scaler/booster ‚Äî –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        try:
            if os.path.exists(self.cfg.xgb_scaler_path):
                with open(self.cfg.xgb_scaler_path, "rb") as f:
                    self.scaler = pickle.load(f)
        except Exception:
            self.scaler = None
        try:
            if HAVE_XGB and os.path.exists(self.cfg.xgb_model_path):
                bst = xgb.Booster()
                bst.load_model(self.cfg.xgb_model_path)
                self.booster = bst
        except Exception:
            self.booster = None


    def _save_all(self):
        # --- state (—Ä–µ–∂–∏–º, —Ö–∏—Ç—ã, –ø–∞–º—è—Ç—å) ---
        try:
            # –æ–±—Ä–µ–∑–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ö–≤–æ—Å—Ç–∞
            X_tail, y_tail = self.X, self.y
            mm = getattr(self.cfg, "max_memory", None)
            if isinstance(mm, int) and mm > 0:
                X_tail = self.X[-mm:]
                y_tail = self.y[-mm:]

            # –æ–±—Ä–µ–∑–∫–∞ —Ñ–∞–∑–æ–≤—ã—Ö –±—É—Ñ–µ—Ä–æ–≤
            cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
            X_ph_tail = {p: self.X_ph.get(p, [])[-cap:] for p in range(self.P)}
            y_ph_tail = {p: self.y_ph.get(p, [])[-cap:] for p in range(self.P)}

            st = {
                "mode": self.mode,
                "shadow_hits": self.shadow_hits[-1000:],
                "active_hits": self.active_hits[-1000:],
                "n_feats": self.n_feats,

                # üëá –ø–∞–º—è—Ç—å
                "X": X_tail, "y": y_tail,
                "X_ph": X_ph_tail, "y_ph": y_ph_tail,
                "new_since_train_ph": {int(p): int(self.new_since_train_ph.get(p, 0)) for p in range(self.P)},
                "_last_seen_phase": int(self._last_seen_phase),
                "P": int(self.P),
            }
            with open(self.cfg.xgb_state_path, "w") as f:
                json.dump(st, f)
        except Exception as e:
            print(f"[xgb ] _save_all state error: {e}")

        # --- scaler / booster ---
        try:
            if self.scaler is not None:
                with open(self.cfg.xgb_scaler_path, "wb") as f:
                    pickle.dump(self.scaler, f)
        except Exception:
            pass
        try:
            if HAVE_XGB and self.booster is not None:
                self.booster.save_model(self.cfg.xgb_model_path)
        except Exception:
            pass



    # ---------- —É—Ç–∏–ª–∏—Ç—ã ----------
    def _ensure_dim(self, x_raw: np.ndarray):
        d = int(x_raw.reshape(1, -1).shape[1])
        if self.n_feats is None or self.n_feats != d:
            # —Å–º–µ–Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ ‚Äî —á–∏—Å—Ç–∏–º –≤—Å—ë
            self.n_feats = d
            self.X, self.y = [], []
            self.X_ph = {p: [] for p in range(self.P)}
            self.y_ph = {p: [] for p in range(self.P)}
            self.new_since_train = 0
            self.new_since_train_ph = {p: 0 for p in range(self.P)}
            self._last_seen_phase = 0
            self.booster = None
            self.scaler = None

    def _transform_one(self, x_raw: np.ndarray) -> np.ndarray:
        self._ensure_dim(x_raw)
        xr = x_raw.astype(np.float32).reshape(1, -1)
        if self.scaler is None:
            return xr
        return self.scaler.transform(xr).astype(np.float32)

    def _transform_many(self, X_raw: np.ndarray) -> np.ndarray:
        X_raw = X_raw.astype(np.float32).reshape(-1, self.n_feats or X_raw.shape[1])
        if self.scaler is None:
            return X_raw
        return self.scaler.transform(X_raw).astype(np.float32)

    def _predict_raw(self, x_raw: np.ndarray) -> Optional[float]:
        if not self.enabled or self.booster is None:
            return None
        Xt = self._transform_one(x_raw)
        d = xgb.DMatrix(Xt)
        p = float(self.booster.predict(d)[0])
        return float(min(max(p, 1e-6), 1.0 - 1e-6))

    def _get_global_tail(self, n: int) -> Tuple[np.ndarray, np.ndarray]:
        if n <= 0 or not self.X:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        Xg = np.array(self.X[-n:], dtype=np.float32)
        yg = np.array(self.y[-n:], dtype=np.int32)
        return Xg, yg

    def _get_past_phases_tail(self, ph: int, n: int) -> Tuple[np.ndarray, np.ndarray]:
        # –ë–µ—Ä–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –∑–∞–ø–∏—Å–µ–π —Ç–æ–ª—å–∫–æ –∏–∑ —Ñ–∞–∑ 0..ph (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        # –ò—Å–∫–ª—é—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É–¥—É—â–∏—Ö —Ñ–∞–∑ ‚Üí –Ω–µ—Ç —É—Ç–µ—á–∫–∏
        if n <= 0:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–∑ 0..ph
        X_past = []
        y_past = []
        for p in range(min(ph + 1, self.P)):
            if self.X_ph.get(p):
                X_past.extend(self.X_ph[p])
                y_past.extend(self.y_ph[p])
        
        if not X_past:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –∑–∞–ø–∏—Å–µ–π
        X_past = X_past[-n:]
        y_past = y_past[-n:]
        
        return np.array(X_past, dtype=np.float32), np.array(y_past, dtype=np.int32)


    def _get_phase_train(self, ph: int) -> Tuple[np.ndarray, np.ndarray]:
        # X_phase
        Xp = np.array(self.X_ph[ph], dtype=np.float32) if self.X_ph[ph] else np.empty((0, self.n_feats or 0), dtype=np.float32)
        yp = np.array(self.y_ph[ph], dtype=np.int32)   if self.y_ph[ph]  else np.empty((0,), dtype=np.int32)

        if len(Xp) >= int(self.cfg.phase_min_ready):
            return Xp, yp

        # –∏–Ω–∞—á–µ —Å–º–µ—à–∏–≤–∞–µ–º X_phase ‚à™ X_past_phases_tail (70/30 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ —Ñ–∞–∑—ã (0..ph), –∞ –Ω–µ –≤–µ—Å—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ö–≤–æ—Å—Ç
        share = float(self.cfg.phase_mix_global_share)  # 0.30
        need_g = int(round(len(Xp) * share / max(1e-9, (1.0 - share))))
        need_g = max(need_g, int(self.cfg.phase_min_ready) - len(Xp))   # –Ω–µ –º–µ–Ω–µ–µ, —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å –ø–æ—Ä–æ–≥–∞
        
        # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω–æ –≤ —Ñ–∞–∑–∞—Ö 0..ph
        available_past = sum(len(self.X_ph.get(p, [])) for p in range(min(ph + 1, self.P)))
        need_g = min(need_g, available_past)  # –Ω–µ –±–æ–ª—å—à–µ, —á–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ –≤ –ø—Ä–æ—à–ª—ã—Ö —Ñ–∞–∑–∞—Ö
        
        Xg, yg = self._get_past_phases_tail(ph, need_g)
        if len(Xg) == 0:
            return Xp, yp

        X = np.concatenate([Xp, Xg], axis=0)
        y = np.concatenate([yp, yg], axis=0)
        return X, y

    def _maybe_train_phase(self, ph: int):
        if not self.enabled or self.n_feats is None:
            return
        if self.new_since_train_ph.get(ph, 0) < int(self.cfg.retrain_every):
            return
        X_all, y_all = self._get_phase_train(ph)
        if len(X_all) < int(self.cfg.phase_min_ready):
            return
        if len(X_all) > int(self.cfg.train_window):
            X_all = X_all[-int(self.cfg.train_window):]
            y_all = y_all[-int(self.cfg.train_window):]

        try:
            # –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∫ —Ä–∞–Ω—å—à–µ (global scaler –æ–∫, –Ω–æ –ª—É—á—à–µ –ø–æ –±–∞—Ç—á—É —Ñ–∞–∑—ã)
            self.scaler = StandardScaler().fit(X_all)
            Xt = self.scaler.transform(X_all)
            dtrain = xgb.DMatrix(Xt, label=y_all)

            params = dict(
                objective="binary:logistic",
                eval_metric="logloss",
                eta=getattr(self.cfg, "xgb_eta", 0.1),
                max_depth=getattr(self.cfg, "xgb_max_depth", 4),
                subsample=getattr(self.cfg, "xgb_subsample", 0.9),
                colsample_bytree=getattr(self.cfg, "xgb_colsample_bytree", 0.8),
                min_child_weight=getattr(self.cfg, "xgb_min_child_weight", 1.0),
                tree_method="auto",
            )
            num_round = int(self.cfg.xgb_rounds_cold if (self.booster is None) else self.cfg.xgb_rounds_warm)
            self.booster = xgb.train(params, dtrain, num_boost_round=num_round, xgb_model=self.booster)
            self.new_since_train_ph[ph] = 0
            self._save_all()
        except Exception as e:
            print(f"[xgb ] train error (ph={ph}): {e}")

    def _run_cv_validation(self, ph: int) -> Dict:
        """
        Walk-forward purged cross-validation –¥–ª—è —Ñ–∞–∑—ã ph.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏: accuracy, CI bounds, fold scores.
        """
        X_all, y_all = self._get_phase_train(ph)
        
        if len(X_all) < self.cfg.cv_min_train_size:
            return {"status": "insufficient_data", "oof_accuracy": 0.0}
        
        n_samples = len(X_all)
        n_splits = min(self.cfg.cv_n_splits, n_samples // self.cfg.cv_min_train_size)
        
        if n_splits < 2:
            return {"status": "insufficient_splits", "oof_accuracy": 0.0}
        
        # Walk-forward splits —Å purge –∏ embargo
        embargo_size = max(1, int(n_samples * self.cfg.cv_embargo_pct))
        purge_size = max(1, int(n_samples * self.cfg.cv_purge_pct))
        
        fold_size = n_samples // n_splits
        oof_preds = np.zeros(n_samples)
        oof_mask = np.zeros(n_samples, dtype=bool)
        fold_scores = []
        
        for fold_idx in range(n_splits):
            # Test fold
            test_start = fold_idx * fold_size
            test_end = min(test_start + fold_size, n_samples)
            
            # Train: –≤—Å—ë –¥–æ (test_start - purge_size)
            train_end = max(0, test_start - purge_size)
            
            if train_end < self.cfg.cv_min_train_size:
                continue
            
            X_train = X_all[:train_end]
            y_train = y_all[:train_end]
            X_test = X_all[test_start:test_end]
            y_test = y_all[test_start:test_end]
            
            # –û–±—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ train fold
            temp_model = self._train_fold_model(X_train, y_train, ph)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test fold
            preds = self._predict_fold(temp_model, X_test, ph)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º OOF predictions
            oof_preds[test_start:test_end] = preds
            oof_mask[test_start:test_end] = True
            
            # –ú–µ—Ç—Ä–∏–∫–∏ —Ñ–æ–ª–¥–∞
            fold_acc = np.mean((preds >= 0.5) == y_test)
            fold_scores.append(fold_acc)
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ OOF –º–µ—Ç—Ä–∏–∫–∏
        oof_valid = oof_mask.sum()
        if oof_valid < self.cfg.cv_min_train_size:
            return {"status": "insufficient_oof", "oof_accuracy": 0.0}
        
        oof_accuracy = 100.0 * np.mean((oof_preds[oof_mask] >= 0.5) == y_all[oof_mask])
        
        # Bootstrap confidence intervals
        ci_lower, ci_upper = self._bootstrap_ci(
            oof_preds[oof_mask], 
            y_all[oof_mask],
            n_bootstrap=self.cfg.cv_bootstrap_n,
            confidence=self.cfg.cv_confidence
        )
        
        return {
            "status": "ok",
            "oof_accuracy": oof_accuracy,
            "ci_lower": ci_lower,
            "ci_upper": ci_upper,
            "fold_scores": fold_scores,
            "n_folds": len(fold_scores),
            "oof_samples": int(oof_valid)
        }

    def _bootstrap_ci(self, preds: np.ndarray, labels: np.ndarray, 
                    n_bootstrap: int, confidence: float) -> tuple:
        """
        Bootstrap confidence intervals –¥–ª—è accuracy.
        """
        accuracies = []
        n = len(preds)
        
        for _ in range(n_bootstrap):
            # Resample —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º
            idx = np.random.choice(n, size=n, replace=True)
            boot_preds = preds[idx]
            boot_labels = labels[idx]
            boot_acc = 100.0 * np.mean((boot_preds >= 0.5) == boot_labels)
            accuracies.append(boot_acc)
        
        accuracies = np.array(accuracies)
        alpha = 1.0 - confidence
        ci_lower = np.percentile(accuracies, 100 * alpha / 2)
        ci_upper = np.percentile(accuracies, 100 * (1 - alpha / 2))
        
        return ci_lower, ci_upper

    def _train_fold_model(self, X: np.ndarray, y: np.ndarray, ph: int):
        """
        –û–±—É—á–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è CV fold.
        –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ (XGB/RF/ARF/NN).
        """
        # –ü—Ä–∏–º–µ—Ä –¥–ª—è XGB
        if not HAVE_XGB:
            return None
        
        scaler = StandardScaler().fit(X) if HAVE_SKLEARN else None
        X_scaled = scaler.transform(X) if scaler else X
        
        dtrain = xgb.DMatrix(X_scaled, label=y)
        model = xgb.train(
            params={
                "objective": "binary:logistic",
                "max_depth": self.cfg.xgb_max_depth,
                "eta": self.cfg.xgb_eta,
                "subsample": self.cfg.xgb_subsample,
                "colsample_bytree": self.cfg.xgb_colsample_bytree,
                "min_child_weight": self.cfg.xgb_min_child_weight,
                "eval_metric": "logloss",
            },
            dtrain=dtrain,
            num_boost_round=self.cfg.xgb_rounds_warm,
            verbose_eval=False
        )
        
        return {"model": model, "scaler": scaler}

    def _predict_fold(self, fold_model, X: np.ndarray, ph: int) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ CV fold.
        """
        if fold_model is None:
            return np.full(len(X), 0.5)
        
        scaler = fold_model.get("scaler")
        model = fold_model.get("model")
        
        X_scaled = scaler.transform(X) if scaler else X
        dtest = xgb.DMatrix(X_scaled)
        preds = model.predict(dtest)
        
        return preds


    # ---------- –∏–Ω—Ñ–µ—Ä–µ–Ω—Å / –∑–∞–ø–∏—Å—å ----------
    def proba_up(self, x_raw: np.ndarray, reg_ctx: Optional[dict] = None) -> Tuple[Optional[float], str]:
        if not self.enabled:
            return (None, "DISABLED")
        if self.booster is None:
            try:
                self._ensure_dim(x_raw)
            except Exception:
                pass
            return (None, self.mode)

        try:
            self._ensure_dim(x_raw)

            # —Å—ã—Ä–æ–π –ø—Ä–æ–≥–Ω–æ–∑
            Xt = self._transform_one(x_raw)
            d = xgb.DMatrix(Xt)
            p = float(self.booster.predict(d)[0])
            p = float(min(max(p, 1e-6), 1.0 - 1e-6))

            # —Ñ–∞–∑–æ–≤—ã–π –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä
            ph = int(reg_ctx.get("phase")) if isinstance(reg_ctx, dict) and "phase" in reg_ctx else 0
            self._last_seen_phase = ph
            cal = self.cal_ph.get(ph) or self.cal_global
            if cal is not None and getattr(cal, "ready", False):
                try:
                    p = float(cal.transform(p))
                except Exception:
                    pass

            p = float(min(max(p, 1e-6), 1.0 - 1e-6))
            return (p, self.mode)
        except Exception:
            return (None, self.mode)

    def record_result(self, x_raw: np.ndarray, y_up: int, used_in_live: bool,
                    p_pred: Optional[float] = None, reg_ctx: Optional[dict] = None) -> None:
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å.
        
        –¢–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç:
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –∏ —Ñ–∞–∑–æ–≤—É—é –ø–∞–º—è—Ç—å
        - –¢—Ä–µ–∫–∏–Ω–≥ —Ö–∏—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        - Out-of-fold predictions –¥–ª—è cross-validation
        - –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é CV –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        - –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        - –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ SHADOW/ACTIVE –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        """
        
        # ========== –ë–õ–û–ö 1: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–†–ù–û–°–¢–ò ==========
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ñ–∏—á–µ–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
        self._ensure_dim(x_raw)

        # ========== –ë–õ–û–ö 2: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ì–õ–û–ë–ê–õ–¨–ù–£–Æ –ü–ê–ú–Ø–¢–¨ ==========
        # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback, –∫–æ–≥–¥–∞ –≤ —Ñ–∞–∑–µ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
        self.X.append(x_raw.astype(np.float32).ravel().tolist())
        self.y.append(int(y_up))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –≥–ª–æ–±–∞–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞–ª–∞—Å—å
        if len(self.X) > int(getattr(self.cfg, "max_memory", 10_000)):
            self.X = self.X[-self.cfg.max_memory:]
            self.y = self.y[-self.cfg.max_memory:]
        
        self.new_since_train += 1

        # ========== –ë–õ–û–ö 3: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –§–ê–ó–´ ==========
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (0-5 –¥–ª—è 6 —Ñ–∞–∑)
        ph = 0
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
        self._last_seen_phase = ph

        # ========== –ë–õ–û–ö 4: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –§–ê–ó–û–í–£–Æ –ü–ê–ú–Ø–¢–¨ ==========
        # –ö–∞–∂–¥–∞—è —Ñ–∞–∑–∞ —Ö—Ä–∞–Ω–∏—Ç —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏–º–µ—Ä–æ–≤
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö
        self.X_ph[ph].append(x_raw.astype(np.float32).ravel().tolist())
        self.y_ph[ph].append(int(y_up))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–∑–æ–≤–æ–π –ø–∞–º—è—Ç–∏
        cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
        if len(self.X_ph[ph]) > cap:
            self.X_ph[ph] = self.X_ph[ph][-cap:]
            self.y_ph[ph] = self.y_ph[ph][-cap:]
        
        self.new_since_train_ph[ph] = self.new_since_train_ph.get(ph, 0) + 1

        # ========== –ë–õ–û–ö 5: –¢–†–ï–ö–ò–ù–ì –•–ò–¢–û–í –ò DRIFT DETECTION ==========
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥—Ä–µ–π—Ñ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        if p_pred is not None:
            try:
                # –°—á–∏—Ç–∞–µ–º hit: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ?
                hit = int((float(p_pred) >= 0.5) == bool(y_up))
                
                if self.mode == "ACTIVE" and used_in_live:
                    # –í –∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Å–¥–µ–ª–∫–∏
                    self.active_hits.append(hit)
                    
                    # ADWIN –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –¥—Ä–µ–π—Ñ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫
                    if self.adwin is not None:
                        in_drift = self.adwin.update(1 - hit)  # 1=correct, 0=error
                        if in_drift:
                            # –û–±–Ω–∞—Ä—É–∂–µ–Ω –¥—Ä–µ–π—Ñ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ shadow —Ä–µ–∂–∏–º
                            self.mode = "SHADOW"
                            self.active_hits = []
                else:
                    # –í shadow —Ä–µ–∂–∏–º–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º "—á—Ç–æ –±—ã–ª–æ –±—ã, –µ—Å–ª–∏ –±—ã –≤—Ö–æ–¥–∏–ª–∏"
                    self.shadow_hits.append(hit)
            except Exception:
                pass

        # ========== –ë–õ–û–ö 6: –ù–û–í–û–ï - –°–û–•–†–ê–ù–ï–ù–ò–ï OOF PREDICTIONS –î–õ–Ø CV ==========
        # Out-of-fold predictions –Ω—É–∂–Ω—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ cross-validation
        # –≠—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—ã–ª–∏ —Å–¥–µ–ª–∞–Ω—ã –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –ù–ï –≤–∏–¥–µ–ª–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        if self.cfg.cv_enabled and p_pred is not None:
            self.cv_oof_preds[ph].append(float(p_pred))
            self.cv_oof_labels[ph].append(int(y_up))

        # ========== –ë–õ–û–ö 7: –§–ê–ó–û–í–ê–Ø –ö–ê–õ–ò–ë–†–û–í–ö–ê ==========
        # –ö–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∞–∑—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        # –≠—Ç–æ –≤–∞–∂–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ-—Ä–∞–∑–Ω–æ–º—É –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞ –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö
        try:
            p_raw = self._predict_raw(x_raw)
            if p_raw is not None:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –¥–ª—è —ç—Ç–æ–π —Ñ–∞–∑—ã, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                if self.cal_ph[ph] is None:
                    self.cal_ph[ph] = make_calibrator(self.cfg.xgb_calibration_method)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä—É –∏—Å—Ç–∏–Ω–Ω—É—é –ø–∞—Ä—É (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
                self.cal_ph[ph].observe(float(p_raw), int(y_up))
                
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É
                if self.cal_ph[ph].maybe_fit(min_samples=200, every=100):
                    cal_path = self._cal_path(self.cfg.xgb_cal_path, ph)
                    self.cal_ph[ph].save(cal_path)
        except Exception:
            pass

        # ========== –ë–õ–û–ö 8: –ù–û–í–û–ï - –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø CV –ü–†–û–í–ï–†–ö–ê ==========
        # –ö–∞–∂–¥—ã–µ N –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é cross-validation –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –¥–∞–µ—Ç —á–µ—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        self.cv_last_check[ph] += 1
        
        if self.cfg.cv_enabled and self.cv_last_check[ph] >= self.cfg.cv_check_every:
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
            self.cv_last_check[ph] = 0
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é walk-forward cross-validation —Å purging
            cv_results = self._run_cv_validation(ph)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ _maybe_flip_modes
            self.cv_metrics[ph] = cv_results
            
            # –ï—Å–ª–∏ CV –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, –ø–æ–º–µ—á–∞–µ–º —Ñ–∞–∑—É –∫–∞–∫ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é
            if cv_results.get("status") == "ok":
                self.validation_passed[ph] = True
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            if cv_results.get("status") == "ok":
                print(f"[{self.__class__.__name__}] CV ph={ph}: "
                    f"OOF_ACC={cv_results['oof_accuracy']:.2f}% "
                    f"CI=[{cv_results['ci_lower']:.2f}%, {cv_results['ci_upper']:.2f}%] "
                    f"folds={cv_results['n_folds']}")

        # ========== –ë–õ–û–ö 9: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ü–û –§–ê–ó–ï ==========
        # –ö–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ñ–∞–∑–µ, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        self._maybe_train_phase(ph)

        # ========== –ë–õ–û–ö 10: –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –†–ï–ñ–ò–ú–û–í ==========
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–≤–∫–ª—é—á–∞—è CV) –∏ —Ä–µ—à–∞–µ–º, –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å –ª–∏ SHADOW ‚Üî ACTIVE
        self._maybe_flip_modes()
        
        # ========== –ë–õ–û–ö 11: –°–û–•–†–ê–ù–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–Ø ==========
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –Ω–∞ –¥–∏—Å–∫ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        self._save_all()

    # ---------- —Ä–µ–∂–∏–º—ã ----------
    def _maybe_flip_modes(self):
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ —Å —É—á—ë—Ç–æ–º:
        1. Cross-validation –º–µ—Ç—Ä–∏–∫
        2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (bootstrap CI)
        3. Out-of-fold predictions
        """
        if not self.cfg.cv_enabled:
            # fallback –∫ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
            self._maybe_flip_modes_simple()
            return
        
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        
        # –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        wr_shadow = wr(self.shadow_hits, self.cfg.min_ready)
        wr_active = wr(self.active_hits, max(30, self.cfg.min_ready // 2))
        
        # –ü–æ–ª—É—á–∞–µ–º CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_passed = self.validation_passed.get(ph, False)
        
        # SHADOW ‚Üí ACTIVE: —Ç—Ä–µ–±—É–µ–º CV validation + bootstrap CI
        if self.mode == "SHADOW" and wr_shadow is not None:
            basic_threshold_met = wr_shadow >= self.cfg.enter_wr
            
            if basic_threshold_met and cv_passed:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
                cv_wr = cv_metrics.get("oof_accuracy", 0.0)
                cv_ci_lower = cv_metrics.get("ci_lower", 0.0)
                
                # –ù—É–∂–Ω–æ: OOF accuracy > –ø–æ—Ä–æ–≥ –ò –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ CI —Ç–æ–∂–µ
                if cv_wr >= self.cfg.enter_wr and cv_ci_lower >= (self.cfg.enter_wr - self.cfg.cv_min_improvement):
                    self.mode = "ACTIVE"
                    if HAVE_RIVER:
                        self.adwin = ADWIN(delta=self.cfg.adwin_delta)
                    print(f"[{self.__class__.__name__}] SHADOW‚ÜíACTIVE ph={ph}: WR={wr_shadow:.2f}%, CV_WR={cv_wr:.2f}% (CI: [{cv_ci_lower:.2f}%, {cv_metrics.get('ci_upper', 0):.2f}%])")
        
        # ACTIVE ‚Üí SHADOW: –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
        if self.mode == "ACTIVE" and wr_active is not None:
            basic_threshold_failed = wr_active < self.cfg.exit_wr
            
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º CV –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
            cv_wr = cv_metrics.get("oof_accuracy", 100.0)
            cv_degraded = cv_wr < self.cfg.exit_wr
            
            if basic_threshold_failed or cv_degraded:
                self.mode = "SHADOW"
                self.validation_passed[ph] = False
                print(f"[{self.__class__.__name__}] ACTIVE‚ÜíSHADOW ph={ph}: WR={wr_active:.2f}%, CV_WR={cv_wr:.2f}%")

    def _maybe_flip_modes_simple(self):
        """–°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è backward compatibility"""
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        wr_shadow = wr(self.shadow_hits, self.cfg.min_ready)
        if self.mode == "SHADOW" and wr_shadow is not None and wr_shadow >= self.cfg.enter_wr:
            self.mode = "ACTIVE"
            if HAVE_RIVER:
                self.adwin = ADWIN(delta=self.cfg.adwin_delta)
        wr_active = wr(self.active_hits, max(30, self.cfg.min_ready // 2))
        if self.mode == "ACTIVE" and (wr_active is not None and wr_active < self.cfg.exit_wr):
            self.mode = "SHADOW"

    # ---------- —Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è –æ–±—ë—Ä—Ç–∫–∞ ----------
    def maybe_train(self, ph: Optional[int] = None, reg_ctx: Optional[dict] = None) -> None:
        """–¢—Ä–µ–Ω–∏—Ä—É–µ–º –ø–æ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑–µ (–±–µ–∑ ¬´–≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ¬ª —Ä–µ—Ñ–∏—Ç–∞)."""
        if not self.enabled or self.n_feats is None:
            return
        if ph is None:
            if isinstance(reg_ctx, dict) and "phase" in reg_ctx:
                ph = int(reg_ctx["phase"])
            else:
                ph = int(getattr(self, "_last_seen_phase", 0))
        self._maybe_train_phase(int(ph))

    # ---------- —Å—Ç–∞—Ç—É—Å ----------
    def status(self):
        def _wr(xs):
            if not xs: return None
            return sum(xs) / float(len(xs))
        def _fmt_pct(p):
            return "‚Äî" if p is None else f"{100.0*p:.2f}%"
        
        wr_a = _wr(self.active_hits)
        wr_s = _wr(self.shadow_hits)
        all_hits = (self.active_hits or []) + (self.shadow_hits or [])
        wr_all = _wr(all_hits)
        
        # CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_status = cv_metrics.get("status", "N/A")
        cv_wr = cv_metrics.get("oof_accuracy", 0.0)
        cv_ci = f"[{cv_metrics.get('ci_lower', 0):.1f}%, {cv_metrics.get('ci_upper', 0):.1f}%]" if cv_status == "ok" else "N/A"
        
        # –ù–û–í–û–ï: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        try:
            from training_visualizer import get_visualizer
            viz = get_visualizer()
            
            expert_name = "XGB"
            
            viz.record_expert_metrics(
                expert_name=expert_name,
                accuracy=wr_all if wr_all is not None else 0.0,
                n_samples=len(all_hits),
                cv_accuracy=cv_wr / 100.0 if cv_wr > 0 else None,
                cv_ci_lower=cv_metrics.get('ci_lower') if cv_status == "ok" else None,
                cv_ci_upper=cv_metrics.get('ci_upper') if cv_status == "ok" else None,
                mode=self.mode
            )
        except Exception:
            pass
        
        return {
            "mode": self.mode,
            "enabled": self.enabled,
            "wr_active": _fmt_pct(wr_a),
            "n_active": len(self.active_hits or []),
            "wr_shadow": _fmt_pct(wr_s),
            "n_shadow": len(self.shadow_hits or []),
            "wr_all": _fmt_pct(wr_all),
            "n": len(all_hits),
            "cv_oof_wr": _fmt_pct(cv_wr / 100.0) if cv_wr > 0 else "‚Äî",
            "cv_ci": cv_ci,
            "cv_validated": str(self.validation_passed.get(ph, False))
        }





# ---------- RF ----------
class RFCalibratedExpert(_BaseExpert):
    def __init__(self, cfg: MLConfig):
        self.cfg = cfg
        self.enabled = HAVE_SKLEARN
        self.mode = "SHADOW"

        # –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π RF (–∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏ CalibratedClassifierCV)
        self.clf: Optional[CalibratedClassifierCV] = None
        # --- –ù–û–í–û–ï: –º–æ–¥–µ–ª–∏ –ø–æ —Ñ–∞–∑–∞–º ---
        self.clf_ph: Dict[int, Optional[CalibratedClassifierCV]] = {}


        # –î–µ—Ç–µ–∫—Ç–æ—Ä –¥—Ä–µ–π—Ñ–∞ (–∫–∞–∫ –±—ã–ª–æ)
        self.adwin = ADWIN(delta=self.cfg.adwin_delta) if HAVE_RIVER else None

        # ===== –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ (—Ö–≤–æ—Å—Ç) =====
        self.X: List[List[float]] = []
        self.y: List[int] = []
        self.new_since_train: int = 0

        # ===== –§–ê–ó–û–í–ê–Ø –ü–ê–ú–Ø–¢–¨ =====
        self.P: int = int(self.cfg.phase_count)  # 6 —Ñ–∞–∑: bull/bear/flat √ó low/high
        self.X_ph: Dict[int, List[List[float]]] = {p: [] for p in range(self.P)}
        self.y_ph: Dict[int, List[int]]         = {p: [] for p in range(self.P)}
        self.new_since_train_ph: Dict[int, int] = {p: 0  for p in range(self.P)}

        self.clf_ph = {p: None for p in range(self.P)}
        # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Ñ–∞–∑–∞ ‚Äî –ø—Ä–∏–≥–æ–¥–∏—Ç—Å—è, –µ—Å–ª–∏ maybe_train() –≤—ã–∑–æ–≤—É—Ç –±–µ–∑ reg_ctx
        self._last_seen_phase: int = 0

        # –•–∏—Ç—ã/–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        self.shadow_hits: List[int] = []
        self.active_hits: List[int] = []
        # Cross-validation tracking (per phase)
        self.cv_oof_preds: Dict[int, deque] = {p: deque(maxlen=cfg.cv_oof_window) for p in range(self.P)}
        self.cv_oof_labels: Dict[int, deque] = {p: deque(maxlen=cfg.cv_oof_window) for p in range(self.P)}
        self.cv_metrics: Dict[int, Dict] = {p: {} for p in range(self.P)}
        self.cv_last_check: Dict[int, int] = {p: 0 for p in range(self.P)}
        
        # Validation mode tracking
        self.validation_passed: Dict[int, bool] = {p: False for p in range(self.P)}


        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ: —á–∏—Å–ª–æ —Ñ–∏—á (–∑–∞–ø–æ–ª–Ω–∏–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ)
        self.n_feats: Optional[int] = None

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–µ–π—Ç–∞ (–µ—Å–ª–∏ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç–µ –ø–∞–º—è—Ç—å/–º–æ–¥–µ–ª—å)
        self._load_all()

    # ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï ----------
    def _get_global_tail(self, n: int) -> Tuple[np.ndarray, np.ndarray]:
        if n <= 0 or not self.X:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        Xg = np.array(self.X[-n:], dtype=np.float32)
        yg = np.array(self.y[-n:], dtype=np.int32)
        return Xg, yg

    def _get_past_phases_tail(self, ph: int, n: int) -> Tuple[np.ndarray, np.ndarray]:
        # –ë–µ—Ä–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –∑–∞–ø–∏—Å–µ–π —Ç–æ–ª—å–∫–æ –∏–∑ —Ñ–∞–∑ 0..ph (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        # –ò—Å–∫–ª—é—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É–¥—É—â–∏—Ö —Ñ–∞–∑ ‚Üí –Ω–µ—Ç —É—Ç–µ—á–∫–∏
        if n <= 0:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–∑ 0..ph
        X_past = []
        y_past = []
        for p in range(min(ph + 1, self.P)):
            if self.X_ph.get(p):
                X_past.extend(self.X_ph[p])
                y_past.extend(self.y_ph[p])
        
        if not X_past:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –∑–∞–ø–∏—Å–µ–π
        X_past = X_past[-n:]
        y_past = y_past[-n:]
        
        return np.array(X_past, dtype=np.float32), np.array(y_past, dtype=np.int32)

    def _get_phase_train(self, ph: int) -> Tuple[np.ndarray, np.ndarray]:
        # X_phase
        Xp = np.array(self.X_ph[ph], dtype=np.float32) if self.X_ph[ph] else np.empty((0, self.n_feats or 0), dtype=np.float32)
        yp = np.array(self.y_ph[ph], dtype=np.int32)   if self.y_ph[ph]  else np.empty((0,), dtype=np.int32)

        if len(Xp) >= int(self.cfg.phase_min_ready):
            return Xp, yp

        # –∏–Ω–∞—á–µ —Å–º–µ—à–∏–≤–∞–µ–º X_phase ‚à™ X_past_phases_tail (70/30 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ —Ñ–∞–∑—ã (0..ph), –∞ –Ω–µ –≤–µ—Å—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ö–≤–æ—Å—Ç
        share = float(self.cfg.phase_mix_global_share)  # 0.30
        need_g = int(round(len(Xp) * share / max(1e-9, (1.0 - share))))
        need_g = max(need_g, int(self.cfg.phase_min_ready) - len(Xp))   # –Ω–µ –º–µ–Ω–µ–µ, —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å –ø–æ—Ä–æ–≥–∞
        
        # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω–æ –≤ —Ñ–∞–∑–∞—Ö 0..ph
        available_past = sum(len(self.X_ph.get(p, [])) for p in range(min(ph + 1, self.P)))
        need_g = min(need_g, available_past)  # –Ω–µ –±–æ–ª—å—à–µ, —á–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ –≤ –ø—Ä–æ—à–ª—ã—Ö —Ñ–∞–∑–∞—Ö
        
        Xg, yg = self._get_past_phases_tail(ph, need_g)
        if len(Xg) == 0:
            return Xp, yp

        X = np.concatenate([Xp, Xg], axis=0)
        y = np.concatenate([yp, yg], axis=0)
        return X, y

    def _maybe_train_phase(self, ph: int) -> None:
        # —Ç—Ä–µ–Ω–∏—Ä—É–µ–º —Ä–æ–≤–Ω–æ –ø–æ —Ñ–∞–∑–µ ph (—Å –ø–æ–¥–º–µ—à–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ—à–ª—ã—Ö —Ñ–∞–∑ 0..ph –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ)
        if self.n_feats is None or not self.enabled:
            return
        if self.new_since_train_ph.get(ph, 0) < int(self.cfg.retrain_every):
            return

        X_all, y_all = self._get_phase_train(ph)
        if len(X_all) < int(self.cfg.phase_min_ready):
            return


        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
        if len(X_all) > int(self.cfg.train_window):
            X_all = X_all[-int(self.cfg.train_window):]
            y_all = y_all[-int(self.cfg.train_window):]

        try:
            # (–ø–µ—Ä–µ)–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if self.clf is None:
                # (–ø–µ—Ä–µ)–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ú–û–î–ï–õ–ò –î–õ–Ø –ö–û–ù–ö–†–ï–¢–ù–û–ô –§–ê–ó–´
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.calibration import CalibratedClassifierCV

                model = self.clf_ph.get(ph)
                if model is None:
                    base = RandomForestClassifier(
                        n_estimators=getattr(self.cfg, "rf_n_estimators", 300),
                        max_depth=getattr(self.cfg, "rf_max_depth", None),
                        min_samples_leaf=getattr(self.cfg, "rf_min_samples_leaf", 2),
                        n_jobs=-1,
                        random_state=42,
                        class_weight=None
                    )
                    cal_method = getattr(self.cfg, "rf_calibration_method", "sigmoid")
                    try:
                        model = CalibratedClassifierCV(estimator=base, method=cal_method, cv=3)
                    except TypeError:
                        model = CalibratedClassifierCV(base_estimator=base, method=cal_method, cv=3)

                # –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ñ–∞–∑–æ–≤–æ–º –±–∞—Ç—á–µ
                model.fit(X_all, y_all)

                # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Ñ–∞–∑
                self.clf_ph[ph] = model
                # –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ "–ø–æ—Å–ª–µ–¥–Ω—é—é –æ–±—É—á–µ–Ω–Ω—É—é"
                self.clf = model


            self.new_since_train_ph[ph] = 0
            # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: self._save_all()
        except Exception as e:
            print(f"[rf  ] train error (ph={ph}): {e}")

    def _run_cv_validation(self, ph: int) -> Dict:
        """
        Walk-forward purged cross-validation –¥–ª—è —Ñ–∞–∑—ã ph.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏: accuracy, CI bounds, fold scores.
        """
        X_all, y_all = self._get_phase_train(ph)
        
        if len(X_all) < self.cfg.cv_min_train_size:
            return {"status": "insufficient_data", "oof_accuracy": 0.0}
        
        n_samples = len(X_all)
        n_splits = min(self.cfg.cv_n_splits, n_samples // self.cfg.cv_min_train_size)
        
        if n_splits < 2:
            return {"status": "insufficient_splits", "oof_accuracy": 0.0}
        
        # Walk-forward splits —Å purge –∏ embargo
        embargo_size = max(1, int(n_samples * self.cfg.cv_embargo_pct))
        purge_size = max(1, int(n_samples * self.cfg.cv_purge_pct))
        
        fold_size = n_samples // n_splits
        oof_preds = np.zeros(n_samples)
        oof_mask = np.zeros(n_samples, dtype=bool)
        fold_scores = []
        
        for fold_idx in range(n_splits):
            # Test fold
            test_start = fold_idx * fold_size
            test_end = min(test_start + fold_size, n_samples)
            
            # Train: –≤—Å—ë –¥–æ (test_start - purge_size)
            train_end = max(0, test_start - purge_size)
            
            if train_end < self.cfg.cv_min_train_size:
                continue
            
            X_train = X_all[:train_end]
            y_train = y_all[:train_end]
            X_test = X_all[test_start:test_end]
            y_test = y_all[test_start:test_end]
            
            # –û–±—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ train fold
            temp_model = self._train_fold_model(X_train, y_train, ph)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test fold
            preds = self._predict_fold(temp_model, X_test, ph)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º OOF predictions
            oof_preds[test_start:test_end] = preds
            oof_mask[test_start:test_end] = True
            
            # –ú–µ—Ç—Ä–∏–∫–∏ —Ñ–æ–ª–¥–∞
            fold_acc = np.mean((preds >= 0.5) == y_test)
            fold_scores.append(fold_acc)
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ OOF –º–µ—Ç—Ä–∏–∫–∏
        oof_valid = oof_mask.sum()
        if oof_valid < self.cfg.cv_min_train_size:
            return {"status": "insufficient_oof", "oof_accuracy": 0.0}
        
        oof_accuracy = 100.0 * np.mean((oof_preds[oof_mask] >= 0.5) == y_all[oof_mask])
        
        # Bootstrap confidence intervals
        ci_lower, ci_upper = self._bootstrap_ci(
            oof_preds[oof_mask], 
            y_all[oof_mask],
            n_bootstrap=self.cfg.cv_bootstrap_n,
            confidence=self.cfg.cv_confidence
        )
        
        return {
            "status": "ok",
            "oof_accuracy": oof_accuracy,
            "ci_lower": ci_lower,
            "ci_upper": ci_upper,
            "fold_scores": fold_scores,
            "n_folds": len(fold_scores),
            "oof_samples": int(oof_valid)
        }

    def _bootstrap_ci(self, preds: np.ndarray, labels: np.ndarray, 
                    n_bootstrap: int, confidence: float) -> tuple:
        """
        Bootstrap confidence intervals –¥–ª—è accuracy.
        """
        accuracies = []
        n = len(preds)
        
        for _ in range(n_bootstrap):
            # Resample —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º
            idx = np.random.choice(n, size=n, replace=True)
            boot_preds = preds[idx]
            boot_labels = labels[idx]
            boot_acc = 100.0 * np.mean((boot_preds >= 0.5) == boot_labels)
            accuracies.append(boot_acc)
        
        accuracies = np.array(accuracies)
        alpha = 1.0 - confidence
        ci_lower = np.percentile(accuracies, 100 * alpha / 2)
        ci_upper = np.percentile(accuracies, 100 * (1 - alpha / 2))
        
        return ci_lower, ci_upper

    def _train_fold_model(self, X: np.ndarray, y: np.ndarray, ph: int):
        """
        –û–±—É—á–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è CV fold.
        –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ (XGB/RF/ARF/NN).
        """
        # –ü—Ä–∏–º–µ—Ä –¥–ª—è XGB
        if not HAVE_XGB:
            return None
        
        scaler = StandardScaler().fit(X) if HAVE_SKLEARN else None
        X_scaled = scaler.transform(X) if scaler else X
        
        dtrain = xgb.DMatrix(X_scaled, label=y)
        model = xgb.train(
            params={
                "objective": "binary:logistic",
                "max_depth": self.cfg.xgb_max_depth,
                "eta": self.cfg.xgb_eta,
                "subsample": self.cfg.xgb_subsample,
                "colsample_bytree": self.cfg.xgb_colsample_bytree,
                "min_child_weight": self.cfg.xgb_min_child_weight,
                "eval_metric": "logloss",
            },
            dtrain=dtrain,
            num_boost_round=self.cfg.xgb_rounds_warm,
            verbose_eval=False
        )
        
        return {"model": model, "scaler": scaler}

    def _predict_fold(self, fold_model, X: np.ndarray, ph: int) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ CV fold.
        """
        if fold_model is None:
            return np.full(len(X), 0.5)
        
        scaler = fold_model.get("scaler")
        model = fold_model.get("model")
        
        X_scaled = scaler.transform(X) if scaler else X
        dtest = xgb.DMatrix(X_scaled)
        preds = model.predict(dtest)
        
        return preds

    def _ensure_dim(self, x_raw: np.ndarray):
        d = int(x_raw.reshape(1, -1).shape[1])
        if self.n_feats is None:
            self.n_feats = d
            self.X, self.y = [], []
            self.clf = None
            self.new_since_train = 0
            # —Ç–∞–∫–∂–µ –æ–±–Ω—É–ª–∏–º —Ñ–∞–∑–æ–≤—ã–µ –±—É—Ñ–µ—Ä—ã –∏ —Å—á—ë—Ç—á–∏–∫–∏
            self.X_ph = {p: [] for p in range(self.P)}
            self.y_ph = {p: [] for p in range(self.P)}
            self.new_since_train_ph = {p: 0 for p in range(self.P)}
            self._last_seen_phase = 0
        elif self.n_feats != d:
            # —Å–º–µ–Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ ‚Äî —Å–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.n_feats = d
            self.X, self.y = [], []
            self.clf = None
            self.new_since_train = 0
            self.X_ph = {p: [] for p in range(self.P)}
            self.y_ph = {p: [] for p in range(self.P)}
            self.new_since_train_ph = {p: 0 for p in range(self.P)}
            self._last_seen_phase = 0

    def _predict_raw(self, x_raw: np.ndarray) -> Optional[float]:
        """
        –°—ã—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ë–ï–ó –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏.
        –î–ª—è CalibratedClassifierCV –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ estimator.
        """
        if not self.enabled:
            return None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É
        ph = getattr(self, '_last_seen_phase', 0)
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å: —Ñ–∞–∑–æ–≤–∞—è –∏–ª–∏ –≥–ª–æ–±–∞–ª—å–Ω–∞—è
        model = self.clf_ph.get(ph) or self.clf
        
        if model is None:
            return None
        
        try:
            xx = x_raw.astype(np.float32).reshape(1, -1)
            if self.n_feats is None:
                self.n_feats = xx.shape[1]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –°–´–†–û–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            # CalibratedClassifierCV —Ö—Ä–∞–Ω–∏—Ç –±–∞–∑–æ–≤—ã–π estimator
            if hasattr(model, 'calibrated_classifiers_'):
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
                base = model.calibrated_classifiers_[0].base_estimator
                p = float(base.predict_proba(xx)[0, 1])
            elif hasattr(model, 'base_estimator'):
                p = float(model.base_estimator.predict_proba(xx)[0, 1])
            elif hasattr(model, 'estimator'):
                p = float(model.estimator.predict_proba(xx)[0, 1])
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                # (–Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ, –Ω–æ –ª—É—á—à–µ —á–µ–º –∫—Ä—ç—à)
                p = float(model.predict_proba(xx)[0, 1])
            
            return float(min(max(p, 1e-6), 1.0 - 1e-6))
        except Exception:
            return None


    # ---------- –ó–ê–ì–†–£–ó–ö–ê/–°–û–•–†–ê–ù–ï–ù–ò–ï ----------
    def _load_all(self) -> None:
        # --- –∑–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞ (JSON) ---
        try:
            if os.path.exists(self.cfg.rf_state_path):
                with open(self.cfg.rf_state_path, "r") as f:
                    st = json.load(f)

                # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
                self.mode = st.get("mode", self.mode if hasattr(self, "mode") else "SHADOW")
                self.shadow_hits = st.get("shadow_hits", [])[-1000:]
                self.active_hits = st.get("active_hits", [])[-1000:]
                self.n_feats = st.get("n_feats", self.n_feats if hasattr(self, "n_feats") else None)

                # NEW: –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ —Å—Ç–µ–π—Ç–µ)
                self.X = st.get("X", self.X if hasattr(self, "X") else [])
                self.y = st.get("y", self.y if hasattr(self, "y") else [])

                # NEW: —Ñ–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å (–∫–ª—é—á–∏ ‚Üí int; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç—ã–µ –±—É—Ñ–µ—Ä—ã)
                X_ph = st.get("X_ph")
                y_ph = st.get("y_ph")
                if isinstance(X_ph, dict) and isinstance(y_ph, dict):
                    self.X_ph = {int(k): v for k, v in X_ph.items()}
                    self.y_ph = {int(k): v for k, v in y_ph.items()}
                else:
                    # —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ —Ñ–∞–∑ ‚Äî –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    self.X_ph = {p: [] for p in range(self.P)}
                    self.y_ph = {p: [] for p in range(self.P)}

                # NEW: —Å—á—ë—Ç—á–∏–∫–∏ retrain –ø–æ —Ñ–∞–∑–∞–º
                self.new_since_train_ph = {p: 0 for p in range(self.P)}
                if isinstance(st.get("new_since_train_ph"), dict):
                    for k, v in st["new_since_train_ph"].items():
                        try:
                            self.new_since_train_ph[int(k)] = int(v)
                        except Exception:
                            pass

                # NEW: –ø–æ—Å–ª–µ–¥–Ω—è—è —É–≤–∏–¥–µ–Ω–Ω–∞—è —Ñ–∞–∑–∞ (–¥–ª—è maybe_train –±–µ–∑ reg_ctx)
                try:
                    self._last_seen_phase = int(st.get("_last_seen_phase", 0))
                except Exception:
                    self._last_seen_phase = 0

                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–±—Ä–µ–∑–∫–∏ –ø–æ –∫–∞–ø–∞–º (–Ω–∞ —Å–ª—É—á–∞–π —Å—Ç–∞—Ä—ã—Ö –±–æ–ª—å—à–∏—Ö —Å—Ç–µ–π—Ç–æ–≤)
                max_mem = getattr(self.cfg, "max_memory", None)
                if isinstance(max_mem, int) and max_mem > 0 and len(self.X) > max_mem:
                    self.X = self.X[-max_mem:]
                    self.y = self.y[-max_mem:]

                cap = int(self.cfg.phase_memory_cap)
                for p in range(self.P):
                    if len(self.X_ph.get(p, [])) > cap:
                        self.X_ph[p] = self.X_ph[p][-cap:]
                        self.y_ph[p] = self.y_ph[p][-cap:]
        except Exception as e:
            print(f"[rf  ] _load_all state error: {e}")

        # --- –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å RF+–∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä (pickle) ---
        try:
            if os.path.exists(self.cfg.rf_model_path):
                with open(self.cfg.rf_model_path, "rb") as f:
                    self.clf = pickle.load(f)
        except Exception as e:
            print(f"[rf  ] _load_all model error: {e}")
            self.clf = None

        # --- –ù–û–í–û–ï: –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π ---
        try:
            root, ext = os.path.splitext(self.cfg.rf_model_path)
            for p in range(self.P):
                ph_path = f"{root}_ph{p}{ext}"
                if os.path.exists(ph_path):
                    with open(ph_path, "rb") as f:
                        self.clf_ph[p] = pickle.load(f)
        except Exception as e:
            print(f"[rf  ] _load_all per-phase model error: {e}")

    def _save_all(self) -> None:
        # --- —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞ (JSON) ---
        try:
            # –ü–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –æ–±—Ä–µ–∑–∫—É –ø–æ –∫–∞–ø–∞–º
            max_mem = getattr(self.cfg, "max_memory", None)
            X_tail = self.X
            y_tail = self.y
            if isinstance(max_mem, int) and max_mem > 0:
                X_tail = self.X[-max_mem:]
                y_tail = self.y[-max_mem:]

            cap = int(self.cfg.phase_memory_cap)
            X_ph_tail: Dict[int, List[List[float]]] = {}
            y_ph_tail: Dict[int, List[int]] = {}
            for p in range(self.P):
                Xp = self.X_ph.get(p, [])
                yp = self.y_ph.get(p, [])
                X_ph_tail[p] = Xp[-cap:]
                y_ph_tail[p] = yp[-cap:]

            st = {
                # –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
                "mode": self.mode,
                "shadow_hits": self.shadow_hits[-1000:],
                "active_hits": self.active_hits[-1000:],
                "n_feats": self.n_feats,

                # NEW: –≥–ª–æ–±–∞–ª—å–Ω–∞—è –∏ —Ñ–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å
                "X": X_tail,
                "y": y_tail,
                "X_ph": X_ph_tail,
                "y_ph": y_ph_tail,
                "new_since_train_ph": {int(p): int(self.new_since_train_ph.get(p, 0)) for p in range(self.P)},
                "_last_seen_phase": int(self._last_seen_phase),

                # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî –ø–∏—à–µ–º P (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏/—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                "P": int(self.P),
            }

            with open(self.cfg.rf_state_path, "w") as f:
                json.dump(st, f)
        except Exception as e:
            print(f"[rf  ] _save_all state error: {e}")

        # --- —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å RF+–∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä (pickle) ---
        try:
            if self.clf is not None:
                with open(self.cfg.rf_model_path, "wb") as f:
                    pickle.dump(self.clf, f)
        except Exception as e:
            print(f"[rf  ] _save_all model error: {e}")

        # --- –ù–û–í–û–ï: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π ---
        try:
            root, ext = os.path.splitext(self.cfg.rf_model_path)
            for p, model in (self.clf_ph or {}).items():
                if model is None:
                    continue
                ph_path = f"{root}_ph{int(p)}{ext}"
                with open(ph_path, "wb") as f:
                    pickle.dump(model, f)
        except Exception as e:
            print(f"[rf  ] _save_all per-phase model error: {e}")


    # ---------- –ò–ù–§–ï–†–ï–ù–° / –û–ë–£–ß–ï–ù–ò–ï ----------
    def proba_up(self, x_raw: np.ndarray, reg_ctx: Optional[dict] = None) -> Tuple[Optional[float], str]:
        # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        try:
            self._ensure_dim(x_raw)
        except Exception:
            pass

        # –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å —Ñ–∞–∑—ã, –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ‚Äî –≥–ª–æ–±–∞–ª—å–Ω—É—é
        model = None
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
            self._last_seen_phase = ph
            model = self.clf_ph.get(ph)
        if model is None:
            model = self.clf

        if not self.enabled or model is None:
            return (None, self.mode)

        # –æ–ø—Ä–µ–¥–µ–ª–∏–º —Ñ–∞–∑—É (—Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é ‚Äî –≤—ã –¥–æ–±–∞–≤–ª—è–µ—Ç–µ –≤ reg_ctx["phase"])
        ph = 0
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
        self._last_seen_phase = ph

        xx = x_raw.astype(np.float32).reshape(1, -1)
        if self.n_feats is None:
            self.n_feats = xx.shape[1]

        try:
            p = float(model.predict_proba(xx)[0, 1])   # –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏
            p = max(1e-6, min(1.0 - 1e-6, p))
            return (p, self.mode)
        except Exception:
            return (None, self.mode)

    def record_result(self, x_raw: np.ndarray, y_up: int, used_in_live: bool,
                    p_pred: Optional[float] = None, reg_ctx: Optional[dict] = None) -> None:
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å.
        
        –¢–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç:
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –∏ —Ñ–∞–∑–æ–≤—É—é –ø–∞–º—è—Ç—å
        - –¢—Ä–µ–∫–∏–Ω–≥ —Ö–∏—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        - Out-of-fold predictions –¥–ª—è cross-validation
        - –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é CV –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        - –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        - –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ SHADOW/ACTIVE –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        """
        
        # ========== –ë–õ–û–ö 1: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–†–ù–û–°–¢–ò ==========
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ñ–∏—á–µ–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
        self._ensure_dim(x_raw)

        # ========== –ë–õ–û–ö 2: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ì–õ–û–ë–ê–õ–¨–ù–£–Æ –ü–ê–ú–Ø–¢–¨ ==========
        # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback, –∫–æ–≥–¥–∞ –≤ —Ñ–∞–∑–µ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
        self.X.append(x_raw.astype(np.float32).ravel().tolist())
        self.y.append(int(y_up))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –≥–ª–æ–±–∞–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞–ª–∞—Å—å
        if len(self.X) > int(getattr(self.cfg, "max_memory", 10_000)):
            self.X = self.X[-self.cfg.max_memory:]
            self.y = self.y[-self.cfg.max_memory:]
        
        self.new_since_train += 1

        # ========== –ë–õ–û–ö 3: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –§–ê–ó–´ ==========
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (0-5 –¥–ª—è 6 —Ñ–∞–∑)
        ph = 0
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
        self._last_seen_phase = ph

        # ========== –ë–õ–û–ö 4: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –§–ê–ó–û–í–£–Æ –ü–ê–ú–Ø–¢–¨ ==========
        # –ö–∞–∂–¥–∞—è —Ñ–∞–∑–∞ —Ö—Ä–∞–Ω–∏—Ç —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏–º–µ—Ä–æ–≤
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö
        self.X_ph[ph].append(x_raw.astype(np.float32).ravel().tolist())
        self.y_ph[ph].append(int(y_up))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–∑–æ–≤–æ–π –ø–∞–º—è—Ç–∏
        cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
        if len(self.X_ph[ph]) > cap:
            self.X_ph[ph] = self.X_ph[ph][-cap:]
            self.y_ph[ph] = self.y_ph[ph][-cap:]
        
        self.new_since_train_ph[ph] = self.new_since_train_ph.get(ph, 0) + 1

        # ========== –ë–õ–û–ö 5: –¢–†–ï–ö–ò–ù–ì –•–ò–¢–û–í –ò DRIFT DETECTION ==========
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥—Ä–µ–π—Ñ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        if p_pred is not None:
            try:
                # –°—á–∏—Ç–∞–µ–º hit: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ?
                hit = int((float(p_pred) >= 0.5) == bool(y_up))
                
                if self.mode == "ACTIVE" and used_in_live:
                    # –í –∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Å–¥–µ–ª–∫–∏
                    self.active_hits.append(hit)
                    
                    # ADWIN –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –¥—Ä–µ–π—Ñ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫
                    if self.adwin is not None:
                        in_drift = self.adwin.update(1 - hit)  # 1=correct, 0=error
                        if in_drift:
                            # –û–±–Ω–∞—Ä—É–∂–µ–Ω –¥—Ä–µ–π—Ñ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ shadow —Ä–µ–∂–∏–º
                            self.mode = "SHADOW"
                            self.active_hits = []
                else:
                    # –í shadow —Ä–µ–∂–∏–º–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º "—á—Ç–æ –±—ã–ª–æ –±—ã, –µ—Å–ª–∏ –±—ã –≤—Ö–æ–¥–∏–ª–∏"
                    self.shadow_hits.append(hit)
            except Exception:
                pass

        # ========== –ë–õ–û–ö 6: –ù–û–í–û–ï - –°–û–•–†–ê–ù–ï–ù–ò–ï OOF PREDICTIONS –î–õ–Ø CV ==========
        # Out-of-fold predictions –Ω—É–∂–Ω—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ cross-validation
        # –≠—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—ã–ª–∏ —Å–¥–µ–ª–∞–Ω—ã –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –ù–ï –≤–∏–¥–µ–ª–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        if self.cfg.cv_enabled and p_pred is not None:
            self.cv_oof_preds[ph].append(float(p_pred))
            self.cv_oof_labels[ph].append(int(y_up))

        # ========== –ë–õ–û–ö 7: –§–ê–ó–û–í–ê–Ø –ö–ê–õ–ò–ë–†–û–í–ö–ê ==========
        # –ö–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∞–∑—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        # –≠—Ç–æ –≤–∞–∂–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ-—Ä–∞–∑–Ω–æ–º—É –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞ –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö
        try:
            p_raw = self._predict_raw(x_raw)
            if p_raw is not None:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –¥–ª—è —ç—Ç–æ–π —Ñ–∞–∑—ã, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                if self.cal_ph[ph] is None:
                    self.cal_ph[ph] = make_calibrator(self.cfg.xgb_calibration_method)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä—É –∏—Å—Ç–∏–Ω–Ω—É—é –ø–∞—Ä—É (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
                self.cal_ph[ph].observe(float(p_raw), int(y_up))
                
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É
                if self.cal_ph[ph].maybe_fit(min_samples=200, every=100):
                    cal_path = self._cal_path(self.cfg.xgb_cal_path, ph)
                    self.cal_ph[ph].save(cal_path)
        except Exception:
            pass

        # ========== –ë–õ–û–ö 8: –ù–û–í–û–ï - –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø CV –ü–†–û–í–ï–†–ö–ê ==========
        # –ö–∞–∂–¥—ã–µ N –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é cross-validation –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –¥–∞–µ—Ç —á–µ—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        self.cv_last_check[ph] += 1
        
        if self.cfg.cv_enabled and self.cv_last_check[ph] >= self.cfg.cv_check_every:
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
            self.cv_last_check[ph] = 0
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é walk-forward cross-validation —Å purging
            cv_results = self._run_cv_validation(ph)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ _maybe_flip_modes
            self.cv_metrics[ph] = cv_results
            
            # –ï—Å–ª–∏ CV –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, –ø–æ–º–µ—á–∞–µ–º —Ñ–∞–∑—É –∫–∞–∫ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é
            if cv_results.get("status") == "ok":
                self.validation_passed[ph] = True
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            if cv_results.get("status") == "ok":
                print(f"[{self.__class__.__name__}] CV ph={ph}: "
                    f"OOF_ACC={cv_results['oof_accuracy']:.2f}% "
                    f"CI=[{cv_results['ci_lower']:.2f}%, {cv_results['ci_upper']:.2f}%] "
                    f"folds={cv_results['n_folds']}")

        # ========== –ë–õ–û–ö 9: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ü–û –§–ê–ó–ï ==========
        # –ö–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ñ–∞–∑–µ, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        self._maybe_train_phase(ph)

        # ========== –ë–õ–û–ö 10: –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –†–ï–ñ–ò–ú–û–í ==========
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–≤–∫–ª—é—á–∞—è CV) –∏ —Ä–µ—à–∞–µ–º, –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å –ª–∏ SHADOW ‚Üî ACTIVE
        self._maybe_flip_modes()
        
        # ========== –ë–õ–û–ö 11: –°–û–•–†–ê–ù–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–Ø ==========
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –Ω–∞ –¥–∏—Å–∫ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        self._save_all()

    def _maybe_flip_modes(self):
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ —Å —É—á—ë—Ç–æ–º:
        1. Cross-validation –º–µ—Ç—Ä–∏–∫
        2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (bootstrap CI)
        3. Out-of-fold predictions
        """
        if not self.cfg.cv_enabled:
            # fallback –∫ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
            self._maybe_flip_modes_simple()
            return
        
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        
        # –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        wr_shadow = wr(self.shadow_hits, self.cfg.min_ready)
        wr_active = wr(self.active_hits, max(30, self.cfg.min_ready // 2))
        
        # –ü–æ–ª—É—á–∞–µ–º CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_passed = self.validation_passed.get(ph, False)
        
        # SHADOW ‚Üí ACTIVE: —Ç—Ä–µ–±—É–µ–º CV validation + bootstrap CI
        if self.mode == "SHADOW" and wr_shadow is not None:
            basic_threshold_met = wr_shadow >= self.cfg.enter_wr
            
            if basic_threshold_met and cv_passed:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
                cv_wr = cv_metrics.get("oof_accuracy", 0.0)
                cv_ci_lower = cv_metrics.get("ci_lower", 0.0)
                
                # –ù—É–∂–Ω–æ: OOF accuracy > –ø–æ—Ä–æ–≥ –ò –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ CI —Ç–æ–∂–µ
                if cv_wr >= self.cfg.enter_wr and cv_ci_lower >= (self.cfg.enter_wr - self.cfg.cv_min_improvement):
                    self.mode = "ACTIVE"
                    if HAVE_RIVER:
                        self.adwin = ADWIN(delta=self.cfg.adwin_delta)
                    print(f"[{self.__class__.__name__}] SHADOW‚ÜíACTIVE ph={ph}: WR={wr_shadow:.2f}%, CV_WR={cv_wr:.2f}% (CI: [{cv_ci_lower:.2f}%, {cv_metrics.get('ci_upper', 0):.2f}%])")
        
        # ACTIVE ‚Üí SHADOW: –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
        if self.mode == "ACTIVE" and wr_active is not None:
            basic_threshold_failed = wr_active < self.cfg.exit_wr
            
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º CV –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
            cv_wr = cv_metrics.get("oof_accuracy", 100.0)
            cv_degraded = cv_wr < self.cfg.exit_wr
            
            if basic_threshold_failed or cv_degraded:
                self.mode = "SHADOW"
                self.validation_passed[ph] = False
                print(f"[{self.__class__.__name__}] ACTIVE‚ÜíSHADOW ph={ph}: WR={wr_active:.2f}%, CV_WR={cv_wr:.2f}%")

    def _maybe_flip_modes_simple(self):
        """–°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è backward compatibility"""
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        wr_shadow = wr(self.shadow_hits, self.cfg.min_ready)
        if self.mode == "SHADOW" and wr_shadow is not None and wr_shadow >= self.cfg.enter_wr:
            self.mode = "ACTIVE"
            if HAVE_RIVER:
                self.adwin = ADWIN(delta=self.cfg.adwin_delta)
        wr_active = wr(self.active_hits, max(30, self.cfg.min_ready // 2))
        if self.mode == "ACTIVE" and (wr_active is not None and wr_active < self.cfg.exit_wr):
            self.mode = "SHADOW"

    def maybe_train(self, ph: Optional[int] = None, reg_ctx: Optional[dict] = None) -> None:
        """–°–æ–≤–º–µ—Å—Ç–∏–º–∞—è –æ–±—ë—Ä—Ç–∫–∞: —Ç—Ä–µ–Ω–∏—Ä—É–µ–º –ø–æ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑–µ (–±–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ä–µ—Ñ–∏—Ç–∞)."""
        if not self.enabled or self.n_feats is None:
            return
        if ph is None:
            if isinstance(reg_ctx, dict) and "phase" in reg_ctx:
                ph = int(reg_ctx["phase"])
            else:
                ph = int(getattr(self, "_last_seen_phase", 0))
        self._maybe_train_phase(int(ph))



    def status(self):
        def _wr(xs):
            if not xs: return None
            return sum(xs) / float(len(xs))
        def _fmt_pct(p):
            return "‚Äî" if p is None else f"{100.0*p:.2f}%"
        
        wr_a = _wr(self.active_hits)
        wr_s = _wr(self.shadow_hits)
        all_hits = (self.active_hits or []) + (self.shadow_hits or [])
        wr_all = _wr(all_hits)
        
        # CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_status = cv_metrics.get("status", "N/A")
        cv_wr = cv_metrics.get("oof_accuracy", 0.0)
        cv_ci = f"[{cv_metrics.get('ci_lower', 0):.1f}%, {cv_metrics.get('ci_upper', 0):.1f}%]" if cv_status == "ok" else "N/A"
        
        # –ù–û–í–û–ï: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        try:
            from training_visualizer import get_visualizer
            viz = get_visualizer()
            
            expert_name = "RF"
            
            viz.record_expert_metrics(
                expert_name=expert_name,
                accuracy=wr_all if wr_all is not None else 0.0,
                n_samples=len(all_hits),
                cv_accuracy=cv_wr / 100.0 if cv_wr > 0 else None,
                cv_ci_lower=cv_metrics.get('ci_lower') if cv_status == "ok" else None,
                cv_ci_upper=cv_metrics.get('ci_upper') if cv_status == "ok" else None,
                mode=self.mode
            )
        except Exception:
            pass
        
        return {
            "mode": self.mode,
            "enabled": self.enabled,
            "wr_active": _fmt_pct(wr_a),
            "n_active": len(self.active_hits or []),
            "wr_shadow": _fmt_pct(wr_s),
            "n_shadow": len(self.shadow_hits or []),
            "wr_all": _fmt_pct(wr_all),
            "n": len(all_hits),
            "cv_oof_wr": _fmt_pct(cv_wr / 100.0) if cv_wr > 0 else "‚Äî",
            "cv_ci": cv_ci,
            "cv_validated": str(self.validation_passed.get(ph, False))
        }



# ---------- ARF (River) ----------
class RiverARFExpert(_BaseExpert):
    def __init__(self, cfg: MLConfig):
        self.cfg = cfg
        self.enabled = HAVE_RIVER and (river_forest is not None)
        self.mode = "SHADOW"
        self.adwin = ADWIN(delta=self.cfg.adwin_delta) if HAVE_RIVER else None
        self.clf = None
        if self.enabled:
            try:
                self.clf = river_forest.ARFClassifier(n_models=self.cfg.arf_n_models, seed=42)
            except Exception:
                self.clf = None
                self.enabled = False

        self.shadow_hits: List[int] = []
        self.active_hits: List[int] = []

        from collections import deque
        self._seen_epochs = deque(maxlen=5000)

        # –§–∞–∑–æ–≤–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
        self.P = int(getattr(self.cfg, "phase_count", 6))
        self.cal_ph = {p: None for p in range(self.P)}
        self._last_seen_phase = 0
        self.n_feats: Optional[int] = None

        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å –¥–ª—è CV (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø—Ä–∏–º–µ—Ä–æ–≤)
        # River —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–Ω–ª–∞–π–Ω, –Ω–æ –¥–ª—è CV –Ω—É–∂–Ω–∞ –Ω–µ–±–æ–ª—å—à–∞—è –∏—Å—Ç–æ—Ä–∏—è
        cv_window = int(getattr(self.cfg, "cv_oof_window", 2000))
        self.X: deque = deque(maxlen=cv_window)
        self.y: deque = deque(maxlen=cv_window)
        
        # –§–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è)
        phase_cap = int(getattr(self.cfg, "phase_memory_cap", 2000))
        self.X_ph: Dict[int, deque] = {p: deque(maxlen=phase_cap) for p in range(self.P)}
        self.y_ph: Dict[int, deque] = {p: deque(maxlen=phase_cap) for p in range(self.P)}
        self.new_since_train = 0
        self.new_since_train_ph: Dict[int, int] = {p: 0 for p in range(self.P)}

        # Cross-validation tracking (per phase)
        self.cv_oof_preds: Dict[int, deque] = {p: deque(maxlen=cv_window) for p in range(self.P)}
        self.cv_oof_labels: Dict[int, deque] = {p: deque(maxlen=cv_window) for p in range(self.P)}
        self.cv_metrics: Dict[int, Dict] = {p: {} for p in range(self.P)}
        self.cv_last_check: Dict[int, int] = {p: 0 for p in range(self.P)}
        self.validation_passed: Dict[int, bool] = {p: False for p in range(self.P)}

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–æ–≤
        for p in range(self.P):
            try:
                self.cal_ph[p] = _BaseCal.load(self._cal_path(self.cfg.arf_cal_path, p))
            except Exception:
                self.cal_ph[p] = None

        self._load_all()

    def _cal_path(self, base: str, ph: int) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—É—Ç—å –∫ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ–∞–∑—ã"""
        root, ext = os.path.splitext(base)
        return f"{root}_ph{int(ph)}{ext}"

    def _ensure_dim(self, x_raw: np.ndarray):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        d = int(x_raw.reshape(1, -1).shape[1])
        if self.n_feats is None:
            self.n_feats = d
        elif self.n_feats != d:
            # –°–º–µ–Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ - –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            self.n_feats = d
            self.clf = None
            if self.enabled:
                try:
                    self.clf = river_forest.ARFClassifier(n_models=self.cfg.arf_n_models, seed=42)
                except Exception:
                    self.clf = None
                    self.enabled = False
            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã
            cv_window = int(getattr(self.cfg, "cv_oof_window", 2000))
            self.X = deque(maxlen=cv_window)
            self.y = deque(maxlen=cv_window)
            phase_cap = int(getattr(self.cfg, "phase_memory_cap", 2000))
            self.X_ph = {p: deque(maxlen=phase_cap) for p in range(self.P)}
            self.y_ph = {p: deque(maxlen=phase_cap) for p in range(self.P)}

    def _load_all(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        try:
            if os.path.exists(self.cfg.arf_state_path):
                with open(self.cfg.arf_state_path, "r") as f:
                    st = json.load(f)
                self.mode = st.get("mode", "SHADOW")
                self.shadow_hits = st.get("shadow_hits", [])[-1000:]
                self.active_hits = st.get("active_hits", [])[-1000:]
                self.n_feats = st.get("n_feats")
        except Exception:
            pass
        
        if self.enabled:
            try:
                if os.path.exists(self.cfg.arf_model_path):
                    with open(self.cfg.arf_model_path, "rb") as f:
                        self.clf = pickle.load(f)
            except Exception:
                pass

    def _save_all(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è"""
        try:
            with open(self.cfg.arf_state_path, "w", encoding="utf-8") as f:
                json.dump({
                    "mode": self.mode,
                    "shadow_hits": self.shadow_hits[-1000:],
                    "active_hits": self.active_hits[-1000:],
                    "n_feats": self.n_feats,
                }, f)
        except Exception:
            pass

        if self.enabled and self.clf is not None:
            try:
                with open(self.cfg.arf_model_path, "wb") as f:
                    pickle.dump(self.clf, f)
            except Exception:
                pass

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–æ–≤
        try:
            for ph, cal in (self.cal_ph or {}).items():
                if cal is not None and getattr(cal, "ready", False):
                    cal_path = self._cal_path(self.cfg.arf_cal_path, ph)
                    try:
                        cal.save(cal_path)
                    except Exception:
                        pass
        except Exception:
            pass

    def _to_dict(self, x_raw: np.ndarray) -> Dict[str, float]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç numpy –º–∞—Å—Å–∏–≤ –≤ dict –¥–ª—è River"""
        return {f"f{k}": float(v) for k, v in enumerate(x_raw.ravel().tolist())}

    def _predict_raw(self, x_raw: np.ndarray) -> Optional[float]:
        """–°—ã—Ä–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
        if not self.enabled or self.clf is None:
            return None
        try:
            pmap = self.clf.predict_proba_one(self._to_dict(x_raw))
            p = float(pmap.get(True, pmap.get(1, 0.5)))
            return float(min(max(p, 1e-6), 1.0 - 1e-6))
        except Exception:
            return None

    def proba_up(self, x_raw: np.ndarray, reg_ctx: Optional[dict] = None) -> Tuple[Optional[float], str]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ UP —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π"""
        if not self.enabled or self.clf is None:
            return (None, "DISABLED" if not self.enabled else self.mode)
        
        try:
            self._ensure_dim(x_raw)
            
            # –°—ã—Ä–æ–π –ø—Ä–æ–≥–Ω–æ–∑
            p = self._predict_raw(x_raw)
            if p is None:
                return (None, self.mode)

            # –§–∞–∑–æ–≤–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
            ph = int(reg_ctx.get("phase")) if isinstance(reg_ctx, dict) and "phase" in reg_ctx else 0
            self._last_seen_phase = ph
            cal = self.cal_ph.get(ph)
            if cal is not None and getattr(cal, "ready", False):
                try:
                    p = float(cal.transform(float(p)))
                except Exception:
                    pass

            p = float(min(max(p, 1e-6), 1.0 - 1e-6))
            return (p, self.mode)
        except Exception:
            return (None, self.mode)

    def record_result(self, x_raw: np.ndarray, y_up: int, used_in_live: bool,
                    p_pred: Optional[float] = None, reg_ctx: Optional[dict] = None) -> None:
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –æ–Ω–ª–∞–π–Ω.
        River ARF –æ–±—É—á–∞–µ—Ç—Å—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.
        """
        if not self.enabled or self.clf is None:
            return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        self._ensure_dim(x_raw)

        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ epoch
        try:
            eid = int(reg_ctx.get("epoch")) if isinstance(reg_ctx, dict) and "epoch" in reg_ctx else None
        except Exception:
            eid = None
        if eid is not None and eid in self._seen_epochs:
            return
        if eid is not None:
            self._seen_epochs.append(eid)

        # === –û–ù–õ–ê–ô–ù-–û–ë–£–ß–ï–ù–ò–ï RIVER ARF ===
        # –ì–ª–∞–≤–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ River: —É—á–∏—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º –ø—Ä–∏–º–µ—Ä–µ –±–µ–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        try:
            self.clf.learn_one(self._to_dict(x_raw), bool(y_up))
        except Exception:
            pass

        # === –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–£–§–ï–†–´ (–¥–ª—è CV –∏ –º–µ—Ç—Ä–∏–∫) ===
        self.X.append(x_raw.astype(np.float32).ravel().tolist())
        self.y.append(int(y_up))
        self.new_since_train += 1

        # –§–∞–∑–∞
        ph = 0
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
        self._last_seen_phase = ph

        # –§–∞–∑–æ–≤–∞—è –ø–∞–º—è—Ç—å
        self.X_ph[ph].append(x_raw.astype(np.float32).ravel().tolist())
        self.y_ph[ph].append(int(y_up))
        self.new_since_train_ph[ph] = self.new_since_train_ph.get(ph, 0) + 1

        # === –¢–†–ï–ö–ò–ù–ì –ö–ê–ß–ï–°–¢–í–ê –ò DRIFT DETECTION ===
        if p_pred is not None:
            try:
                hit = int((float(p_pred) >= 0.5) == bool(y_up))
                
                if self.mode == "ACTIVE" and used_in_live:
                    self.active_hits.append(hit)
                    if self.adwin is not None:
                        try:
                            in_drift = self.adwin.update(1 - hit)
                            if in_drift:
                                self.mode = "SHADOW"
                                self.active_hits = []
                        except Exception:
                            pass
                else:
                    self.shadow_hits.append(hit)
            except Exception:
                pass

        # === OOF PREDICTIONS –î–õ–Ø CV ===
        if getattr(self.cfg, "cv_enabled", False) and p_pred is not None:
            self.cv_oof_preds[ph].append(float(p_pred))
            self.cv_oof_labels[ph].append(int(y_up))

        # === –§–ê–ó–û–í–ê–Ø –ö–ê–õ–ò–ë–†–û–í–ö–ê ===
        try:
            p_raw = self._predict_raw(x_raw)
            if p_raw is not None:
                if self.cal_ph[ph] is None:
                    try:
                        from prob_calibrators import make_calibrator
                        cal_method = getattr(self.cfg, "arf_calibration_method", "logistic")
                        self.cal_ph[ph] = make_calibrator(cal_method)
                    except Exception:
                        pass
                
                if self.cal_ph[ph] is not None:
                    self.cal_ph[ph].observe(float(p_raw), int(y_up))
                    if self.cal_ph[ph].maybe_fit(min_samples=200, every=100):
                        cal_path = self._cal_path(self.cfg.arf_cal_path, ph)
                        self.cal_ph[ph].save(cal_path)
        except Exception:
            pass

        # === –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø CV –ü–†–û–í–ï–†–ö–ê ===
        self.cv_last_check[ph] = self.cv_last_check.get(ph, 0) + 1
        
        if getattr(self.cfg, "cv_enabled", False):
            cv_check_every = int(getattr(self.cfg, "cv_check_every", 200))
            if self.cv_last_check[ph] >= cv_check_every:
                self.cv_last_check[ph] = 0
                cv_results = self._run_cv_validation(ph)
                self.cv_metrics[ph] = cv_results
                
                if cv_results.get("status") == "ok":
                    self.validation_passed[ph] = True
                    print(f"[ARF] CV ph={ph}: "
                        f"ACC={cv_results['oof_accuracy']:.2f}% "
                        f"CI=[{cv_results['ci_lower']:.2f}%, {cv_results['ci_upper']:.2f}%] "
                        f"n={cv_results['oof_samples']}")

        # === –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –†–ï–ñ–ò–ú–û–í ===
        self._maybe_flip_modes()
        
        # === –°–û–•–†–ê–ù–ï–ù–ò–ï ===
        self._save_all()

    def _get_phase_train(self, ph: int) -> Tuple[np.ndarray, np.ndarray]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è/–≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–∑—ã"""
        if not self.X_ph[ph]:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        X = np.array(list(self.X_ph[ph]), dtype=np.float32)
        y = np.array(list(self.y_ph[ph]), dtype=np.int32)
        return X, y

    def _run_cv_validation(self, ph: int) -> Dict:
        """
        –ü—Ä–æ—Å—Ç–∞—è walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è River ARF.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –±—É—Ñ–µ—Ä–∞.
        """
        X_all, y_all = self._get_phase_train(ph)
        
        cv_min_train = int(getattr(self.cfg, "cv_min_train_size", 100))
        if len(X_all) < cv_min_train:
            return {"status": "insufficient_data", "oof_accuracy": 0.0, "oof_samples": 0}
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º OOF predictions –∏–∑ –±—É—Ñ–µ—Ä–∞ (—á–µ—Å—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
        if ph in self.cv_oof_preds and len(self.cv_oof_preds[ph]) >= cv_min_train:
            preds = np.array(list(self.cv_oof_preds[ph]))
            labels = np.array(list(self.cv_oof_labels[ph]))
            
            oof_accuracy = 100.0 * np.mean((preds >= 0.5) == labels)
            
            # Bootstrap CI
            ci_lower, ci_upper = self._bootstrap_ci(
                preds, labels,
                n_bootstrap=int(getattr(self.cfg, "cv_bootstrap_n", 100)),
                confidence=float(getattr(self.cfg, "cv_confidence", 0.95))
            )
            
            return {
                "status": "ok",
                "oof_accuracy": oof_accuracy,
                "ci_lower": ci_lower,
                "ci_upper": ci_upper,
                "oof_samples": len(preds)
            }
        
        # Fallback: –ø—Ä–æ—Å—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        n_test = max(50, len(X_all) // 5)
        X_train, y_train = X_all[:-n_test], y_all[:-n_test]
        X_test, y_test = X_all[-n_test:], y_all[-n_test:]
        
        if len(X_train) < cv_min_train // 2:
            return {"status": "insufficient_train", "oof_accuracy": 0.0, "oof_samples": 0}
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        temp_clf = None
        if HAVE_RIVER:
            try:
                temp_clf = river_forest.ARFClassifier(n_models=self.cfg.arf_n_models, seed=42)
                for i in range(len(X_train)):
                    x_dict = {f"f{k}": float(v) for k, v in enumerate(X_train[i])}
                    temp_clf.learn_one(x_dict, bool(y_train[i]))
            except Exception:
                temp_clf = None
        
        if temp_clf is None:
            return {"status": "temp_model_failed", "oof_accuracy": 0.0, "oof_samples": 0}
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        preds = []
        for i in range(len(X_test)):
            x_dict = {f"f{k}": float(v) for k, v in enumerate(X_test[i])}
            pmap = temp_clf.predict_proba_one(x_dict)
            p = float(pmap.get(True, pmap.get(1, 0.5)))
            preds.append(p)
        
        preds = np.array(preds)
        oof_accuracy = 100.0 * np.mean((preds >= 0.5) == y_test)
        
        ci_lower, ci_upper = self._bootstrap_ci(
            preds, y_test,
            n_bootstrap=int(getattr(self.cfg, "cv_bootstrap_n", 100)),
            confidence=float(getattr(self.cfg, "cv_confidence", 0.95))
        )
        
        return {
            "status": "ok",
            "oof_accuracy": oof_accuracy,
            "ci_lower": ci_lower,
            "ci_upper": ci_upper,
            "oof_samples": len(preds)
        }

    def _bootstrap_ci(self, preds: np.ndarray, labels: np.ndarray, 
                    n_bootstrap: int, confidence: float) -> tuple:
        """Bootstrap confidence intervals –¥–ª—è accuracy"""
        accuracies = []
        n = len(preds)
        
        if n < 10:
            return (0.0, 100.0)
        
        for _ in range(n_bootstrap):
            idx = np.random.choice(n, size=n, replace=True)
            boot_preds = preds[idx]
            boot_labels = labels[idx]
            boot_acc = 100.0 * np.mean((boot_preds >= 0.5) == boot_labels)
            accuracies.append(boot_acc)
        
        accuracies = np.array(accuracies)
        alpha = 1.0 - confidence
        ci_lower = np.percentile(accuracies, 100 * alpha / 2)
        ci_upper = np.percentile(accuracies, 100 * (1 - alpha / 2))
        
        return ci_lower, ci_upper

    def maybe_train(self, ph: Optional[int] = None, reg_ctx: Optional[dict] = None) -> None:
        """
        River ARF –æ–±—É—á–∞–µ—Ç—Å—è –æ–Ω–ª–∞–π–Ω –≤ record_result(), –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø—É—Å—Ç–æ–π.
        –û—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º _BaseExpert.
        """
        pass

    def _maybe_flip_modes(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ SHADOW ‚Üî ACTIVE —Å —É—á–µ—Ç–æ–º CV"""
        def wr(arr, n):
            if len(arr) < n:
                return None
            window = arr[-n:]
            return 100.0 * (sum(window) / len(window))
        
        min_ready = int(getattr(self.cfg, "min_ready", 500))
        enter_wr = float(getattr(self.cfg, "enter_wr", 55.0))
        exit_wr = float(getattr(self.cfg, "exit_wr", 50.0))
        cv_enabled = getattr(self.cfg, "cv_enabled", True)
        
        wr_shadow = wr(self.shadow_hits, min_ready)
        wr_active = wr(self.active_hits, max(30, min_ready // 2))
        
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_passed = self.validation_passed.get(ph, False)
        
        # SHADOW ‚Üí ACTIVE
        if self.mode == "SHADOW" and wr_shadow is not None:
            basic_met = wr_shadow >= enter_wr
            
            if cv_enabled and basic_met and cv_passed:
                cv_wr = cv_metrics.get("oof_accuracy", 0.0)
                cv_ci_lower = cv_metrics.get("ci_lower", 0.0)
                cv_min_improvement = float(getattr(self.cfg, "cv_min_improvement", 2.0))
                
                if cv_wr >= enter_wr and cv_ci_lower >= (enter_wr - cv_min_improvement):
                    self.mode = "ACTIVE"
                    if HAVE_RIVER:
                        self.adwin = ADWIN(delta=self.cfg.adwin_delta)
                    print(f"[ARF] SHADOW‚ÜíACTIVE ph={ph}: WR={wr_shadow:.2f}%, "
                          f"CV={cv_wr:.2f}% (CI: [{cv_ci_lower:.2f}%, {cv_metrics.get('ci_upper', 0):.2f}%])")
            elif not cv_enabled and basic_met:
                self.mode = "ACTIVE"
                if HAVE_RIVER:
                    self.adwin = ADWIN(delta=self.cfg.adwin_delta)
        
        # ACTIVE ‚Üí SHADOW
        if self.mode == "ACTIVE" and wr_active is not None:
            basic_failed = wr_active < exit_wr
            
            cv_wr = cv_metrics.get("oof_accuracy", 100.0)
            cv_degraded = cv_enabled and cv_wr < exit_wr
            
            if basic_failed or cv_degraded:
                self.mode = "SHADOW"
                self.validation_passed[ph] = False
                print(f"[ARF] ACTIVE‚ÜíSHADOW ph={ph}: WR={wr_active:.2f}%, CV={cv_wr:.2f}%")

    def status(self):
        def _wr(xs):
            if not xs: return None
            return sum(xs) / float(len(xs))
        def _fmt_pct(p):
            return "‚Äî" if p is None else f"{100.0*p:.2f}%"
        
        wr_a = _wr(self.active_hits)
        wr_s = _wr(self.shadow_hits)
        all_hits = (self.active_hits or []) + (self.shadow_hits or [])
        wr_all = _wr(all_hits)
        
        # CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_status = cv_metrics.get("status", "N/A")
        cv_wr = cv_metrics.get("oof_accuracy", 0.0)
        cv_ci = f"[{cv_metrics.get('ci_lower', 0):.1f}%, {cv_metrics.get('ci_upper', 0):.1f}%]" if cv_status == "ok" else "N/A"
        
        # –ù–û–í–û–ï: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        try:
            from training_visualizer import get_visualizer
            viz = get_visualizer()
            
            expert_name = "ARF"
            
            viz.record_expert_metrics(
                expert_name=expert_name,
                accuracy=wr_all if wr_all is not None else 0.0,
                n_samples=len(all_hits),
                cv_accuracy=cv_wr / 100.0 if cv_wr > 0 else None,
                cv_ci_lower=cv_metrics.get('ci_lower') if cv_status == "ok" else None,
                cv_ci_upper=cv_metrics.get('ci_upper') if cv_status == "ok" else None,
                mode=self.mode
            )
        except Exception:
            pass
        
        return {
            "mode": self.mode,
            "enabled": self.enabled,
            "wr_active": _fmt_pct(wr_a),
            "n_active": len(self.active_hits or []),
            "wr_shadow": _fmt_pct(wr_s),
            "n_shadow": len(self.shadow_hits or []),
            "wr_all": _fmt_pct(wr_all),
            "n": len(all_hits),
            "cv_oof_wr": _fmt_pct(cv_wr / 100.0) if cv_wr > 0 else "‚Äî",
            "cv_ci": cv_ci,
            "cv_validated": str(self.validation_passed.get(ph, False))
        }



# =============================
# NNExpert ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è MLP —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π (–ü–û –§–ê–ó–ê–ú)
# =============================
class _SimpleMLP:
    def __init__(self, n_in: int, n_h: int, eta: float, l2: float):
        rng = np.random.default_rng(42)
        self.n_in, self.n_h = int(n_in), int(n_h)
        self.W1 = rng.normal(0, 0.1, size=(n_in, n_h)).astype(np.float32)
        self.b1 = np.zeros(n_h, dtype=np.float32)
        self.W2 = rng.normal(0, 0.1, size=(n_h,)).astype(np.float32)
        self.b2 = np.float32(0.0)
        self.eta = float(eta)
        self.l2 = float(l2)

    @staticmethod
    def _sigmoid(z):
        z = np.clip(z, -60.0, 60.0)
        return 1.0/(1.0 + np.exp(-z))

    @staticmethod
    def _tanh(z):
        return np.tanh(z)

    def forward_logits(self, X: np.ndarray) -> np.ndarray:
        H = self._tanh(X @ self.W1 + self.b1)
        z = H @ self.W2 + self.b2
        return z.astype(np.float32), H.astype(np.float32)

    def predict_proba(self, X: np.ndarray, T: float = 1.0) -> np.ndarray:
        z, _ = self.forward_logits(X)
        zT = z / max(1e-3, float(T))
        return self._sigmoid(zT).astype(np.float32)

    def fit_epoch(self, X: np.ndarray, y: np.ndarray, batch_size: int = 128):
        n = len(X)
        if n <= 0:
            return
        idx = np.arange(n)
        np.random.shuffle(idx)
        for start in range(0, n, batch_size):
            sl = idx[start:start+batch_size]
            xb, yb = X[sl], y[sl]
            z, H = self.forward_logits(xb)
            p = self._sigmoid(z)
            g = (p - yb).reshape(-1, 1)  # (B,1)
            # grads
            dW2 = (H * g).mean(axis=0) + self.l2 * self.W2
            db2 = g.mean()
            dH = g * (1.0 - H*H)  # tanh'
            dW1 = (xb.T @ dH).astype(np.float32)/len(xb) + self.l2 * self.W1
            db1 = dH.mean(axis=0)
            # step
            self.W2 -= self.eta * dW2
            self.b2 -= self.eta * db2
            self.W1 -= self.eta * dW1
            self.b1 -= self.eta * db1

    def save(self, path: str):
        obj = dict(W1=self.W1, b1=self.b1, W2=self.W2, b2=self.b2, n_in=self.n_in, n_h=self.n_h, eta=self.eta, l2=self.l2)
        with open(path, "wb") as f:
            pickle.dump(obj, f)

    @staticmethod
    def load(path: str) -> Optional["_SimpleMLP"]:
        try:
            with open(path, "rb") as f:
                obj = pickle.load(f)
            m = _SimpleMLP(obj["n_in"], obj["n_h"], obj["eta"], obj["l2"])
            m.W1, m.b1, m.W2, m.b2 = obj["W1"], obj["b1"], obj["W2"], obj["b2"]
            return m
        except Exception:
            return None


class NNExpert(_BaseExpert):
    def __init__(self, cfg: MLConfig):
        self.cfg = cfg
        self.enabled = True  # –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self.mode = "SHADOW"
        self.adwin = ADWIN(delta=self.cfg.adwin_delta) if HAVE_RIVER else None

        # –°–∫–µ–π–ª–µ—Ä + —Å–µ—Ç—å
        self.scaler: Optional[StandardScaler] = None
        self.net: Optional[_SimpleMLP] = None
        # --- –ù–û–í–û–ï: –ø–µ—Ä–µ—Ñ–∞–∑–Ω—ã–µ —Å–µ—Ç–∏ –∏ —Å–∫–µ–π–ª–µ—Ä—ã ---
        self.net_ph: Dict[int, Optional[_SimpleMLP]] = {}
        self.scaler_ph: Dict[int, Optional[StandardScaler]] = {}
        self.n_feats: Optional[int] = None

        # ===== –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å (—Ö–≤–æ—Å—Ç), –∫–∞–∫ –±—ã–ª–æ =====
        self.X: List[List[float]] = []
        self.y: List[int] = []
        self.new_since_train: int = 0

        # ===== –§–ê–ó–û–í–ê–Ø –ü–ê–ú–Ø–¢–¨ =====
        self.P: int = int(getattr(self.cfg, "phase_count", 6))  # 6 —Ñ–∞–∑ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.X_ph: Dict[int, List[List[float]]] = {p: [] for p in range(self.P)}
        self.y_ph: Dict[int, List[int]]         = {p: [] for p in range(self.P)}
        self.new_since_train_ph: Dict[int, int] = {p: 0  for p in range(self.P)}
        self._last_seen_phase: int = 0

        # ===== –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π –ü–û –§–ê–ó–ê–ú =====
        # T_ph[œÜ] ‚Äî —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Ñ–∞–∑—ã; seen_since_calib_ph[œÜ] ‚Äî –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–µ—Å—á—ë—Ç–∞
        self.T_ph: Dict[int, float] = {p: 1.0 for p in range(self.P)}
        self.seen_since_calib_ph: Dict[int, int] = {p: 0 for p in range(self.P)}
        # –°—Ç–∞—Ä–æ–µ –ø–æ–ª–µ T –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ)
        self.T: float = 1.0
        # Cross-validation tracking (per phase)
        self.cv_oof_preds: Dict[int, deque] = {p: deque(maxlen=cfg.cv_oof_window) for p in range(self.P)}
        self.cv_oof_labels: Dict[int, deque] = {p: deque(maxlen=cfg.cv_oof_window) for p in range(self.P)}
        self.cv_metrics: Dict[int, Dict] = {p: {} for p in range(self.P)}
        self.cv_last_check: Dict[int, int] = {p: 0 for p in range(self.P)}
        
        # Validation mode tracking
        self.validation_passed: Dict[int, bool] = {p: False for p in range(self.P)}

        # –•–∏—Ç—ã
        self.shadow_hits: List[int] = []
        self.active_hits: List[int] = []

        self._load_all()

    # ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –£–¢–ò–õ–´ ----------
    @staticmethod
    def _clip01(p: float) -> float:
        return float(min(max(p, 1e-6), 1 - 1e-6))

    @staticmethod
    def _sigmoid(z: float) -> float:
        z = float(np.clip(z, -60.0, 60.0))
        return 1.0/(1.0 + math.exp(-z))

    @staticmethod
    def _logit(p: float) -> float:
        p = NNExpert._clip01(p)
        return math.log(p / (1 - p))

    def _ensure_dim(self, x_raw: np.ndarray):
        d = int(x_raw.reshape(1, -1).shape[1])
        if self.n_feats is None or self.n_feats != d:
            # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–¥ –Ω–æ–≤—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            self.n_feats = d
            self.net = None
            self.scaler = None
            self.X, self.y = [], []
            self.new_since_train = 0
            # —Ñ–∞–∑–æ–≤—ã–µ –±—É—Ñ–µ—Ä—ã –∏ —Å—á—ë—Ç—á–∏–∫–∏ —Ç–æ–∂–µ –ª—É—á—à–µ —Å–±—Ä–æ—Å–∏—Ç—å, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞–ª–∏—Å—å —Ä–∞–∑–Ω—ã–µ d
            self.X_ph = {p: [] for p in range(self.P)}
            self.y_ph = {p: [] for p in range(self.P)}
            self.new_since_train_ph = {p: 0 for p in range(self.P)}
            self.net_ph     = {p: None for p in range(self.P)}
            self.scaler_ph  = {p: None for p in range(self.P)}
            self.seen_since_calib_ph = {p: 0 for p in range(self.P)}
            self.T_ph = {p: 1.0 for p in range(self.P)}

    def _transform(self, X: np.ndarray) -> np.ndarray:
        if self.scaler is None:
            return X.astype(np.float32)
        return self.scaler.transform(X.astype(np.float32))

    def _get_global_tail(self, n: int) -> Tuple[np.ndarray, np.ndarray]:
        if n <= 0 or not self.X:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        Xg = np.array(self.X[-n:], dtype=np.float32)
        yg = np.array(self.y[-n:], dtype=np.int32)
        return Xg, yg

    def _get_past_phases_tail(self, ph: int, n: int) -> Tuple[np.ndarray, np.ndarray]:
        # –ë–µ—Ä–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –∑–∞–ø–∏—Å–µ–π —Ç–æ–ª—å–∫–æ –∏–∑ —Ñ–∞–∑ 0..ph (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        # –ò—Å–∫–ª—é—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É–¥—É—â–∏—Ö —Ñ–∞–∑ ‚Üí –Ω–µ—Ç —É—Ç–µ—á–∫–∏
        if n <= 0:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–∑ 0..ph
        X_past = []
        y_past = []
        for p in range(min(ph + 1, self.P)):
            if self.X_ph.get(p):
                X_past.extend(self.X_ph[p])
                y_past.extend(self.y_ph[p])
        
        if not X_past:
            return np.empty((0, self.n_feats or 0), dtype=np.float32), np.empty((0,), dtype=np.int32)
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ n –∑–∞–ø–∏—Å–µ–π
        X_past = X_past[-n:]
        y_past = y_past[-n:]
        
        return np.array(X_past, dtype=np.float32), np.array(y_past, dtype=np.int32)

    def _get_phase_train(self, ph: int) -> Tuple[np.ndarray, np.ndarray]:
        # X_phase
        Xp = np.array(self.X_ph[ph], dtype=np.float32) if self.X_ph[ph] else np.empty((0, self.n_feats or 0), dtype=np.float32)
        yp = np.array(self.y_ph[ph], dtype=np.int32)   if self.y_ph[ph]  else np.empty((0,), dtype=np.int32)

        if len(Xp) >= int(self.cfg.phase_min_ready):
            return Xp, yp

        # –∏–Ω–∞—á–µ —Å–º–µ—à–∏–≤–∞–µ–º X_phase ‚à™ X_past_phases_tail (70/30 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—ã–µ —Ñ–∞–∑—ã (0..ph), –∞ –Ω–µ –≤–µ—Å—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ö–≤–æ—Å—Ç
        share = float(self.cfg.phase_mix_global_share)  # 0.30
        need_g = int(round(len(Xp) * share / max(1e-9, (1.0 - share))))
        need_g = max(need_g, int(self.cfg.phase_min_ready) - len(Xp))   # –Ω–µ –º–µ–Ω–µ–µ, —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å –ø–æ—Ä–æ–≥–∞
        
        # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω–æ –≤ —Ñ–∞–∑–∞—Ö 0..ph
        available_past = sum(len(self.X_ph.get(p, [])) for p in range(min(ph + 1, self.P)))
        need_g = min(need_g, available_past)  # –Ω–µ –±–æ–ª—å—à–µ, —á–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ –≤ –ø—Ä–æ—à–ª—ã—Ö —Ñ–∞–∑–∞—Ö
        
        Xg, yg = self._get_past_phases_tail(ph, need_g)
        if len(Xg) == 0:
            return Xp, yp

        X = np.concatenate([Xp, Xg], axis=0)
        y = np.concatenate([yp, yg], axis=0)
        return X, y

    def _nll_with_T(self, z_list: np.ndarray, y: np.ndarray, T: float) -> float:
        zT = z_list / float(max(T, 1e-6))
        p = 1.0 / (1.0 + np.exp(-np.clip(zT, -60, 60)))
        p = np.clip(p, 1e-6, 1 - 1e-6)
        return float(-np.mean(y * np.log(p) + (1 - y) * np.log(1 - p)))

    def _maybe_recalibrate_T(self, ph: int) -> None:
        """–£–ü–†–û–©–ï–ù–û: –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ T=1.0 (–±–µ–∑ grid search)."""
        # –û–¢–ö–õ–Æ–ß–ï–ù–û: grid search –ø–æ 25 —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞–º
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
        self.T_ph[ph] = 1.0
        self.seen_since_calib_ph[ph] = 0
        return

    # ---------- API –≠–ö–°–ü–ï–†–¢–ê ----------
    def proba_up(self, x_raw: np.ndarray, reg_ctx: Optional[dict] = None) -> Tuple[Optional[float], str]:
        try:
            self._ensure_dim(x_raw)
        except Exception:
            pass

        # —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Ñ–∞–∑–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –≤ reg_ctx["phase"] (–≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å –≤—ã—à–µ –ø–æ –∫–æ–¥—É)
        ph = 0
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
        self._last_seen_phase = ph

        # —Å–µ—Ç—å / —Å–∫–µ–π–ª–µ—Ä –ø–æ —Ñ–∞–∑–µ (fallback –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ, –µ—Å–ª–∏ –Ω–µ—Ç)
        net = (self.net_ph.get(ph) if hasattr(self, "net_ph") else None) or self.net
        scaler = (self.scaler_ph.get(ph) if hasattr(self, "scaler_ph") else None) or self.scaler
        if net is None:
            return (None, self.mode)

        try:
            X = x_raw.reshape(1, -1).astype(np.float32)
            Xt = scaler.transform(X) if scaler is not None else X
            T = float(self.T_ph.get(ph, 1.0))
            p = float(net.predict_proba(Xt, T=T)[0])
            p = self._clip01(p)
            return (p, self.mode)
        except Exception:
            return (None, self.mode)


    def record_result(self, x_raw: np.ndarray, y_up: int, used_in_live: bool,
                    p_pred: Optional[float] = None, reg_ctx: Optional[dict] = None) -> None:
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å.
        
        –¢–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç:
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –∏ —Ñ–∞–∑–æ–≤—É—é –ø–∞–º—è—Ç—å
        - –¢—Ä–µ–∫–∏–Ω–≥ —Ö–∏—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        - Out-of-fold predictions –¥–ª—è cross-validation
        - –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é CV –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        - –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        - –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ SHADOW/ACTIVE –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        """
        
        # ========== –ë–õ–û–ö 1: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ü–†–û–í–ï–†–ö–ê –†–ê–ó–ú–ï–†–ù–û–°–¢–ò ==========
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ñ–∏—á–µ–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
        self._ensure_dim(x_raw)

        # ========== –ë–õ–û–ö 2: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ì–õ–û–ë–ê–õ–¨–ù–£–Æ –ü–ê–ú–Ø–¢–¨ ==========
        # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback, –∫–æ–≥–¥–∞ –≤ —Ñ–∞–∑–µ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
        self.X.append(x_raw.astype(np.float32).ravel().tolist())
        self.y.append(int(y_up))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –≥–ª–æ–±–∞–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞–ª–∞—Å—å
        if len(self.X) > int(getattr(self.cfg, "max_memory", 10_000)):
            self.X = self.X[-self.cfg.max_memory:]
            self.y = self.y[-self.cfg.max_memory:]
        
        self.new_since_train += 1

        # ========== –ë–õ–û–ö 3: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –§–ê–ó–´ ==========
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (0-5 –¥–ª—è 6 —Ñ–∞–∑)
        ph = 0
        if isinstance(reg_ctx, dict):
            ph = int(reg_ctx.get("phase", 0))
        self._last_seen_phase = ph

        # ========== –ë–õ–û–ö 4: –°–û–•–†–ê–ù–ï–ù–ò–ï –í –§–ê–ó–û–í–£–Æ –ü–ê–ú–Ø–¢–¨ ==========
        # –ö–∞–∂–¥–∞—è —Ñ–∞–∑–∞ —Ö—Ä–∞–Ω–∏—Ç —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏–º–µ—Ä–æ–≤
        # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö
        self.X_ph[ph].append(x_raw.astype(np.float32).ravel().tolist())
        self.y_ph[ph].append(int(y_up))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–∑–æ–≤–æ–π –ø–∞–º—è—Ç–∏
        cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
        if len(self.X_ph[ph]) > cap:
            self.X_ph[ph] = self.X_ph[ph][-cap:]
            self.y_ph[ph] = self.y_ph[ph][-cap:]
        
        self.new_since_train_ph[ph] = self.new_since_train_ph.get(ph, 0) + 1

        # ========== –ë–õ–û–ö 5: –¢–†–ï–ö–ò–ù–ì –•–ò–¢–û–í –ò DRIFT DETECTION ==========
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –¥—Ä–µ–π—Ñ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        if p_pred is not None:
            try:
                # –°—á–∏—Ç–∞–µ–º hit: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ?
                hit = int((float(p_pred) >= 0.5) == bool(y_up))
                
                if self.mode == "ACTIVE" and used_in_live:
                    # –í –∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Å–¥–µ–ª–∫–∏
                    self.active_hits.append(hit)
                    
                    # ADWIN –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –¥—Ä–µ–π—Ñ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫
                    if self.adwin is not None:
                        in_drift = self.adwin.update(1 - hit)  # 1=correct, 0=error
                        if in_drift:
                            # –û–±–Ω–∞—Ä—É–∂–µ–Ω –¥—Ä–µ–π—Ñ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ shadow —Ä–µ–∂–∏–º
                            self.mode = "SHADOW"
                            self.active_hits = []
                else:
                    # –í shadow —Ä–µ–∂–∏–º–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º "—á—Ç–æ –±—ã–ª–æ –±—ã, –µ—Å–ª–∏ –±—ã –≤—Ö–æ–¥–∏–ª–∏"
                    self.shadow_hits.append(hit)
            except Exception:
                pass

        # ========== –ë–õ–û–ö 6: –ù–û–í–û–ï - –°–û–•–†–ê–ù–ï–ù–ò–ï OOF PREDICTIONS –î–õ–Ø CV ==========
        # Out-of-fold predictions –Ω—É–∂–Ω—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ cross-validation
        # –≠—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—ã–ª–∏ —Å–¥–µ–ª–∞–Ω—ã –Ω–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –ù–ï –≤–∏–¥–µ–ª–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        if self.cfg.cv_enabled and p_pred is not None:
            self.cv_oof_preds[ph].append(float(p_pred))
            self.cv_oof_labels[ph].append(int(y_up))

        # ========== –ë–õ–û–ö 7: –§–ê–ó–û–í–ê–Ø –ö–ê–õ–ò–ë–†–û–í–ö–ê ==========
        # –ö–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–∞–∑—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        # –≠—Ç–æ –≤–∞–∂–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ-—Ä–∞–∑–Ω–æ–º—É –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞ –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö
        try:
            p_raw = self._predict_raw(x_raw)
            if p_raw is not None:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –¥–ª—è —ç—Ç–æ–π —Ñ–∞–∑—ã, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                if self.cal_ph[ph] is None:
                    self.cal_ph[ph] = make_calibrator(self.cfg.xgb_calibration_method)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä—É –∏—Å—Ç–∏–Ω–Ω—É—é –ø–∞—Ä—É (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
                self.cal_ph[ph].observe(float(p_raw), int(y_up))
                
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É
                if self.cal_ph[ph].maybe_fit(min_samples=200, every=100):
                    cal_path = self._cal_path(self.cfg.xgb_cal_path, ph)
                    self.cal_ph[ph].save(cal_path)
        except Exception:
            pass

        # ========== –ë–õ–û–ö 8: –ù–û–í–û–ï - –ü–ï–†–ò–û–î–ò–ß–ï–°–ö–ê–Ø CV –ü–†–û–í–ï–†–ö–ê ==========
        # –ö–∞–∂–¥—ã–µ N –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é cross-validation –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –¥–∞–µ—Ç —á–µ—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        self.cv_last_check[ph] += 1
        
        if self.cfg.cv_enabled and self.cv_last_check[ph] >= self.cfg.cv_check_every:
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
            self.cv_last_check[ph] = 0
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é walk-forward cross-validation —Å purging
            cv_results = self._run_cv_validation(ph)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ _maybe_flip_modes
            self.cv_metrics[ph] = cv_results
            
            # –ï—Å–ª–∏ CV –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ, –ø–æ–º–µ—á–∞–µ–º —Ñ–∞–∑—É –∫–∞–∫ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é
            if cv_results.get("status") == "ok":
                self.validation_passed[ph] = True
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            if cv_results.get("status") == "ok":
                print(f"[{self.__class__.__name__}] CV ph={ph}: "
                    f"OOF_ACC={cv_results['oof_accuracy']:.2f}% "
                    f"CI=[{cv_results['ci_lower']:.2f}%, {cv_results['ci_upper']:.2f}%] "
                    f"folds={cv_results['n_folds']}")

        # ========== –ë–õ–û–ö 9: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ü–û –§–ê–ó–ï ==========
        # –ö–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ —Ñ–∞–∑–µ, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
        self._maybe_train_phase(ph)

        # ========== –ë–õ–û–ö 10: –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –†–ï–ñ–ò–ú–û–í ==========
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–≤–∫–ª—é—á–∞—è CV) –∏ —Ä–µ—à–∞–µ–º, –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å –ª–∏ SHADOW ‚Üî ACTIVE
        self._maybe_flip_modes()
        
        # ========== –ë–õ–û–ö 11: –°–û–•–†–ê–ù–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–Ø ==========
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –Ω–∞ –¥–∏—Å–∫ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        self._save_all()

    def _maybe_flip_modes(self):
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ —Å —É—á—ë—Ç–æ–º:
        1. Cross-validation –º–µ—Ç—Ä–∏–∫
        2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (bootstrap CI)
        3. Out-of-fold predictions
        """
        if not self.cfg.cv_enabled:
            # fallback –∫ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
            self._maybe_flip_modes_simple()
            return
        
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        
        # –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        wr_shadow = wr(self.shadow_hits, self.cfg.min_ready)
        wr_active = wr(self.active_hits, max(30, self.cfg.min_ready // 2))
        
        # –ü–æ–ª—É—á–∞–µ–º CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_passed = self.validation_passed.get(ph, False)
        
        # SHADOW ‚Üí ACTIVE: —Ç—Ä–µ–±—É–µ–º CV validation + bootstrap CI
        if self.mode == "SHADOW" and wr_shadow is not None:
            basic_threshold_met = wr_shadow >= self.cfg.enter_wr
            
            if basic_threshold_met and cv_passed:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
                cv_wr = cv_metrics.get("oof_accuracy", 0.0)
                cv_ci_lower = cv_metrics.get("ci_lower", 0.0)
                
                # –ù—É–∂–Ω–æ: OOF accuracy > –ø–æ—Ä–æ–≥ –ò –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ CI —Ç–æ–∂–µ
                if cv_wr >= self.cfg.enter_wr and cv_ci_lower >= (self.cfg.enter_wr - self.cfg.cv_min_improvement):
                    self.mode = "ACTIVE"
                    if HAVE_RIVER:
                        self.adwin = ADWIN(delta=self.cfg.adwin_delta)
                    print(f"[{self.__class__.__name__}] SHADOW‚ÜíACTIVE ph={ph}: WR={wr_shadow:.2f}%, CV_WR={cv_wr:.2f}% (CI: [{cv_ci_lower:.2f}%, {cv_metrics.get('ci_upper', 0):.2f}%])")
        
        # ACTIVE ‚Üí SHADOW: –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
        if self.mode == "ACTIVE" and wr_active is not None:
            basic_threshold_failed = wr_active < self.cfg.exit_wr
            
            # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º CV –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é
            cv_wr = cv_metrics.get("oof_accuracy", 100.0)
            cv_degraded = cv_wr < self.cfg.exit_wr
            
            if basic_threshold_failed or cv_degraded:
                self.mode = "SHADOW"
                self.validation_passed[ph] = False
                print(f"[{self.__class__.__name__}] ACTIVE‚ÜíSHADOW ph={ph}: WR={wr_active:.2f}%, CV_WR={cv_wr:.2f}%")

    def _maybe_flip_modes_simple(self):
        """–°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è backward compatibility"""
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        wr_shadow = wr(self.shadow_hits, self.cfg.min_ready)
        if self.mode == "SHADOW" and wr_shadow is not None and wr_shadow >= self.cfg.enter_wr:
            self.mode = "ACTIVE"
            if HAVE_RIVER:
                self.adwin = ADWIN(delta=self.cfg.adwin_delta)
        wr_active = wr(self.active_hits, max(30, self.cfg.min_ready // 2))
        if self.mode == "ACTIVE" and (wr_active is not None and wr_active < self.cfg.exit_wr):
            self.mode = "SHADOW"

    # --- –æ–±—É—á–µ–Ω–∏–µ NN –ø–æ –§–ê–ó–ï ---
    # --- –æ–±—É—á–µ–Ω–∏–µ NN –ø–æ –§–ê–ó–ï ---
    def _maybe_train_phase(self, ph: int) -> None:
        # –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –≤ —Ñ–∞–∑–µ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
        if self.new_since_train_ph.get(ph, 0) < int(getattr(self.cfg, "nn_retrain_every", 100)):
            return

        # —Å–æ–±–∏—Ä–∞–µ–º –±–∞—Ç—á –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ–∞–∑—ã
        X_all, y_all = self._get_phase_train(ph)
        if len(X_all) < int(self.cfg.phase_min_ready):
            return

        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è –ø–æ —Å–≤–µ–∂–µ—Å—Ç–∏
        train_window = int(getattr(self.cfg, "train_window", 5000))
        if len(X_all) > train_window:
            X_all = X_all[-train_window:]
            y_all = y_all[-train_window:]

        # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–µ—Ç—å –∏ —Å–∫–µ–π–ª–µ—Ä –¥–ª—è –ö–û–ù–ö–†–ï–¢–ù–û–ô —Ñ–∞–∑—ã
        net = self.net_ph.get(ph)
        if net is None and self.n_feats is not None:
            net = _SimpleMLP(
                n_in=self.n_feats,
                n_h=int(getattr(self.cfg, "nn_hidden", 32)),
                eta=float(getattr(self.cfg, "nn_eta", 0.01)),
                l2=float(getattr(self.cfg, "nn_l2", 0.0)),
            )

        # —Å–∫–µ–π–ª–µ—Ä –ø–æ –±–∞—Ç—á—É —Ñ–∞–∑—ã
        scaler = None
        if HAVE_SKLEARN:
            try:
                scaler = StandardScaler().fit(X_all)
            except Exception:
                scaler = None

        # —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ
        Xt = scaler.transform(X_all) if (scaler is not None) else X_all
        y_float = y_all.astype(np.float32)

        try:
            epochs = int(getattr(self.cfg, "nn_epochs", 1))
            for _ in range(max(1, epochs)):
                net.fit_epoch(Xt, y_float, batch_size=128)

            # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å/—Å–∫–µ–π–ª–µ—Ä —Ñ–∞–∑—ã –∏ –æ–±–Ω–æ–≤–∏—Ç—å ¬´–ø–æ—Å–ª–µ–¥–Ω–∏–µ¬ª –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
            self.net_ph[ph] = net
            self.scaler_ph[ph] = scaler
            self.net = net
            self.scaler = scaler

            # —Å–±—Ä–æ—Å —Å—á—ë—Ç—á–∏–∫–∞ ¬´–Ω–æ–≤—ã—Ö —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ç—Ä–µ–Ω–∏–Ω–≥–∞¬ª –¥–ª—è —ç—Ç–æ–π —Ñ–∞–∑—ã
            self.new_since_train_ph[ph] = 0
        except Exception as e:
            print(f"[nn  ] train error (ph={ph}): {e}")
    def _run_cv_validation(self, ph: int) -> Dict:
        """
        Walk-forward purged cross-validation –¥–ª—è —Ñ–∞–∑—ã ph.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏: accuracy, CI bounds, fold scores.
        """
        X_all, y_all = self._get_phase_train(ph)
        
        if len(X_all) < self.cfg.cv_min_train_size:
            return {"status": "insufficient_data", "oof_accuracy": 0.0}
        
        n_samples = len(X_all)
        n_splits = min(self.cfg.cv_n_splits, n_samples // self.cfg.cv_min_train_size)
        
        if n_splits < 2:
            return {"status": "insufficient_splits", "oof_accuracy": 0.0}
        
        # Walk-forward splits —Å purge –∏ embargo
        embargo_size = max(1, int(n_samples * self.cfg.cv_embargo_pct))
        purge_size = max(1, int(n_samples * self.cfg.cv_purge_pct))
        
        fold_size = n_samples // n_splits
        oof_preds = np.zeros(n_samples)
        oof_mask = np.zeros(n_samples, dtype=bool)
        fold_scores = []
        
        for fold_idx in range(n_splits):
            # Test fold
            test_start = fold_idx * fold_size
            test_end = min(test_start + fold_size, n_samples)
            
            # Train: –≤—Å—ë –¥–æ (test_start - purge_size)
            train_end = max(0, test_start - purge_size)
            
            if train_end < self.cfg.cv_min_train_size:
                continue
            
            X_train = X_all[:train_end]
            y_train = y_all[:train_end]
            X_test = X_all[test_start:test_end]
            y_test = y_all[test_start:test_end]
            
            # –û–±—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ train fold
            temp_model = self._train_fold_model(X_train, y_train, ph)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test fold
            preds = self._predict_fold(temp_model, X_test, ph)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º OOF predictions
            oof_preds[test_start:test_end] = preds
            oof_mask[test_start:test_end] = True
            
            # –ú–µ—Ç—Ä–∏–∫–∏ —Ñ–æ–ª–¥–∞
            fold_acc = np.mean((preds >= 0.5) == y_test)
            fold_scores.append(fold_acc)
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ OOF –º–µ—Ç—Ä–∏–∫–∏
        oof_valid = oof_mask.sum()
        if oof_valid < self.cfg.cv_min_train_size:
            return {"status": "insufficient_oof", "oof_accuracy": 0.0}
        
        oof_accuracy = 100.0 * np.mean((oof_preds[oof_mask] >= 0.5) == y_all[oof_mask])
        
        # Bootstrap confidence intervals
        ci_lower, ci_upper = self._bootstrap_ci(
            oof_preds[oof_mask], 
            y_all[oof_mask],
            n_bootstrap=self.cfg.cv_bootstrap_n,
            confidence=self.cfg.cv_confidence
        )
        
        return {
            "status": "ok",
            "oof_accuracy": oof_accuracy,
            "ci_lower": ci_lower,
            "ci_upper": ci_upper,
            "fold_scores": fold_scores,
            "n_folds": len(fold_scores),
            "oof_samples": int(oof_valid)
        }

    def _bootstrap_ci(self, preds: np.ndarray, labels: np.ndarray, 
                    n_bootstrap: int, confidence: float) -> tuple:
        """
        Bootstrap confidence intervals –¥–ª—è accuracy.
        """
        accuracies = []
        n = len(preds)
        
        for _ in range(n_bootstrap):
            # Resample —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º
            idx = np.random.choice(n, size=n, replace=True)
            boot_preds = preds[idx]
            boot_labels = labels[idx]
            boot_acc = 100.0 * np.mean((boot_preds >= 0.5) == boot_labels)
            accuracies.append(boot_acc)
        
        accuracies = np.array(accuracies)
        alpha = 1.0 - confidence
        ci_lower = np.percentile(accuracies, 100 * alpha / 2)
        ci_upper = np.percentile(accuracies, 100 * (1 - alpha / 2))
        
        return ci_lower, ci_upper

    def _train_fold_model(self, X: np.ndarray, y: np.ndarray, ph: int):
        """
        –û–±—É—á–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è CV fold.
        –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–∏–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ (XGB/RF/ARF/NN).
        """
        # –ü—Ä–∏–º–µ—Ä –¥–ª—è XGB
        if not HAVE_XGB:
            return None
        
        scaler = StandardScaler().fit(X) if HAVE_SKLEARN else None
        X_scaled = scaler.transform(X) if scaler else X
        
        dtrain = xgb.DMatrix(X_scaled, label=y)
        model = xgb.train(
            params={
                "objective": "binary:logistic",
                "max_depth": self.cfg.xgb_max_depth,
                "eta": self.cfg.xgb_eta,
                "subsample": self.cfg.xgb_subsample,
                "colsample_bytree": self.cfg.xgb_colsample_bytree,
                "min_child_weight": self.cfg.xgb_min_child_weight,
                "eval_metric": "logloss",
            },
            dtrain=dtrain,
            num_boost_round=self.cfg.xgb_rounds_warm,
            verbose_eval=False
        )
        
        return {"model": model, "scaler": scaler}

    def _predict_fold(self, fold_model, X: np.ndarray, ph: int) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ CV fold.
        """
        if fold_model is None:
            return np.full(len(X), 0.5)
        
        scaler = fold_model.get("scaler")
        model = fold_model.get("model")
        
        X_scaled = scaler.transform(X) if scaler else X
        dtest = xgb.DMatrix(X_scaled)
        preds = model.predict(dtest)
        
        return preds


    def maybe_train(self, ph: Optional[int] = None, reg_ctx: Optional[dict] = None) -> None:
        if ph is None:
            if isinstance(reg_ctx, dict) and "phase" in reg_ctx:
                ph = int(reg_ctx["phase"])
            else:
                ph = int(getattr(self, "_last_seen_phase", 0))
        self._maybe_train_phase(int(ph))

    # ---------- —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ ----------
    def _load_all(self) -> None:
        # state (mode, hits, T, n_feats, —Ñ–∞–∑–æ–≤—ã–µ –±—É—Ñ–µ—Ä—ã, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ —Ñ–∞–∑–∞–º)
        try:
            if os.path.exists(self.cfg.nn_state_path):
                with open(self.cfg.nn_state_path, "r") as f:
                    st = json.load(f)

                self.mode = st.get("mode", "SHADOW")
                self.shadow_hits = st.get("shadow_hits", [])[-1000:]
                self.active_hits = st.get("active_hits", [])[-1000:]
                self.n_feats = st.get("n_feats", None)

                # –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å
                self.X = st.get("X", [])
                self.y = st.get("y", [])

                # —Ñ–∞–∑–æ–≤—ã–µ –±—É—Ñ–µ—Ä—ã
                X_ph = st.get("X_ph"); y_ph = st.get("y_ph")
                if isinstance(X_ph, dict) and isinstance(y_ph, dict):
                    self.X_ph = {int(k): v for k, v in X_ph.items()}
                    self.y_ph = {int(k): v for k, v in y_ph.items()}
                else:
                    self.X_ph = {p: [] for p in range(self.P)}
                    self.y_ph = {p: [] for p in range(self.P)}

                # —Å—á—ë—Ç—á–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
                self.new_since_train_ph = {p: 0 for p in range(self.P)}
                if isinstance(st.get("new_since_train_ph"), dict):
                    for k, v in st["new_since_train_ph"].items():
                        try:
                            self.new_since_train_ph[int(k)] = int(v)
                        except Exception:
                            pass

                # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ —Ñ–∞–∑–∞–º + —Å—á—ë—Ç—á–∏–∫–∏ –¥–ª—è –ø–µ—Ä–µ–∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
                T_ph = st.get("T_ph")
                self.T_ph = {p: 1.0 for p in range(self.P)}
                if isinstance(T_ph, dict):
                    for k, v in T_ph.items():
                        try:
                            self.T_ph[int(k)] = float(v)
                        except Exception:
                            pass
                ssc = st.get("seen_since_calib_ph")
                self.seen_since_calib_ph = {p: 0 for p in range(self.P)}
                if isinstance(ssc, dict):
                    for k, v in ssc.items():
                        try:
                            self.seen_since_calib_ph[int(k)] = int(v)
                        except Exception:
                            pass

                self._last_seen_phase = int(st.get("_last_seen_phase", 0))
                # —Å—Ç–∞—Ä–æ–µ –ø–æ–ª–µ T (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                try:
                    self.T = float(st.get("T", 1.0))
                except Exception:
                    self.T = 1.0

                # –æ–±—Ä–µ–∑–∫–∏ –ø–æ –∫–∞–ø–∞–º
                if isinstance(getattr(self.cfg, "max_memory", None), int) and self.cfg.max_memory > 0:
                    self.X = self.X[-self.cfg.max_memory:]
                    self.y = self.y[-self.cfg.max_memory:]
                cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
                for p in range(self.P):
                    self.X_ph[p] = self.X_ph.get(p, [])[-cap:]
                    self.y_ph[p] = self.y_ph.get(p, [])[-cap:]
        except Exception as e:
            print(f"[nn  ] _load_all state error: {e}")

        # scaler
        try:
            if os.path.exists(self.cfg.nn_scaler_path):
                with open(self.cfg.nn_scaler_path, "rb") as f:
                    self.scaler = pickle.load(f)
        except Exception as e:
            print(f"[nn  ] _load_all scaler error: {e}")
            self.scaler = None

        # model
        try:
            self.net = _SimpleMLP.load(self.cfg.nn_model_path)
        except Exception as e:
            print(f"[nn  ] _load_all model error: {e}")
            self.net = None

        # --- –ù–û–í–û–ï: –∑–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ—Ñ–∞–∑–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ —Å–∫–µ–π–ª–µ—Ä–æ–≤ ---
        try:
            root_m, ext_m = os.path.splitext(self.cfg.nn_model_path)
            root_s, ext_s = os.path.splitext(self.cfg.nn_scaler_path)
            for p in range(self.P):
                mp = f"{root_m}_ph{p}{ext_m}"
                sp = f"{root_s}_ph{p}{ext_s}"
                # —Å–µ—Ç—å
                try:
                    self.net_ph[p] = _SimpleMLP.load(mp)
                except Exception:
                    self.net_ph[p] = None
                # —Å–∫–µ–π–ª–µ—Ä
                try:
                    with open(sp, "rb") as f:
                        self.scaler_ph[p] = pickle.load(f)
                except Exception:
                    self.scaler_ph[p] = None
        except Exception as e:
            print(f"[nn  ] _load_all per-phase error: {e}")


    def _save_all(self) -> None:
        try:
            # –æ–±—Ä–µ–∑–∫–∏
            X_tail, y_tail = self.X, self.y
            if isinstance(getattr(self.cfg, "max_memory", None), int) and self.cfg.max_memory > 0:
                X_tail = self.X[-self.cfg.max_memory:]
                y_tail = self.y[-self.cfg.max_memory:]
            cap = int(getattr(self.cfg, "phase_memory_cap", 10_000))
            X_ph_tail = {p: self.X_ph.get(p, [])[-cap:] for p in range(self.P)}
            y_ph_tail = {p: self.y_ph.get(p, [])[-cap:] for p in range(self.P)}

            st = {
                "mode": self.mode,
                "shadow_hits": self.shadow_hits[-1000:],
                "active_hits": self.active_hits[-1000:],
                "n_feats": self.n_feats,

                "X": X_tail, "y": y_tail,
                "X_ph": X_ph_tail, "y_ph": y_ph_tail,
                "new_since_train_ph": {int(p): int(self.new_since_train_ph.get(p, 0)) for p in range(self.P)},
                "_last_seen_phase": int(self._last_seen_phase),

                # —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ —Å—á—ë—Ç—á–∏–∫–∏
                "T_ph": {int(p): float(self.T_ph.get(p, 1.0)) for p in range(self.P)},
                "seen_since_calib_ph": {int(p): int(self.seen_since_calib_ph.get(p, 0)) for p in range(self.P)},

                # –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                "T": float(self.T),
                "P": int(self.P),
            }
            with open(self.cfg.nn_state_path, "w") as f:
                json.dump(st, f)
        except Exception as e:
            print(f"[nn  ] _save_all state error: {e}")

        # scaler
        try:
            if self.scaler is not None:
                with open(self.cfg.nn_scaler_path, "wb") as f:
                    pickle.dump(self.scaler, f)
        except Exception as e:
            print(f"[nn  ] _save_all scaler error: {e}")

        # model
        try:
            if self.net is not None:
                self.net.save(self.cfg.nn_model_path)
        except Exception as e:
            print(f"[nn  ] _save_all model error: {e}")

        # --- –ù–û–í–û–ï: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ—Ñ–∞–∑–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ —Å–∫–µ–π–ª–µ—Ä–æ–≤ ---
        try:
            root_m, ext_m = os.path.splitext(self.cfg.nn_model_path)
            root_s, ext_s = os.path.splitext(self.cfg.nn_scaler_path)
            for p in range(self.P):
                net = self.net_ph.get(p)
                if net is not None:
                    net.save(f"{root_m}_ph{p}{ext_m}")
                sc = self.scaler_ph.get(p)
                if sc is not None:
                    with open(f"{root_s}_ph{p}{ext_s}", "wb") as f:
                        pickle.dump(sc, f)
        except Exception as e:
            print(f"[nn  ] _save_all per-phase error: {e}")


    # ---------- —Å—Ç–∞—Ç—É—Å ----------
    def status(self):
        def _wr(xs):
            if not xs: return None
            return sum(xs) / float(len(xs))
        def _fmt_pct(p):
            return "‚Äî" if p is None else f"{100.0*p:.2f}%"
        
        wr_a = _wr(self.active_hits)
        wr_s = _wr(self.shadow_hits)
        all_hits = (self.active_hits or []) + (self.shadow_hits or [])
        wr_all = _wr(all_hits)
        
        # CV –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã
        ph = self._last_seen_phase
        cv_metrics = self.cv_metrics.get(ph, {})
        cv_status = cv_metrics.get("status", "N/A")
        cv_wr = cv_metrics.get("oof_accuracy", 0.0)
        cv_ci = f"[{cv_metrics.get('ci_lower', 0):.1f}%, {cv_metrics.get('ci_upper', 0):.1f}%]" if cv_status == "ok" else "N/A"
        
        # –ù–û–í–û–ï: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        try:
            from training_visualizer import get_visualizer
            viz = get_visualizer()
            
            expert_name = "NN"
            
            viz.record_expert_metrics(
                expert_name=expert_name,
                accuracy=wr_all if wr_all is not None else 0.0,
                n_samples=len(all_hits),
                cv_accuracy=cv_wr / 100.0 if cv_wr > 0 else None,
                cv_ci_lower=cv_metrics.get('ci_lower') if cv_status == "ok" else None,
                cv_ci_upper=cv_metrics.get('ci_upper') if cv_status == "ok" else None,
                mode=self.mode
            )
        except Exception:
            pass
        
        return {
            "mode": self.mode,
            "enabled": self.enabled,
            "wr_active": _fmt_pct(wr_a),
            "n_active": len(self.active_hits or []),
            "wr_shadow": _fmt_pct(wr_s),
            "n_shadow": len(self.shadow_hits or []),
            "wr_all": _fmt_pct(wr_all),
            "n": len(all_hits),
            "cv_oof_wr": _fmt_pct(cv_wr / 100.0) if cv_wr > 0 else "‚Äî",
            "cv_ci": cv_ci,
            "cv_validated": str(self.validation_passed.get(ph, False))
        }




# =============================
# META-–æ—Ü–µ–Ω—â–∏–∫ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π, 5 –ª–æ–≥–∏—Ç–æ–≤)
# =============================

class MetaStacking:
    """
    –ú–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –≥–µ–π—Ç–∏–Ω–≥–æ–º.
    –í—Ö–æ–¥: p_xgb, p_rf, p_arf, p_nn, p_base, reg_ctx (œà).
    –†–µ–∂–∏–º—ã:
      - gating_mode="soft": g = softmax(Wg @ œà_ext). z = Œ£ g_k*logit(p_k) * alpha_mix + (w_meta ¬∑ [lz_base, disagree, entropy, 1]).
      - gating_mode="exp4": –ø–æ —Ñ–∞–∑–µ œÜ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –≤–µ—Å–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ Hedge/EXP4; z = Œ£ w_k(œÜ)*logit(p_k) * alpha_mix + (w_meta ¬∑ ...).
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ settle.
    """
    def __init__(self, cfg: MLConfig):
        self.cfg = cfg
        self.enabled = True
        self.mode = "SHADOW"
        self.adwin = ADWIN(delta=self.cfg.adwin_delta) if HAVE_RIVER else None

        # –±–∞–∑–æ–≤–∞—è –ª–∏–Ω–µ–π–∫–∞ –º–µ—Ç—ã: [lz_b, disagree, ent, 1]
        self.P = int(cfg.meta_exp4_phases)
        self.w_meta_ph = np.zeros((self.P, 4), dtype=float)  # [lz_b, disagree, ent, 1]
        self.eta = cfg.meta_eta
        self.l2  = cfg.meta_l2
        self.w_clip = cfg.meta_w_clip
        self.g_clip = cfg.meta_g_clip

        # soft –≥–µ–π—Ç–µ—Ä
        self.gating_mode = cfg.meta_gating_mode
        self.alpha_mix   = float(cfg.meta_alpha_mix)
        self.Wg = None            # (K x d_ctx), —Ä–µ–∞–ª–∏–∑—É–µ–º –∫–∞–∫ (K, D) –≥–¥–µ D=len(œà_ext)
        self.g_eta = cfg.meta_gate_eta
        self.g_l2  = cfg.meta_gate_l2
        self.gate_clip = cfg.meta_gate_clip

        # EXP4 –≤–µ—Å–∞ –ø–æ —Ñ–∞–∑–∞–º: P x K (–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –ø–æ K)
        self.P = int(cfg.meta_exp4_phases)
        self.exp4_eta = float(cfg.meta_exp4_eta)
        self.exp4_w = None  # np.ndarray (P,K)

        # —Ç—Ä–µ–∫–∏–Ω–≥ –¥–ª—è flip —Ä–µ–∂–∏–º–æ–≤
        self.shadow_hits: List[int] = []
        self.active_hits: List[int] = []

        self._load()

    def bind_experts(self, *experts):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–¥–ª—è —Å—Ç–∞—Ç—É—Å–∞/–ª–æ–≥–æ–≤ –∏ –±—É–¥—É—â–∏—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç self –¥–ª—è chain-style.
        """
        self._experts = list(experts)
        return self

    # ---------- —Å–ª—É–∂–µ–±–∫–∏ ----------
    @staticmethod
    def _lz(p: Optional[float]) -> float:
        if p is None: return 0.0
        return to_logit(float(np.clip(p, 1e-6, 1-1e-6)))

    @staticmethod
    def _entropy(p_list: List[Optional[float]]) -> float:
        out, n = 0.0, 0
        for p in p_list:
            if p is None: 
                continue
            pp = float(np.clip(p, 1e-6, 1-1e-6))
            out += -(pp*math.log(pp) + (1-pp)*math.log(1-pp))
            n += 1
        return out / max(1, n)

    @staticmethod
    def _softmax(x: np.ndarray) -> np.ndarray:
        x = x - np.max(x)
        ex = np.exp(np.clip(x, -60, 60))
        s = ex.sum()
        if s <= 0:  # fallback
            return np.ones_like(ex)/len(ex)
        return ex / s

    from state_safety import atomic_save_json
    def _save(self):
        try:
            atomic_save_json(self.cfg.meta_state_path,{
                    "mode": self.mode,
                    "w_meta_ph": self.w_meta_ph.tolist(),
                    "shadow_hits": self.shadow_hits[-1000:],
                    "active_hits": self.active_hits[-1000:],
                    "gating_mode": self.gating_mode,
                    "alpha_mix": self.alpha_mix,
                    "Wg": (self.Wg.tolist() if self.Wg is not None else []),
                    "P": self.P,
                    "exp4_w": (self.exp4_w.tolist() if self.exp4_w is not None else []),
                })
        except Exception:
            pass

    def _load(self):
        try:
            if os.path.exists(self.cfg.meta_state_path):
                with open(self.cfg.meta_state_path, "r") as f:
                    st = json.load(f)
                self.mode = st.get("mode", "SHADOW")
                # –æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
                wm_ph = st.get("w_meta_ph", None)
                if wm_ph:
                    self.w_meta_ph = np.array(wm_ph, dtype=float)
                elif "w_meta" in st:
                    w = np.array(st["w_meta"], dtype=float)
                    self.w_meta_ph = np.vstack([w for _ in range(self.P)])  # —Ç–∏—Ä–∞–∂–∏—Ä—É–µ–º
                elif "w" in st and isinstance(st["w"], list):
                    w_old = np.array(st["w"], dtype=float)
                    w = np.zeros(4, dtype=float)
                    if len(w_old) >= 8:
                        w[0], w[1], w[2], w[3] = w_old[4], w_old[5], w_old[6], w_old[7]
                    self.w_meta_ph = np.vstack([w for _ in range(self.P)])
                self.shadow_hits = st.get("shadow_hits", [])
                self.active_hits = st.get("active_hits", [])
                self.gating_mode = st.get("gating_mode", self.gating_mode)
                self.alpha_mix   = float(st.get("alpha_mix", self.alpha_mix))
                Wg = st.get("Wg", [])
                if Wg:
                    self.Wg = np.array(Wg, dtype=float)
                P = int(st.get("P", self.P))
                self.P = P
                exp4_w = st.get("exp4_w", [])
                if exp4_w:
                    self.exp4_w = np.array(exp4_w, dtype=float)
        except Exception:
            pass

    # ---------- –≥–µ–π—Ç–µ—Ä—ã ----------
    def _ensure_Wg(self, d_ctx: int, K: int):
        if self.Wg is None or self.Wg.shape != (K, d_ctx):
            self.Wg = np.zeros((K, d_ctx), dtype=float)

    def _ensure_exp4(self, K: int):
        if self.exp4_w is None or self.exp4_w.shape != (self.P, K):
            self.exp4_w = np.ones((self.P, K), dtype=float) / float(K)

    def _gating_soft(self, psi_ext: np.ndarray, avail_mask: np.ndarray) -> np.ndarray:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç g –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–º–∞—Å–∫–∞ avail_mask), –ø–µ—Ä–µ–Ω–æ—Ä–º–∏—Ä—É—è.
        """
        K = len(avail_mask)
        self._ensure_Wg(len(psi_ext), K)
        scores = (self.Wg @ psi_ext)  # (K,)
        g = self._softmax(scores)
        # –∑–∞–Ω—É–ª–∏–º –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö, –ø–µ—Ä–µ–Ω–æ—Ä–º–∏—Ä—É–µ–º
        g = g * avail_mask
        s = g.sum()
        if s <= 0:
            g = avail_mask / max(1, avail_mask.sum())
        else:
            g = g / s
        return g

    def _gating_exp4(self, phase_id: int, avail_mask: np.ndarray) -> np.ndarray:
        K = len(avail_mask)
        self._ensure_exp4(K)
        w = self.exp4_w[phase_id].copy()
        w = w * avail_mask
        s = w.sum()
        if s <= 0:
            w = avail_mask / max(1, avail_mask.sum())
        else:
            w = w / s
        return w

    # ---------- –ø—É–±–ª–∏—á–Ω—ã–µ API ----------
    def predict(
        self,
        p_xgb: Optional[float],
        p_rf: Optional[float],
        p_arf: Optional[float],
        p_nn: Optional[float],
        p_base: Optional[float],
        reg_ctx: Optional[Dict[str, float]] = None
    ) -> float:
        # –ª–æ–≥–∏—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        lzs = np.array([
            self._lz(p_xgb), self._lz(p_rf), self._lz(p_arf), self._lz(p_nn)
        ], dtype=float)
        avail = np.array([p_xgb is not None, p_rf is not None, p_arf is not None, p_nn is not None], dtype=float)

        # —Å–º–µ—Å—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        mix_logit = 0.0
        if reg_ctx is not None and avail.any():
            from meta_ctx import pack_ctx, phase_from_ctx
            psi_ext, _ = pack_ctx(reg_ctx)
            if self.gating_mode == "soft":
                g = self._gating_soft(psi_ext, avail)
            else:  # "exp4"
                ph = phase_from_ctx(reg_ctx)
                g = self._gating_exp4(ph, avail)
            mix_logit = float(np.dot(g, lzs))
        else:
            # —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º
            s = avail.sum()
            if s > 0:
                mix_logit = float(np.dot(lzs, avail / s))

        # –±–∞–∑–æ–≤—ã–µ –∞–≥—Ä–µ–≥–∞—Ç—ã –º–µ—Ç—ã
        lz_b = self._lz(p_base)
        plist = [p for p in [p_xgb, p_rf, p_arf, p_nn] if p is not None]
        disagree = float(np.mean([abs(p - 0.5) for p in plist])) if plist else 0.0
        ent = self._entropy([p_xgb, p_rf, p_arf, p_nn])

        phi_meta = np.array([lz_b, disagree, ent, 1.0], dtype=float)
        ph = int(reg_ctx.get("phase")) if isinstance(reg_ctx, dict) and "phase" in reg_ctx else (
            phase_from_ctx(reg_ctx) if reg_ctx is not None else 0)
        w_phi = self.w_meta_ph[ph]
        z = self.alpha_mix * mix_logit + float(np.dot(w_phi, phi_meta))
        return sigmoid(z)


    def record_result(
        self,
        p_xgb: Optional[float],
        p_rf: Optional[float],
        p_arf: Optional[float],
        p_nn: Optional[float],
        p_base: Optional[float],
        y_up: int,
        used_in_live: bool,
        p_final_used: Optional[float] = None,
        reg_ctx: Optional[Dict[str, float]] = None
    ):
        # --- —à–∞–≥ –ø–æ –º–µ—Ç–∞-–≤–µ—Å–∞–º (logistic loss)
        lz_b = self._lz(p_base)
        plist = [p for p in [p_xgb, p_rf, p_arf, p_nn] if p is not None]
        disagree = float(np.mean([abs(p - 0.5) for p in plist])) if plist else 0.0
        ent = self._entropy([p_xgb, p_rf, p_arf, p_nn])
        phi_meta = np.array([lz_b, disagree, ent, 1.0], dtype=float)

        # === NEW: —Å—á–∏—Ç–∞–µ–º —Å–º–µ—Å—å –ª–æ–≥–∏—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∫–∞–∫ –≤ predict()
        lzs = np.array([
            self._lz(p_xgb), self._lz(p_rf), self._lz(p_arf), self._lz(p_nn)
        ], dtype=float)
        avail = np.array([p_xgb is not None, p_rf is not None, p_arf is not None, p_nn is not None], dtype=float)

        mix_logit = 0.0
        if avail.any():
            if reg_ctx is not None:
                if getattr(self, "gating_mode", "soft") == "soft":
                    from meta_ctx import pack_ctx
                    psi_ext, _ = pack_ctx(reg_ctx)
                    self._ensure_Wg(len(psi_ext), len(avail))
                    g = self._gating_soft(psi_ext, avail)
                else:
                    from meta_ctx import phase_from_ctx
                    ph = phase_from_ctx(reg_ctx)
                    g = self._gating_exp4(ph, avail)
            else:
                g = (avail / avail.sum())
            mix_logit = float(np.dot(g, lzs))

        # —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ —Ñ–æ—Ä–º—É–ª—É, —á—Ç–æ –∏ –≤ predict()
        ph = int(reg_ctx.get("phase")) if isinstance(reg_ctx, dict) and "phase" in reg_ctx else (
            phase_from_ctx(reg_ctx) if reg_ctx is not None else 0)
        w_phi = self.w_meta_ph[ph]
        p_hat = sigmoid(self.alpha_mix * mix_logit + float(np.dot(w_phi, phi_meta)))
        g = float(np.clip(p_hat - float(y_up), -self.g_clip, self.g_clip))
        w_phi = w_phi - self.eta * (g * phi_meta + self.l2 * w_phi)
        w_phi = np.clip(w_phi, -self.w_clip, self.w_clip)
        self.w_meta_ph[ph] = w_phi


        # --- soft: —à–∞–≥ –ø–æ Wg
        if self.gating_mode == "soft" and reg_ctx is not None:
            from meta_ctx import pack_ctx
            psi_ext, _ = pack_ctx(reg_ctx)
            lzs = np.array([
                self._lz(p_xgb), self._lz(p_rf), self._lz(p_arf), self._lz(p_nn)
            ], dtype=float)
            avail = np.array([p_xgb is not None, p_rf is not None, p_arf is not None, p_nn is not None], dtype=float)
            if avail.any():
                self._ensure_Wg(len(psi_ext), len(avail))
                # —Ç–µ–∫—É—â–∞—è —Å–º–µ—Å—å
                scores = (self.Wg @ psi_ext)
                g_soft = self._softmax(scores)
                g_soft = g_soft * avail
                s = g_soft.sum()
                g_soft = (g_soft / s) if s > 0 else (avail / max(1, avail.sum()))
                # —Ü–µ–ª–µ–≤–æ–π –ª–æ–≥–∏—Ç = logit(y_up) ~ +inf/-inf, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç —á–µ—Ä–µ–∑ —Å–∏–≥–º–æ–∏–¥—É:
                mix_logit = float(np.dot(g_soft, lzs))
                p_mix = sigmoid(self.alpha_mix * mix_logit)
                gm = float(np.clip(p_mix - float(y_up), -self.gate_clip, self.gate_clip))
                # dL/dscores_k = alpha_mix * gm * (lzs_k - Œ£ g*lzs) * g_k * (1 - g_k)
                lzs_mean = float(np.dot(g_soft, lzs))
                delta = (lzs - lzs_mean) * g_soft * (1.0 - g_soft) * (self.alpha_mix * gm)
                # Wg -= Œ∑ * (delta_k * psi_ext + l2 * Wg_k)
                for k in range(self.Wg.shape[0]):
                    self.Wg[k, :] -= self.g_eta * (delta[k] * psi_ext + self.g_l2 * self.Wg[k, :])
                self.Wg = np.clip(self.Wg, -20.0, 20.0)

        # --- EXP4: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –ø–æ —Ñ–∞–∑–µ (Hedge)
        if self.gating_mode == "exp4" and reg_ctx is not None:
            from meta_ctx import phase_from_ctx
            ph = phase_from_ctx(reg_ctx)
            lzs = np.array([
                self._lz(p_xgb), self._lz(p_rf), self._lz(p_arf), self._lz(p_nn)
            ], dtype=float)
            avail = np.array([p_xgb is not None, p_rf is not None, p_arf is not None, p_nn is not None], dtype=float)
            K = len(avail)
            self._ensure_exp4(K)
            # log-loss –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ –∏—Å—Ö–æ–¥–µ
            def _ll(p):
                if p is None: return 0.0
                p = float(np.clip(p, 1e-6, 1-1e-6))
                return -(y_up*math.log(p) + (1-y_up)*math.log(1-p))
            losses = np.array([_ll(p_xgb), _ll(p_rf), _ll(p_arf), _ll(p_nn)], dtype=float)
            # –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
            for k in range(K):
                if avail[k] > 0:
                    self.exp4_w[ph, k] *= math.exp(-self.exp4_eta * losses[k])
            # –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∞
            s = self.exp4_w[ph, :].sum()
            if s > 0: self.exp4_w[ph, :] /= s

        # --- –≥–µ–π—Ç–∏–Ω–≥ / –¥—Ä–µ–π—Ñ: –∞–ø–¥–µ–π—Ç hit-rate
        p_for_gate = p_final_used if (p_final_used is not None) else p_hat
        hit = int((p_for_gate >= 0.5) == bool(y_up))
        if self.mode == "ACTIVE" and used_in_live:
            self.active_hits.append(hit)
            if self.adwin is not None:
                try:
                    in_drift = self.adwin.update(1 - hit)
                    if in_drift:
                        self.mode = "SHADOW"
                        self.active_hits = []
                except Exception:
                    pass
        else:
            self.shadow_hits.append(hit)

        self._maybe_flip_modes()
        self._save()

    def _maybe_flip_modes(self):
        """
        –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ SHADOW ‚Üî ACTIVE –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏.
        
        –õ–æ–≥–∏–∫–∞:
        - –í —Ä–µ–∂–∏–º–µ SHADOW –º–µ—Ç–∞ –¥–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã, –Ω–æ –æ–Ω–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ç–∞–≤–æ–∫
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –∏ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è)
        - –ü—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ ‚Üí –ø–µ—Ä–µ—Ö–æ–¥ –≤ ACTIVE (–º–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Å—Ç–∞–≤–∫–∞—Ö)
        - –ü—Ä–∏ —É—Ö—É–¥—à–µ–Ω–∏–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ ‚Üí –≤–æ–∑–≤—Ä–∞—Ç –≤ SHADOW (–∑–∞—â–∏—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∞)
        
        –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–∞–¥ –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏:
        - –ë–æ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ç–æ—Ä–≥–æ–≤–∞—Ç—å –∏ —Å–æ–±–∏—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —É—á–∏—Ç—å—Å—è –≤ —Ñ–æ–Ω–µ (SHADOW —Ä–µ–∂–∏–º)
        - –ö–∞–ø–∏—Ç–∞–ª –∑–∞—â–∏—â—ë–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –ø–ª–æ—Ö–æ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–µ
        - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç—ã –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        
        # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –≤–∏–Ω—Ä–µ–π—Ç–∞ (–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        def wr(arr, n):
            if len(arr) < n: return None
            window = arr[-n:]
            return 100.0 * (sum(window)/len(window))
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏
        min_observations = max(50, self.cfg.min_ready // 2)
        
        # === SHADOW ‚Üí ACTIVE: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –≤ —Ç–µ–Ω–µ–≤–æ–º —Ä–µ–∂–∏–º–µ ===
        if self.mode == "SHADOW":
            # –ù—É–∂–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            if len(self.shadow_hits) < min_observations:
                return  # –ï—â—ë —Ä–∞–Ω–æ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –Ω–∞ —Ç–µ–Ω–µ–≤—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            try:
                # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –∏ –∏—Ö –∏—Å—Ö–æ–¥—ã –∏–∑ shadow_hits
                # shadow_hits —Å–æ–¥–µ—Ä–∂–∏—Ç 1 (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑) –∏–ª–∏ 0 (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π)
                window_size = min(200, len(self.shadow_hits))
                
                # –î–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –Ω–∞–º –Ω—É–∂–Ω—ã —Å–∞–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ö–∏—Ç—ã
                # –ü–æ—ç—Ç–æ–º—É —á–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV, –≥–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è p_meta_raw –¥–ª—è —Ç–µ–Ω–µ–≤—ã—Ö —Å–¥–µ–ª–æ–∫
                calib_err = rolling_calib_error(CSV_SHADOW_PATH, n=window_size)
                
                if calib_err is None:
                    # –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å - –æ—Å—Ç–∞—ë–º—Å—è –≤ —Ç–µ–∫—É—â–µ–º —Ä–µ–∂–∏–º–µ
                    return
                
                # –ü–æ—Ä–æ–≥–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ (ECE - Expected Calibration Error)
                CALIB_EXCELLENT = 0.03  # ‚â§ 3% - –æ—Ç–ª–∏—á–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
                CALIB_GOOD = 0.05       # ‚â§ 5% - —Ö–æ—Ä–æ—à–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
                CALIB_ACCEPTABLE = 0.07 # ‚â§ 7% - –ø—Ä–∏–µ–º–ª–µ–º–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
                
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ ACTIVE –µ—Å–ª–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø—Ä–∏–µ–º–ª–µ–º–∞—è –∏–ª–∏ –ª—É—á—à–µ
                if calib_err <= CALIB_ACCEPTABLE:
                    self.mode = "ACTIVE"
                    if HAVE_RIVER:
                        self.adwin = ADWIN(delta=self.cfg.adwin_delta)
                    
                    # –î–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–∞–∫–∂–µ –ø–æ–∫–∞–∂–µ–º –≤–∏–Ω—Ä–µ–π—Ç
                    wr_shadow = wr(self.shadow_hits, min_observations)
                    calib_quality = ("excellent" if calib_err <= CALIB_EXCELLENT 
                                else "good" if calib_err <= CALIB_GOOD 
                                else "acceptable")
                    
                    print(f"[meta] SHADOW‚ÜíACTIVE: –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ {calib_quality} (ECE={calib_err:.3f}), "
                        f"shadow_wr={wr_shadow:.1f}% (n={len(self.shadow_hits)})")
                    
                    try:
                        tg_send(f"üü¢ <b>–ú–µ—Ç–∞: SHADOW‚ÜíACTIVE</b>\n"
                            f"–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞: <b>{calib_quality}</b> (ECE={calib_err:.3f})\n"
                            f"Shadow –≤–∏–Ω—Ä–µ–π—Ç: {wr_shadow:.1f}% (n={len(self.shadow_hits)})\n"
                            f"–ú–µ—Ç–∞-–º–æ–¥–µ–ª—å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ç–∞–≤–æ–∫")
                    except:
                        pass
                    
            except Exception as e:
                print(f"[meta] –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –¥–ª—è SHADOW‚ÜíACTIVE: {e}")
                return
        
        # === ACTIVE ‚Üí SHADOW: –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—é –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤ –∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ ===
        elif self.mode == "ACTIVE":
            # –í –∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—â–µ (–º–µ–Ω—å—à–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –Ω—É–∂–Ω–æ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º—ã)
            active_min_obs = max(30, self.cfg.min_ready // 3)
            
            if len(self.active_hits) < active_min_obs:
                return  # –ï—â—ë —Ä–∞–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –Ω–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–∫–∞—Ö (–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ CSV)
                window_size = min(200, len(self.active_hits))
                calib_err = rolling_calib_error(CSV_PATH, n=window_size)
                
                if calib_err is None:
                    return
                
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º ADWIN –Ω–∞ –¥—Ä–µ–π—Ñ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
                adwin_drift_detected = False
                if self.adwin is not None and len(self.active_hits) > 0:
                    try:
                        # ADWIN —É–∂–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –≤ record_result, –∑–¥–µ—Å—å —Ç–æ–ª—å–∫–æ —á–∏—Ç–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                        # –ï—Å–ª–∏ –±—ã–ª –¥—Ä–µ–π—Ñ, ADWIN —É–∂–µ –ø–µ—Ä–µ–≤—ë–ª mode –≤ SHADOW
                        if self.mode == "SHADOW":  # ADWIN —É–∂–µ –ø–µ—Ä–µ–∫–ª—é—á–∏–ª
                            adwin_drift_detected = True
                    except:
                        pass
                
                # –ü–æ—Ä–æ–≥ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ - –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π —á–µ–º –¥–ª—è –≤—Ö–æ–¥–∞
                CALIB_DEGRADED = 0.08  # > 8% - –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –¥–µ–≥—Ä–∞–¥–∏—Ä–æ–≤–∞–ª–∞, –∑–∞—â–∏—Ç–∞ –∫–∞–ø–∏—Ç–∞–ª–∞
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ SHADOW –µ—Å–ª–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å—Ç–∞–ª–∞ –ø–ª–æ—Ö–æ–π –ò–õ–ò ADWIN –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–ª –¥—Ä–µ–π—Ñ
                if calib_err > CALIB_DEGRADED or adwin_drift_detected:
                    self.mode = "SHADOW"
                    self.active_hits = []  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —á–∏—Å—Ç–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
                    
                    wr_active = wr(self.active_hits, active_min_obs) if not adwin_drift_detected else None
                    
                    reason = "ADWIN drift" if adwin_drift_detected else f"ECE={calib_err:.3f}"
                    print(f"[meta] ACTIVE‚ÜíSHADOW: {reason}, "
                        f"active_wr={wr_active:.1f}% (n={len(self.active_hits)})")
                    
                    try:
                        tg_send(f"üü° <b>–ú–µ—Ç–∞: ACTIVE‚ÜíSHADOW</b>\n"
                            f"–ü—Ä–∏—á–∏–Ω–∞: {reason}\n"
                            f"Active –≤–∏–Ω—Ä–µ–π—Ç: {wr_active:.1f}% (n={len(self.active_hits)})\n"
                            f"–ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞—â–∏—Ç—ã –∫–∞–ø–∏—Ç–∞–ª–∞\n"
                            f"–ú–µ—Ç–∞ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç –æ–±—É—á–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–µ")
                    except:
                        pass
                    
            except Exception as e:
                print(f"[meta] –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –¥–ª—è ACTIVE‚ÜíSHADOW: {e}")
                return

    def status(self):
        def _wr(xs):
            if not xs: 
                return None
            return sum(xs) / float(len(xs))
        def _fmt_pct(p):
            return "‚Äî" if p is None else f"{100.0*p:.2f}%"

        wr_a = _wr(self.active_hits)
        wr_s = _wr(self.shadow_hits)
        all_hits = (self.active_hits or []) + (self.shadow_hits or [])
        wr_all = _wr(all_hits)

        return {
            "mode": self.mode,
            "enabled": self.enabled,
            "wr_active": _fmt_pct(wr_a),
            "n_active": len(self.active_hits or []),
            "wr_shadow": _fmt_pct(wr_s),
            "n_shadow": len(self.shadow_hits or []),
            "wr_all": _fmt_pct(wr_all),
            "n": len(all_hits)
        }




# =============================
# REST MODE
# =============================

def _prune_bets(bets: Dict[int, Dict], keep_settled_last: int = 500, keep_other_last: int = 200):
    settled = sorted([e for e, b in bets.items() if b.get("settled")])
    to_drop = settled[:-keep_settled_last] if len(settled) > keep_settled_last else []
    for e in to_drop:
        bets.pop(e, None)
    # —á–∏—Å—Ç–∏–º —Å—Ç–∞—Ä—ã–µ ¬´–Ω–µ –∑–∞–∫—Ä—ã—Ç—ã–µ¬ª, –≤–∫–ª—é—á–∞—è skipped=True
    others = sorted([e for e, b in bets.items() if not b.get("settled")])
    to_drop2 = others[:-keep_other_last] if len(others) > keep_other_last else []
    for e in to_drop2:
        bets.pop(e, None)

def _settled_trades_count(csv_path: str) -> int:
    """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –≤ CSV."""
    try:
        if not os.path.exists(csv_path):
            return 0
        df = pd.read_csv(csv_path)
        # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–¥–µ–ª–∫–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º (settled=1 –∏–ª–∏ has payout_ratio)
        if "settled" in df.columns:
            return int(df[df["settled"] == 1].shape[0])
        elif "payout_ratio" in df.columns:
            return int(df[df["payout_ratio"].notna()].shape[0])
        else:
            return len(df)
    except Exception:
        return 0

# =============================
# –ì–õ–ê–í–ù–´–ô –¶–ò–ö–õ (—Å –∞–Ω—Å–∞–º–±–ª–µ–º)
# =============================
def main_loop():
    global rpc_fail_streak
    global DELTA_PROTECT  # –±—É–¥–µ–º –º–µ–Ω—è—Ç—å –º–æ–¥—É–ª—å–Ω—É—é –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É
    # --- –§–∞–∑–∞-–≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å --
    hours = None
    ml_cfg = MLConfig() 
    phase_filter = PhaseFilter(hysteresis_s=ml_cfg.phase_hysteresis_s)
    # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å last_phase/last_change_ts –∏–∑ JSON, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∂–∏–≤–∞—Ç—å —Ä–µ—Å—Ç–∞—Ä—Ç)
    # –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    try:
        if os.path.exists(ml_cfg.phase_state_path):
            with open(ml_cfg.phase_state_path, "r") as f:
                st = json.load(f)
            phase_filter.last_phase = st.get("last_phase", None)
            phase_filter.last_change_ts = st.get("last_change_ts", None)
    except Exception:
        pass
        # === Œ¥: —Å—É—Ç–æ—á–Ω—ã–π –ø–æ–¥–±–æ—Ä –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º 100 —Å–¥–µ–ª–∫–∞–º ===
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        n_trades = _settled_trades_count(CSV_PATH)
        
        delta_daily = DeltaDaily(csv_path=CSV_PATH, state_path=DELTA_STATE_PATH,
                                n_last=min(100, n_trades),  # –ù–µ –±–æ–ª—å—à–µ —á–µ–º –µ—Å—Ç—å —Å–¥–µ–ª–æ–∫
                                grid_start=0.000, grid_stop=0.100, grid_step=0.005,
                                csv_shadow_path=CSV_SHADOW_PATH,
                                window_hours=24,
                                opt_mode="dr_lcb")  # ‚ú≥Ô∏è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        st = delta_daily.load_or_recompute_every_hours(period_hours=4)
        
        if st and isinstance(st.get("delta"), (int, float)):
            if n_trades < MIN_TRADES_FOR_DELTA:
                DELTA_PROTECT = 0.0
                print(
                    "[delta] startup(4h/24h): Œ¥=0.000 (FORCED) "
                    f"| trades={n_trades}/{MIN_TRADES_FOR_DELTA} ‚Äî –∫–æ–ø–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É; "
                    f"p_opt={st.get('p_thr_opt', float('nan')):.4f} | avg_used={st.get('avg_p_thr_used', float('nan')):.4f}"
                )
            else:
                DELTA_PROTECT = float(st["delta"])
                method = str(st.get("method","?")).lower()
                if method == "dr_lcb":
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ lcb15 –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                    lcb_value = st.get('lcb15', 0.0)
                    # –ó–∞—â–∏—Ç–∞ –æ—Ç -1e9 –ø—Ä–∏ –≤—ã–≤–æ–¥–µ
                    if lcb_value < -1000:
                        lcb_str = "N/A"
                    else:
                        lcb_str = f"{lcb_value:.6f}"
                    
                    print(
                        "[delta] startup(4h/24h): "
                        f"Œ¥={DELTA_PROTECT:.3f} | method=DR-LCB | p_opt={st.get('p_thr_opt', float('nan')):.4f} | "
                        f"N={st.get('sample_size','?')}, picked={st.get('selected_n','?')} | "
                        f"LCB15={lcb_str} | window={st.get('window_hours','?')}h"
                    )
                elif method == "grid_pnl":
                    print(
                        "[delta] startup(4h/24h): "
                        f"Œ¥={DELTA_PROTECT:.3f} | method=GRID-PnL | p_opt={st.get('p_thr_opt', float('nan')):.4f} | "
                        f"N={st.get('sample_size','?')}, picked={st.get('selected_n','?')} | "
                        f"P&L*={st.get('pnl_at_opt', float('nan')):.6f} BNB | window={st.get('window_hours','?')}h"
                    )
                else:
                    print(
                        "[delta] startup(4h/24h): "
                        f"Œ¥={DELTA_PROTECT:.3f} | method=P*-AVG_USED | p_opt={st.get('p_thr_opt', float('nan')):.4f} | "
                        f"avg_used={st.get('avg_p_thr_used', float('nan')):.4f} | "
                        f"N={st.get('sample_size','?')}, picked={st.get('selected_n','?')} | "
                        f"P&L*={st.get('pnl_at_opt', float('nan')):.6f} BNB | window={st.get('window_hours','?')}h"
                    )

    except Exception as e:
        print(f"[warn] delta_daily init failed: {e}")
    
    # --- init web3/contract
    w3 = connect_web3_resilient()
    c = get_prediction_contract(w3)
    interval_sec = int(c.functions.intervalSeconds().call())
    buffer_sec   = int(c.functions.bufferSeconds().call())
    min_bet_bnb  = get_min_bet_bnb(c)
    print(f"[init] Connected. interval={interval_sec}s buffer={buffer_sec}s minBet={min_bet_bnb:.6f} BNB")

    # --- –ü–ï–†–ï–ú–ï–°–¢–ò–õ–ò –°–Æ–î–ê: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –∫–∞–ø–∏—Ç–∞–ª –∏–∑ CSV (–∏–ª–∏ –∏–∑ capital_state.json, –µ—Å–ª–∏ CSV –ø—É—Å—Ç)
    # --- –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –∫–∞–ø–∏—Ç–∞–ª: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç capital_state.json (–∞–∫—Ç—É–∞–ª—å–Ω—ã–π), –ø–æ—Ç–æ–º CSV
    capital_state = CapitalState(path=os.path.join(os.path.dirname(__file__), "capital_state.json"))
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ capital_state.json
    cap_state = None
    if os.path.exists(capital_state.path):
        try:
            with open(capital_state.path, "r") as f:
                obj = json.load(f)
            cap_state = float(obj.get("capital"))
            if not math.isfinite(cap_state) or cap_state <= 0:
                cap_state = None
        except Exception:
            cap_state = None
    
    # –ü–æ—Ç–æ–º –∏–∑ CSV
    cap_csv = _restore_capital_from_csv(CSV_PATH)
    
    # –í—ã–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫: capital_state.json –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if cap_state is not None:
        capital = cap_state
        cap_src = "capital_state.json"
    elif cap_csv is not None:
        capital = cap_csv
        cap_src = "trades_prediction.csv"
    else:
        capital = START_CAPITAL_BNB
        cap_src = "default"
    print(f"[init] Capital restored: {capital:.6f} BNB (source={cap_src})")
    print(f"[init] Trading mode: {'üìÑ PAPER TRADING' if PAPER_TRADING else 'üí∞ REAL TRADING'}")

    # --- –¢–ï–ü–ï–†–¨ –ú–û–ñ–ù–û –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Telegram (capital —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω)
    if tg_enabled():
        mode_emoji = "üìÑ" if PAPER_TRADING else "üí∞"
        mode_text = "PAPER TRADING" if PAPER_TRADING else "REAL TRADING"
        tg_send(
            f"ü§ñ Bot online ({mode_emoji} {mode_text})\n"
            f"Interval: {interval_sec}s | Buffer: {buffer_sec}s\n"
            f"MinBet: {min_bet_bnb:.6f} BNB\n"
            f"Capital: {capital:.6f} BNB"  # ‚úÖ –¢–µ–ø–µ—Ä—å capital —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω!
        )
    
    if PAPER_TRADING:
        print("[init] Balance checks will use virtual capital from capital_state.json")
    else:
        print(f"[init] Balance checks will use real wallet: {WALLET_ADDRESS}")

    # --- –º–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (EV & log-growth)
    try:
        perf = PerfMonitor(
            path=os.path.join(os.path.dirname(__file__), "perf_state.json"),
            window_trades=500,              # –º–æ–∂–Ω–æ 300‚Äì1000
            min_trades_for_report=50,       # –º–∏–Ω–∏–º—É–º –¥–ª—è –æ—Ç—á—ë—Ç–∞
            fees_net=True                   # pnl —É–∂–µ NET ‚Üí c=0 –≤ p_BE
        )
        print("[init] PerfMonitor ready")
    except Exception as e:
        perf = None
        print(f"[warn] perf init failed: {e}")


    # --- —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —Ñ–æ–Ω–¥: –∑–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    try:
        reserve = ReserveFund(path=os.path.join(os.path.dirname(__file__), "reserve_state.json"), checkpoint_hour=23)
        # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ–∫–∞–∂–µ–º –±–∞–ª–∞–Ω—Å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        print(f"[init] Reserve balance: {reserve.balance:.6f} BNB")
    except Exception as e:
        reserve = None
        print(f"[warn] reserve init failed: {e}")




    # REST/WR —Ç—Ä–µ–∫–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ–º CSV_PATH)
    # REST/WR —Ç—Ä–µ–∫–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ–º CSV_PATH)
    stats = StatsTracker(csv_path=CSV_PATH)
    rest  = RestState.load(path="rest_state.json")
    rest_cfg = RestConfig(drop_for_rest4h=0.10, drop_for_rest24h=0.15,
                        min_trades_per_window=40, min_trades_after_rest4h=10)
    # üëá –¥–æ–±–∞–≤–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç –Ω–∞–ø—Ä—è–º—É—é (—Å—Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –µ—Å–ª–∏ —É –∫–ª–∞—Å—Å–∞ –Ω–µ—Ç __init__ —Å kwargs)
    rest_cfg.min_total_trades_for_rest = 500


    # —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    alpha = 2.0 / (SMOOTH_N + 1.0)
    p_up_ema = None
    p_ss = EhlersSuperSmoother(SS_LEN) if USE_SUPER_SMOOTHER else None

    logreg = OnlineLogReg(state_path="calib_logreg_state.json") if NN_USE else None
    wf = WalkForwardWeighter() if WF_USE else None
    if wf:
        print(f"[wf  ] init weights = {wf.w}")

    # --- –∞–Ω—Å–∞–º–±–ª—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ + –º–µ—Ç–∞
    xgb_exp = XGBExpert(ml_cfg)
    rf_exp  = RFCalibratedExpert(ml_cfg)
    arf_exp = RiverARFExpert(ml_cfg)
    nn_exp  = NNExpert(ml_cfg)

    # –ï—Å–ª–∏ –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ —É–∂–µ –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å —Ç–æ–∫–µ–Ω–æ–º/—á–∞—Ç–æ–º ‚Äî –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –∏—Ö –≤ cfg:
    ml_cfg.meta_report_dir = "meta_reports"    # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å PNG
    ml_cfg.phase_min_ready = 50                # ‚Üê —Å—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è —Å 50 –ø—Ä–∏–º–µ—Ä–æ–≤/—Ñ–∞–∑—É
    ml_cfg.meta_retrain_every = 50             # ‚Üê —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫–∞–∂–¥—ã–µ 50 –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
    meta    = MetaCEMMC(ml_cfg)

    meta.bind_experts(xgb_exp, rf_exp, arf_exp, nn_exp)

    # --- –∫–∞–ª–∏–±—Ä–æ–≤—â–∏–∫–∏ –∏ –≤—Ç–æ—Ä–∞—è –ú–ï–¢–ê + –±–ª–µ–Ω–¥–µ—Ä ---
    from calib.manager import OnlineCalibManager
    _CALIB_MGR = globals().get("_CALIB_MGR")
    if _CALIB_MGR is None:
        _CALIB_MGR = OnlineCalibManager()
        globals()["_CALIB_MGR"] = _CALIB_MGR
        try:
            import pandas as pd, numpy as np
            if os.path.exists(CSV_PATH):
                df_hist = pd.read_csv(CSV_PATH, encoding="utf-8-sig")
                if {"p_meta_raw","outcome"}.issubset(df_hist.columns):
                    y_hist = (df_hist["outcome"].astype(str).str.lower()=="win").astype(int).to_numpy()
                    p_hist = df_hist["p_meta_raw"].astype(float).to_numpy()
                    mask = np.isfinite(p_hist)
                    if mask.sum() >= int(os.getenv("CALIB_MIN_N","300")):
                        _CALIB_MGR.fit_global(p_hist[mask], y_hist[mask])
        except Exception:
            pass

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
    _CALIB_MGR2 = None
    _LM_META = None
    _BLENDER = None
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ globals –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    globals()["_CALIB_MGR2"] = None
    globals()["_LM_META"] = None
    globals()["_BLENDER"] = None


    import atexit, signal, sys

    def _meta_flush(*_):
        try: meta._save_throttled(force=True)
        except: pass

    atexit.register(_meta_flush)
    try:
        signal.signal(signal.SIGTERM, _meta_flush)              # OK: –º—è–≥–∫–æ —Ñ–ª–∞—à–∏–º –ø—Ä–∏ SIGTERM
        signal.signal(signal.SIGINT,  signal.default_int_handler)  # ‚Üê –≤–µ—Ä–Ω—É—Ç—å –¥–µ—Ñ–æ–ª—Ç
    except Exception:
        pass
 

    def _status_line(name, st):
        return (f"{name}: enabled={st['enabled']}, mode={st['mode']}, "
                f"wr_act={st.get('wr_active','‚Äî')} (n={st.get('n_active','0')}), "
                f"wr_sh={st.get('wr_shadow','‚Äî')} (n={st.get('n_shadow','0')}), "
                f"wr_all={st.get('wr_all','‚Äî')} (n={st.get('n','0')})")

    print("[ens ] " + _status_line("XGB", xgb_exp.status()))
    print("[ens ] " + _status_line("RF ", rf_exp.status()))
    print("[ens ] " + _status_line("ARF", arf_exp.status()))
    print("[ens ] " + _status_line("NN ", nn_exp.status()))
    print("[ens ] " + _status_line("META", meta.status()))
    if tg_enabled():
        tg_send("üß† Ensemble init:\n" +
                _status_line("XGB", xgb_exp.status()) + "\n" +
                _status_line("RF ", rf_exp.status()) + "\n" +
                _status_line("ARF", arf_exp.status()) + "\n" +
                _status_line("NN ",  nn_exp.status())  + "\n" +
                _status_line("META", meta.status()))
        # --- NEW: contexts for addons ---
    micro = MicrostructureClient(SESSION, SYMBOL)
    fut   = FuturesContext(SESSION, SYMBOL, min_refresh_sec=30)
    # bnbusdrt6.py (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤)
    pool  = PoolFeaturesCtx(k=10, late_sec=30)

    # –ù–û–í–û–ï: –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞—è 2D-—Ç–∞–±–ª–∏—Ü–∞ –∫–≤–∞–Ω—Ç–∏–ª–µ–π rÃÇ –ø–æ (t_rem √ó pool)
    r2d   = RHat2D(state_path="rhat2d_state.json", pending_path="rhat2d_pending.json")

    gas_hist = GasHistory(maxlen=1200)  # ~20 –º–∏–Ω—É—Ç –ø—Ä–∏ —à–∞–≥–µ 1—Å



    # –∫–µ—à—ã —Å–≤–µ—á–µ–π/—Ñ–∏—á
    kl_df: Optional[pd.DataFrame] = None
    cross_df_map: Dict[str, Optional[pd.DataFrame]] = {}
    stab_df_map: Dict[str, Optional[pd.DataFrame]] = {}
    feats: Optional[Dict[str, pd.Series]] = None
    cross_feats_map: Dict[str, Dict[str, pd.Series]] = {}
    stab_feats_map: Dict[str, Dict[str, pd.Series]] = {}

    # —Ñ–∞–±—Ä–∏–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    ext_builder = ExtendedMLFeatures()

    bets: Dict[int, Dict] = {}
    last_seen_epoch = None
    print("[loop] Press Ctrl+C to stop.")

    rpc_fail_streak = 0
    RPC_FAIL_MAX = 5
    _last_gc = 0  # unix-ts –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä—É—á–Ω–æ–≥–æ GC

    # OU/Logit-OU
    ou_skew = OUOnlineSkew(dt_unit=OU_SKEW_DT_UNIT, decay=OU_SKEW_DECAY) if OU_SKEW_USE else None
    logit_ou = LogitOUSmoother(half_life_sec=LOGIT_OU_HALF_LIFE_SEC,
                               mu_beta=LOGIT_OU_MU_BETA,
                               z_clip=LOGIT_OU_Z_CLIP) if LOGIT_OU_USE else None

    def notify_ens_used(p_base: Optional[float],
                        px: Optional[float], prf: Optional[float], parf: Optional[float], pnn: Optional[float],
                        p_final: Optional[float], used: bool, meta_mode: str):
        try:
            if used and p_final is not None:
                tg_send(
                    "üìä ENS used=<b>YES</b>\n"
                    f"mode=<b>{meta_mode}</b>, "
                    f"p_base={fmt_prob(p_base)}, "
                    f"p_xgb={fmt_prob(px)}, "
                    f"p_rf={fmt_prob(prf)}, "
                    f"p_arf={fmt_prob(parf)}, "
                    f"p_nn={fmt_prob(pnn)}, "
                    f"p_final={fmt_prob(p_final)}"
                )

            else:
                s_x = xgb_exp.status(); s_r = rf_exp.status(); s_a = arf_exp.status(); s_n = nn_exp.status(); s_m = meta.status()
                tg_send("üìä ENS used=no\n"
                        + _status_line("XGB", s_x) + "\n"
                        + _status_line("RF ", s_r) + "\n"
                        + _status_line("ARF", s_a) + "\n"
                        + _status_line("NN ", s_n) + "\n"
                        + _status_line("META", s_m))
        except Exception:
            pass

    while True:
        try:
            now = int(time.time())

            # ‚Äî –ø–µ—Ä–µ—Å—á—ë—Ç ¬´—Ö–æ—Ä–æ—à–∏—Ö —á–∞—Å–æ–≤¬ª –ø–æ –æ–∫–Ω—É 14 –¥–Ω–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) –∫–∞–∂–¥—ã–µ 4 —á–∞—Å–∞
            try:
                if 'hours' in globals() and hours is not None:
                    hours.maybe_recompute(now_ts=now)
            except Exception as e:
                print(f"[hours] recompute failed: {e}")

            # ‚Äî –µ–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ—Ç—Å–µ—á–∫–∞ —Ä–µ–∑–µ—Ä–≤–∞ –≤ 23:00 UTC (–ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Ç–∏–∫–µ –ø–æ—Å–ª–µ 23:00)
            try:
                if reserve is not None:
                    evt = reserve.maybe_eod_rebalance(now_ts=now, capital=capital)
                    if evt and evt.get("changed"):
                        new_capital = float(evt["capital"])
                        try:
                            capital_state.save(new_capital, ts=now)  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Ä–∞–±–æ—á–∏–π –∫–∞–ø–∏—Ç–∞–ª
                        except Exception as e:
                            print(f"[warn] capital_state save failed: {e}")
                        # –∏–Ω—Ñ–æ—Ä–º–∏—Ä—É–µ–º –≤ TG (—Ç–∏—Ö–æ –∏–≥–Ω–æ—Ä–∏–º —Å–±–æ–∏)
                        try:
                            tg_send(evt["message"])
                        except Exception:
                            pass
                        capital = new_capital  # –æ–±–Ω–æ–≤–ª—è–µ–º capital –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
            except Exception as e:
                print(f"[reserve] eod rebalance failed: {e}")



            # --- —Ç–µ–∫—É—â–∏–π epoch
            try:
                cur = int(c.functions.currentEpoch().call())
                rpc_fail_streak = 0
            except Exception as e:
                print(f"[rpc ] currentEpoch failed: {e}")
                rpc_fail_streak += 1
                if rpc_fail_streak >= RPC_FAIL_MAX:
                    try:
                        w3 = connect_web3()
                        c = get_prediction_contract(w3)
                        rpc_fail_streak = 0
                        print("[rpc ] reconnected")
                    except Exception as ee:
                        print(f"[rpc ] reconnect failed: {ee}")
                time.sleep(1.0)
                continue

            if last_seen_epoch != cur:
                print(f"\n[epoch] currentEpoch={cur} (time={now})")
                last_seen_epoch = cur
            try:
                try_settle_shadow_rows(CSV_SHADOW_PATH, w3, c, cur)
            except Exception as e:
                print(f"[shadow] settle pass failed: {e}")


            try:
                st = delta_daily.maybe_update_every_hours(period_hours=4, now_ts=now)
                if st and isinstance(st.get("delta"), (int, float)):
                    n_trades = _settled_trades_count(CSV_PATH)

                    if n_trades < MIN_TRADES_FOR_DELTA:
                        DELTA_PROTECT = 0.0
                        try:
                            tg_send(
                                "‚öôÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Œ¥ (–∫–∞–∂–¥—ã–µ 4—á)\n"
                                f"Œ¥=<b>0.000</b> (FORCED: trades={n_trades}/{MIN_TRADES_FOR_DELTA})\n"
                                f"p_opt=<b>{st.get('p_thr_opt', float('nan')):.4f}</b> | "
                                f"avg_used=<b>{st.get('avg_p_thr_used', float('nan')):.4f}</b>\n"
                                f"N={st.get('sample_size','?')}  –≤–∑—è–ª–∏={st.get('selected_n','?')}\n"
                                f"P&L*={st.get('pnl_at_opt', float('nan')):.6f} BNB\n"
                                "<i>* –ø–æ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤—É –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –≤–∑—è—Ç—ã—Ö —Å–¥–µ–ª–æ–∫</i>"
                            )
                        except Exception:
                            pass

                    elif (meta.mode != "ACTIVE") or (not had_trade_in_last_hours(CSV_PATH, 1.0)):
                        DELTA_PROTECT = 0.0
                        reason = "meta‚â†ACTIVE" if meta.mode != "ACTIVE" else "idle‚â•1h"
                        try:
                            tg_send(
                                "‚öôÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Œ¥ (–∫–∞–∂–¥—ã–µ 4—á)\n"
                                f"Œ¥=<b>0.000</b> (DISABLED: {reason})\n"
                                f"p_opt=<b>{st.get('p_thr_opt', float('nan')):.4f}</b> | "
                                f"avg_used=<b>{st.get('avg_p_thr_used', float('nan')):.4f}</b>\n"
                                f"N={st.get('sample_size','?')}  –≤–∑—è–ª–∏={st.get('selected_n','?')}\n"
                                f"P&L*={st.get('pnl_at_opt', float('nan')):.6f} BNB\n"
                                "<i>* –ø–æ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤—É –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –≤–∑—è—Ç—ã—Ö —Å–¥–µ–ª–æ–∫</i>"
                            )
                        except Exception:
                            pass

                    else:
                        DELTA_PROTECT = float(st["delta"])
                        try:
                            tg_send(
                                "‚öôÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Œ¥ (–∫–∞–∂–¥—ã–µ 4—á)\n"
                                f"Œ¥=<b>{DELTA_PROTECT:.3f}</b>\n"
                                f"p_opt=<b>{st.get('p_thr_opt', float('nan')):.4f}</b> | "
                                f"avg_used=<b>{st.get('avg_p_thr_used', float('nan')):.4f}</b>\n"
                                f"N={st.get('sample_size','?')}  –≤–∑—è–ª–∏={st.get('selected_n','?')}\n"
                                f"P&L*={st.get('pnl_at_opt', float('nan')):.6f} BNB\n"
                                "<i>* –ø–æ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤—É –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏ –≤–∑—è—Ç—ã—Ö —Å–¥–µ–ª–æ–∫</i>"
                            )
                        except Exception:
                            pass
            except Exception as e:
                print(f"[delta] update failed: {e}")



            # –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ/–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ
            pending = sorted([e for e, b in bets.items() if not b.get("settled") and e < cur - 1])[-50:]

            for epoch in [cur, cur - 1] + pending:
                if epoch <= 0:
                    continue

                try:
                    rd = get_round(w3, c, epoch)
                    if rd is None:
                        print(f"[skip] epoch={epoch} (rpc timeout)")
                        continue  # –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ü–∏–∫–ª—É/–æ–∂–∏–¥–∞–Ω–∏—é
                    rpc_fail_streak = 0
                except Exception as e:
                    print(f"[rpc ] get_round({epoch}) failed: {e}")
                    rpc_fail_streak += 1
                    if rpc_fail_streak >= RPC_FAIL_MAX:
                        try:
                            w3 = connect_web3()
                            c = get_prediction_contract(w3)
                            rpc_fail_streak = 0
                            print("[rpc ] reconnected")
                        except Exception as ee:
                            print(f"[rpc ] reconnect failed: {ee}")
                    continue

                # ============= –ó–ê–ú–ï–ù–ò–¢–¨ –ë–õ–û–ö (—Å—Ç—Ä–æ–∫–∏ ~975-995) =============

                if epoch not in bets:
                    # === COOLING PERIOD: —É–º–Ω–∞—è –ø–∞—É–∑–∞ –ø–æ—Å–ª–µ —Å–µ—Ä–∏–∏ –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π ===
                    if epoch == cur and now < rd.lock_ts:
                        try:
                            df_recent = _read_csv_df(CSV_PATH).sort_values("settled_ts")
                            if not df_recent.empty:
                                # –°–º–æ—Ç—Ä–∏–º –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–¥–µ–ª–æ–∫ (–≤–º–µ—Å—Ç–æ 3)
                                recent_trades = df_recent[df_recent["outcome"].isin(["win", "loss"])].tail(5)
                                
                                if len(recent_trades) >= 5:
                                    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π
                                    losses = (recent_trades["outcome"] == "loss").sum()
                                    
                                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ö–ê–ß–ï–°–¢–í–û –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π (edge_at_entry)
                                    loss_rows = recent_trades[recent_trades["outcome"] == "loss"]
                                    
                                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º edge_at_entry
                                    loss_edges = pd.to_numeric(
                                        loss_rows.get("edge_at_entry", pd.Series(dtype=float)), 
                                        errors="coerce"
                                    ).dropna()
                                    
                                    avg_loss_edge = float(loss_edges.mean()) if len(loss_edges) > 0 else 0.0
                                    
                                    # === –£–°–õ–û–í–ò–Ø –î–õ–Ø COOLING ===
                                    # 1) 3+ –ø—Ä–æ–∏–≥—Ä—ã—à–∞ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5
                                    # 2) –°—Ä–µ–¥–Ω–∏–π edge –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π >= 0.03 (–Ω–µ –º–∞—Ä–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞–≤–∫–∏)
                                    cooling_needed = (losses >= 3) and (avg_loss_edge >= 0.03)
                                    
                                    if cooling_needed:
                                        last_loss_ts = int(recent_trades[recent_trades["outcome"] == "loss"].iloc[-1]["settled_ts"])
                                        hours_since = (now - last_loss_ts) / 3600.0
                                        COOLDOWN_HOURS = 1.0  # –±—ã–ª–æ 2.0
                                        
                                        if hours_since < COOLDOWN_HOURS:
                                            bets[epoch] = dict(
                                                skipped=True, 
                                                reason="cooling_period", 
                                                wait_polls=0, 
                                                settled=False
                                            )
                                            
                                            # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                                            print(f"[cool] epoch={epoch} COOLING: {losses}/5 losses "
                                                f"(avg_edge={avg_loss_edge:.3f}) | "
                                                f"wait {COOLDOWN_HOURS-hours_since:.1f}h more")
                                            
                                            send_round_snapshot(
                                                prefix=f"üßä <b>Cooling</b> epoch={epoch}",
                                                extra_lines=[
                                                    f"–ü–∞—É–∑–∞ –ø–æ—Å–ª–µ {losses}/5 –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π (–ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å).",
                                                    f"–°—Ä–µ–¥–Ω–∏–π edge –ø—Ä–æ–∏–≥—Ä—ã—à–µ–π: {avg_loss_edge:.3f}",
                                                    f"–û—Å—Ç–∞–ª–æ—Å—å: {COOLDOWN_HOURS-hours_since:.1f}—á"
                                                ]
                                            )
                                            
                                            notify_ens_used(None, None, None, None, None, None, False, meta.mode)
                                            continue
                                
                        except Exception as e:
                            print(f"[cool] check failed: {e}")
                    
                    # --- —Å—Ç–∞–¥–∏—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è
                    if epoch == cur and now < rd.lock_ts:
                        # --- Guard: –∂–¥—ë–º –¥–æ –æ–∫–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 15 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ lock
                        time_left = rd.lock_ts - now
                        if time_left > GUARD_SECONDS:
                            # –µ—â—ë —Ä–∞–Ω–æ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ: –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Å–Ω–∞–ø—à–æ—Ç—ã –ø—É–ª–æ–≤ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                            pool.observe(epoch, now, rd.bull_amount, rd.bear_amount)
                            continue




                        # --- —Ç–∏–∫–∏/—Ñ–∏—á–∏ –∫ lock-1s
                        t_lock = pd.to_datetime((rd.lock_ts - 1) * 1000, unit="ms", utc=True)
                        need_until_ms = int(t_lock.timestamp() * 1000)

                        kl_df = ensure_klines_cover(kl_df, SYMBOL, BINANCE_INTERVAL, need_until_ms)
                        if kl_df is None or kl_df.empty:
                            continue
                        feats = features_from_binance(kl_df)

                        if USE_CROSS_ASSETS:
                            cross_df_map = ensure_klines_cover_map(cross_df_map, CROSS_SYMBOLS, BINANCE_INTERVAL, need_until_ms)
                            stab_df_map  = ensure_klines_cover_map(stab_df_map,  STABLE_SYMBOLS, BINANCE_INTERVAL, need_until_ms)
                            cross_feats_map = features_for_symbols(cross_df_map)
                            stab_feats_map  = features_for_symbols(stab_df_map)

                        if is_chop_at_time(feats, t_lock):
                            bets[epoch] = dict(skipped=True, reason="chop", wait_polls=0, settled=False)
                            print(f"[skip] epoch={epoch} (chop)")
                            send_round_snapshot(
                                prefix=f"‚õî <b>Skip</b> epoch={epoch} (–±–æ–ª–æ—Ç–æ ATR/CHOP)",
                                extra_lines=[f"–ü—Ä–∏—á–∏–Ω–∞: chop (–Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)."]
                            )
                            notify_ens_used(None, None, None, None, None, None, False, meta.mode)
                            continue

                        # --- –±–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
                        w_for_prob = wf.w if (wf is not None) else None
                        P_up, P_dn, wf_phi_dict = prob_up_down_at_time(feats, t_lock, w_for_prob)

                        # –æ—Ç–ª–∞–¥–∫–∞ –∞–º–ø–ª–∏—Ç—É–¥—ã –±–∞–∑–æ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                        try:
                            phi_dbg = np.array([
                                wf_phi_dict.get("phi_wf0", 0.0),
                                wf_phi_dict.get("phi_wf1", 0.0),
                                wf_phi_dict.get("phi_wf2", 0.0),
                                wf_phi_dict.get("phi_wf3", 0.0),
                            ], dtype=float)
                            w_dbg = (wf.w if (wf is not None) else np.array([0.35, 0.20, 0.20, 0.25], dtype=float))
                            z_up = float(np.dot(w_dbg, phi_dbg))
                            print(f"[base] ||w||={np.linalg.norm(w_dbg):.3f} logit={z_up:+.4f} P_up_raw={P_up:.4f}")
                        except Exception:
                            pass


                        if USE_SUPER_SMOOTHER and p_ss is not None:
                            P_up = float(np.clip(p_ss.update(P_up), 0.0, 1.0))
                            P_dn = 1.0 - P_up
                        else:
                            p_up_ema = P_up if p_up_ema is None else (alpha * P_up + (1 - alpha) * p_up_ema)
                            P_up = p_up_ema
                            P_dn = 1.0 - P_up

                        # NN-–∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –ø–æ–≤–µ—Ä—Ö —Ñ–∏—á (—Å—Ç–∞—Ä—ã–π)
                        phi, i = None, _index_pad(feats["M_up"], t_lock)
                        if NN_USE and i is not None:
                            phi = np.array([
                                float(feats["M_up"].iloc[i] - feats["M_dn"].iloc[i]),
                                float(feats["S_up"].iloc[i] - feats["S_dn"].iloc[i]),
                                float(feats["B_up"].iloc[i] - feats["B_dn"].iloc[i]),
                                float(feats["R_up"].iloc[i] - feats["R_dn"].iloc[i]),
                                1.0
                            ], dtype=float)
                            if logreg is not None:
                                p_nncal = logreg.predict(phi)
                                P_up = (1.0 - BLEND_NN) * P_up + BLEND_NN * p_nncal
                                P_dn = 1.0 - P_up

                        # –∫—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤—ã
                        if USE_CROSS_ASSETS:
                            zc_up1, zc_dn1 = cross_up_down_contrib(cross_feats_map, t_lock, CROSS_SYMBOLS, CROSS_W_MOM, CROSS_W_VWAP, CROSS_SHIFT_BARS)
                            zc_up2, zc_dn2 = cross_up_down_contrib(stab_feats_map,  t_lock, STABLE_SYMBOLS, STABLE_W_MOM, STABLE_W_VWAP, CROSS_SHIFT_BARS)
                            delta_logit = CROSS_ALPHA * ((zc_up1 + zc_up2) - (zc_dn1 + zc_dn2))
                            P_up = from_logit(to_logit(P_up) + float(delta_logit))
                            P_up = float(np.clip(P_up, 0.0, 1.0))
                            P_dn = 1.0 - P_up

                        P_up = elder_logit_adjust(kl_df, t_lock, P_up)
                        P_dn = 1.0 - P_up

                        # OU-–¥–æ–±–∞–≤–∫–∏
                        if OU_SKEW_USE and "Zs" in feats:
                            j = _index_pad(feats["Zs"], t_lock)
                            if j is not None and j > 0:
                                z_prev = float(np.clip(feats["Zs"].iloc[j-1], -OU_SKEW_Z_CLIP, OU_SKEW_Z_CLIP))
                                z_now  = float(np.clip(feats["Zs"].iloc[j],   -OU_SKEW_Z_CLIP, OU_SKEW_Z_CLIP))
                                ou_skew.update_pair(z_prev, z_now)
                                horizon_sec = max(1.0, rd.close_ts - rd.lock_ts)
                                res = ou_skew.prob_above_zero(z_now, horizon_sec)
                                if res is not None:
                                    p_ou_up, strength = res
                                    z_base = to_logit(P_up)
                                    z_ou = to_logit(p_ou_up)
                                    amp = float(np.clip((abs(z_now) - OU_SKEW_THR) / max(1e-6, OU_SKEW_THR), 0.0, 1.0))
                                    lam = min(OU_SKEW_LAMBDA_MAX, strength) * amp
                                    z_mix = (1.0 - lam) * z_base + lam * z_ou
                                    P_up = from_logit(z_mix)
                                    P_dn = 1.0 - P_up

                        if LOGIT_OU_USE and logit_ou is not None:
                            z_now = to_logit(P_up)
                            logit_ou.update_mu(z_now)
                            horizon_sec = max(1.0, rd.close_ts - rd.lock_ts)
                            z_pred = logit_ou.predict_future(z_now, horizon_sec)
                            P_up = from_logit(z_pred)
                            P_dn = 1.0 - P_up



                        # --- NEW: microstructure/futures/pools/jumps/liquidity/time/gas/idio

                        # 1) –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫ lock-1s
                        end_ms = int(t_lock.timestamp()*1000)
                        micro_feats = micro.compute(end_ms)  # rel_spread, book_imb, microprice_delta, ofi_5s/15s/30s, ob_slope, mid

                        # 2) –§—å—é—á–µ—Ä—Å—ã (refresh ‚âà —Ä–∞–∑ –≤ 30—Å)
                        fut.refresh()
                        spot_mid = micro_feats.get("mid", float(kl_df["close"].iloc[-1]))
                        fut_feats = fut.features(spot_mid)

                        # 3) –ü—É–ª—ã Prediction: –∫–æ–ø–∏–º –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏ –∫ lock-1s
                        pool.observe(epoch, now, rd.bull_amount, rd.bear_amount)
                        pool.update_streak_from_rounds(lambda e: get_round(w3, c, e), cur)
                        pool_feats = pool.features(epoch, rd.lock_ts)

                        # 4) –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å/–¥–∂–∞–º–ø—ã (BV/RQ/RV) –Ω–∞ –æ–∫–Ω–∞—Ö 20/60/120 –±–∞—Ä–æ–≤
                        RV20,BV20,RQ20,n20 = realized_metrics(kl_df["close"], 20)
                        RV60,BV60,RQ60,n60 = realized_metrics(kl_df["close"], 60)
                        RV120,BV120,RQ120,n120 = realized_metrics(kl_df["close"], 120)
                        jump20 = jump_flag_from_rv_bv_rq(RV20,BV20,RQ20,n20, z_thr=3.0)
                        jump60 = jump_flag_from_rv_bv_rq(RV60,BV60,RQ60,n60, z_thr=3.0)

                        # 5) –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å/–∏–º–ø–∞–∫—Ç
                        amihud = amihud_illiq(kl_df, win=20)
                        kyle   = kyle_lambda(kl_df, win=20)

                        # 6) –ò–Ω—Ç—Ä–∞–¥–µ–π-–ø—Ä–æ—Ñ–∏–ª—å –≤—Ä–µ–º–µ–Ω–∏
                        time_feats = intraday_time_features(t_lock)

                        # 7) –ö—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤—ã: ¬´–æ—á–∏—â–µ–Ω–Ω—ã–π¬ª —Ä–µ—Ç—ë—Ä–Ω –∏ –¥–∏–Ω–∞–º–∏–∫–∞ –±–µ—Ç—ã
                        btc_df = cross_df_map.get("BTCUSDT")
                        eth_df = cross_df_map.get("ETHUSDT")
                        idio = idio_features(kl_df, btc_df, eth_df, look_min=240)

                        # 8) –ì–∞–∑ ‚Äî –¥–µ–ª—å—Ç–∞/–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                        gas_gwei_now = float(get_gas_price_wei(w3))/1e9
                        gas_hist.push(now, gas_gwei_now)
                        gas_feats = gas_hist.features(now)

                        # –°–±–æ—Ä –≤—Å–µ—Ö –Ω–æ–≤—ã—Ö —Ñ–∏—á –≤ –µ–¥–∏–Ω—ã–π –≤–µ–∫—Ç–æ—Ä (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–ª—é—á–µ–π):
                        addon_dict = {}
                        addon_dict.update({
                            "rel_spread": micro_feats.get("rel_spread", 0.0),
                            "book_imb": micro_feats.get("book_imb", 0.0),
                            "microprice_delta": micro_feats.get("microprice_delta", 0.0),
                            "ofi_5s": micro_feats.get("ofi_5s", 0.0),
                            "ofi_15s": micro_feats.get("ofi_15s", 0.0),
                            "ofi_30s": micro_feats.get("ofi_30s", 0.0),
                            "ob_slope": micro_feats.get("ob_slope", 0.0),
                            "funding_sign": fut_feats.get("funding_sign", 0.0),
                            "funding_timeleft": fut_feats.get("funding_timeleft", 0.0),
                            "dOI_1m": fut_feats.get("dOI_1m", 0.0),
                            "dOI_5m": fut_feats.get("dOI_5m", 0.0),
                            "basis_now": fut_feats.get("basis_now", 0.0),
                            "pool_logit": pool_feats.get("pool_logit", 0.0),
                            "pool_logit_d30": pool_feats.get("pool_logit_d30", 0.0),
                            "pool_logit_d60": pool_feats.get("pool_logit_d60", 0.0),
                            "late_money_share": pool_feats.get("late_money_share", 0.0),
                            "last_k_outcomes_mean": pool_feats.get("last_k_outcomes_mean", 0.0),
                            "last_k_payout_median": pool_feats.get("last_k_payout_median", 0.0),
                            "bv_over_rv_20": (BV20/max(1e-12, RV20)),
                            "bv_over_rv_60": (BV60/max(1e-12, RV60)),
                            "rq_norm_20": RQ20,
                            "rq_norm_60": RQ60,
                            "jump20": float(jump20),
                            "jump60": float(jump60),
                            "amihud_illq": amihud,
                            "kyle_lambda": kyle,
                            "resid_ret_1m": idio.get("resid_ret_1m", 0.0),
                            "beta_sum": idio.get("beta_sum", 0.0),
                            "beta_sum_d60": idio.get("beta_sum_d60", 0.0),
                            "gas_d1m": gas_feats.get("gas_d1m", 0.0),
                            "gas_vol5m": gas_feats.get("gas_vol5m", 0.0),
                        })
                        addon_dict.update(time_feats)

                        addon_names = [
                            "rel_spread","book_imb","microprice_delta","ofi_5s","ofi_15s","ofi_30s","ob_slope",
                            "funding_sign","funding_timeleft","dOI_1m","dOI_5m","basis_now",
                            "pool_logit","pool_logit_d30","pool_logit_d60","late_money_share",
                            "last_k_outcomes_mean","last_k_payout_median",
                            "bv_over_rv_20","bv_over_rv_60","rq_norm_20","rq_norm_60","jump20","jump60",
                            "amihud_illq","kyle_lambda","resid_ret_1m","beta_sum","beta_sum_d60",
                            "gas_d1m","gas_vol5m",
                            "tod_sin","tod_cos","EU","US","ASIA",
                            "dow_0","dow_1","dow_2","dow_3","dow_4","dow_5","dow_6"
                        ]
                        x_addon, _ = pack_vector(addon_dict, addon_names)

                        # --- –¢–í–û–ô –°–¢–ê–†–´–ô x_ml ---
                        x_ml = ext_builder.build(kl_df, feats, t_lock)

                        # --- –ö–û–ù–ö–ê–¢–ï–ù–ê–¶–ò–Ø ---
                        x_ml = np.concatenate([x_ml, x_addon], axis=0)

                        # --- NEW: —Ä–µ–∂–∏–º (œà) –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –≥–µ–π—Ç–∏–Ω–≥–∞
                        reg_ctx = build_regime_ctx(
                            kl_df, feats, t_lock,
                            micro_feats=micro_feats,
                            fut_feats=fut_feats,
                            jump_flag=max(float(jump20), float(jump60))
                        )


                        # –∞–Ω—Ç–∏-–¥—Ä–æ–∂—å —Ñ–∞–∑—ã
                        from meta_ctx import phase_from_ctx
                        phase_raw = int(phase_from_ctx(reg_ctx))
                        phase_stable = int(phase_filter.update(phase_raw, now_ts=int(t_lock.timestamp())))
                        reg_ctx["phase_raw"] = phase_raw
                        reg_ctx["phase"] = phase_stable  # ‚Üê –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ–∑–¥–µ –¥–∞–ª–µ–µ
                        try:
                            with open(ml_cfg.phase_state_path, "w") as f:
                                json.dump({
                                    "last_phase": int(phase_stable),
                                    "last_change_ts": int(t_lock.timestamp()),
                                }, f)
                        except Exception:
                            pass
                       

                        p_xgb, m_xgb = xgb_exp.proba_up(x_ml, reg_ctx=reg_ctx)
                        p_rf,  m_rf  = rf_exp.proba_up(x_ml,  reg_ctx=reg_ctx)
                        p_arf, m_arf = arf_exp.proba_up(x_ml, reg_ctx=reg_ctx)
                        p_nn,  m_nn  = nn_exp.proba_up(x_ml,   reg_ctx=reg_ctx)



                        p_base_before_ens = P_up
                        p_final = meta.predict(p_xgb, p_rf, p_arf, p_nn, p_base_before_ens, reg_ctx=reg_ctx)
                        ens_used = False
                        
                        if meta.mode == "ACTIVE" and p_final is not None:
                            # –£–ü–†–û–©–ï–ù–û: –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —Å hold-out –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
                            p_meta_raw = float(np.clip(p_final, 0.0, 1.0))

                            # –û–¥–Ω–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ rolling window —Å hold-out
                            calib1 = globals().get("_CALIB_MGR")
                            p_side_cal = float(calib1.transform(p_meta_raw)) if calib1 else p_meta_raw
                            
                            calib_src = "calib[roll/holdout]" if (calib1 and calib1.roll_cal) else "calib[off]"
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º P_up –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
                            P_up = float(np.clip(p_side_cal, 0.0, 1.0))
                            P_dn = 1.0 - P_up
                            ens_used = True
                            
                            # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å CSV –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                            p_blend = P_up
                            blend_w = 1.0
                            p_meta2_raw = None  # –æ—Ç–∫–ª—é—á–µ–Ω–æ
                            calib2_src = "disabled"


                        # --- –≤—ã–±–æ—Ä —Å—Ç–æ—Ä–æ–Ω—ã
                        bet_up = P_up >= P_dn
                        p_side_raw = P_up if bet_up else P_dn
                        
                        # === –ê–î–ê–ü–¢–ò–í–ù–´–ô Shrinkage: –º–µ–Ω—å—à–µ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫—Ä–∞—è ===
                        edge_est = abs(p_side_raw - 0.5)

                        if edge_est > 0.10:  # –æ—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
                            shrinkage = 0.05  # 5% - –ø–æ—á—Ç–∏ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
                        elif edge_est > 0.06:  # —Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            shrinkage = 0.10  # 10%
                        else:  # –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            shrinkage = 0.15  # 15%

                        p_side = 0.5 + (p_side_raw - 0.5) * (1.0 - shrinkage)
                        print(f"[shrink] p_raw={p_side_raw:.4f} ‚Üí p_conservative={p_side:.4f} (Œî={p_side-p_side_raw:+.4f}, shrink={shrinkage:.2f})")
                        
                        side = "UP" if bet_up else "DOWN"



                        # gas now
                        # gas now
                        gas_price_wei = 0
                        try:
                            gas_price_wei = get_gas_price_wei(w3)
                            rpc_fail_streak = 0
                        except Exception as e:
                            print(f"[rpc ] gas_price failed: {e}")
                            rpc_fail_streak += 1
                            gas_price_wei = get_gas_price_with_fallback(w3)
                            if rpc_fail_streak >= RPC_FAIL_MAX:
                                try:
                                    w3 = connect_web3()
                                    c = get_prediction_contract(w3)
                                    rpc_fail_streak = 0
                                    print("[rpc ] reconnected successfully")
                                except Exception as ee:
                                    print(f"[rpc ] reconnect failed: {ee}")
                            
                        gas_bet_bnb_cur = _as_float(GAS_USED_BET * gas_price_wei / 1e18, 0.0)
                        gas_claim_bnb_cur = _as_float(GAS_USED_CLAIM * gas_price_wei / 1e18, 0.0)

                        # =============================
                        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –û–¶–ï–ù–ö–ê rÃÇ
                        # =============================
                        
                        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞: –æ–±–Ω–æ–≤–∏—Ç—å 2D-—Ç–∞–±–ª–∏—Ü—É –∏ –≥–∞–∑–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏
                        r_med, gb_med, gc_med = last3_ev_estimates(CSV_PATH)
                        r_med = _as_float(r_med, None)
                        gb_med = _as_float(gb_med, None)
                        gc_med = _as_float(gc_med, None)
                        
                        try:
                            r2d.ingest_settled(CSV_PATH)
                        except Exception:
                            pass
                        
                        _now_ts = int(time.time())
                        t_rem_s = max(0, int(_as_float(getattr(rd, "lock_ts", _now_ts), _now_ts) - _now_ts))
                        if t_rem_s <= 2:
                            bets[epoch] = dict(skipped=True, reason="late", wait_polls=0, settled=False)
                            print(f"[late] epoch={epoch} missed betting window")
                            notify_ens_used(None, None, None, None, None, None, False, meta.mode)
                            continue
                        pool_tot = _as_float(getattr(rd, "bull_amount", 0.0), 0.0) + _as_float(getattr(rd, "bear_amount", 0.0), 0.0)
                        
                        try:
                            r2d.observe_epoch(epoch=int(epoch), t_rem_s=int(t_rem_s), pool_total_bnb=float(pool_tot))
                        except Exception:
                            pass
                        
                        # –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –∏–∑ –º–æ–¥—É–ª—è: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç IMPLIED ‚Üí –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º –º–µ—Ç–æ–¥–∞–º
                        # –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –∏–∑ –º–æ–¥—É–ª—è: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç IMPLIED ‚Üí –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º –º–µ—Ç–æ–¥–∞–º
                        try:
                            r_hat, r_hat_source = estimate_r_hat_improved(
                                rd=rd,
                                bet_up=bet_up,
                                epoch=epoch,
                                pool=pool,
                                csv_path=CSV_PATH,
                                kl_df=kl_df,
                                treasury_fee=TREASURY_FEE,
                                use_stress_r15=USE_STRESS_R15,
                                r2d=r2d
                            )
                            r_hat = _as_float(r_hat, 1.90)
                            r_hat_source = str(r_hat_source) if r_hat_source else "unknown"
                        except Exception as e:
                            print(f"[r_hat] estimate_r_hat_improved failed: {e}")
                            r_hat = 1.90
                            r_hat_source = "fallback_after_error"
                        
                        print(f"[r_hat] {r_hat:.4f} from {r_hat_source}")
                        
                        # –ì–∞–∑–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
                        gb_hat = _as_float(gb_med if (gb_med is not None and math.isfinite(_as_float(gb_med))) else gas_bet_bnb_cur, 0.0)
                        gc_hat = _as_float(gc_med if (gc_med is not None and math.isfinite(_as_float(gc_med))) else gas_claim_bnb_cur, 0.0)


                        total_settled = settled_trades_count(CSV_PATH)
                        has_recent = had_trade_in_last_hours(CSV_PATH, 1.0)
                        bootstrap_phase = (total_settled < MIN_TRADES_FOR_DELTA)

                        cap3 = MAX_STAKE_FRACTION * capital
                        if cap3 < min_bet_bnb:
                            bets[epoch] = dict(skipped=True, reason="cap3_lt_minbet", wait_polls=0, settled=False)
                            print(f"[skip] epoch={epoch} (cap 3% < minBet) cap3={cap3:.6f} minBet={min_bet_bnb:.6f}")
                            send_round_snapshot(
                                prefix=f"‚õî <b>Skip</b> epoch={epoch} (cap 3% ‚â§ minBet)",
                                extra_lines=[f"cap3={cap3:.6f} BNB ‚â§ minBet={min_bet_bnb:.6f} BNB"]
                            )
                            notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, False, meta.mode)
                            continue

                        # –ù–û–í–û–ï: –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ p ‚Üí p_ctx
                        # p_side –∑–¥–µ—Å—å ‚Äî ¬´—Å—ã—Ä–æ–µ¬ª –ø–æ—Å–ª–µ –∞–Ω—Å–∞–º–±–ª—è/—Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–π; –∑–∞–º–µ–Ω–∏–º –µ–≥–æ –Ω–∞ p_ctx
                        # p_side –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
                        p_side = float(np.clip(p_side, 0.0, 1.0))

                        if bootstrap_phase:
                            # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –ø–æ—Å–ª–µ 200 —Å–¥–µ–ª–æ–∫
                            if n_trades >= 200:
                                stake_pct = 0.015  # 1.5% –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                            else:
                                stake_pct = 0.01   # 1% –≤ –Ω–∞—á–∞–ª–µ
                            
                            stake = max(min_bet_bnb, stake_pct * capital)
                            stake = min(stake, cap3)
                            kelly_half = None
                        else:
                            # --- Kelly –ø–æ —Ä—ã–Ω–∫—É (—Ä–∏—Å–∫/–≤—ã–ø–ª–∞—Ç–∞ rÃÇ): f* = (p*rÃÇ - 1) / (rÃÇ - 1) ---
                            # --- Kelly –ø–æ —Ä—ã–Ω–∫—É (—Ä–∏—Å–∫/–≤—ã–ø–ª–∞—Ç–∞ rÃÇ): f* = (p*rÃÇ - 1) / (rÃÇ - 1) ---
                            denom_r = max(1e-6, float(r_hat) - 1.0)
                            f_kelly_base = float(max(0.0, (p_side * float(r_hat) - 1.0) / denom_r))
                            if not math.isfinite(f_kelly_base):
                                f_kelly_base = 0.0

                            # –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–Ω–∞—è –ø–æ–ø—Ä–∞–≤–∫–∏ ‚Äî –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ
                            calib_err = rolling_calib_error(CSV_PATH, n=200)   # ~ECE proxy
                            calib_err = float(np.clip(calib_err, 0.0, 0.15))
                            f_calib = float(np.clip(1.0 - 2.0*calib_err, 0.5, 1.0))
                            if not math.isfinite(f_calib):
                                f_calib = 1.0

                            sigma_star = 0.01
                            sigma_realized = realized_sigma_g(CSV_PATH, n=200)
                            sigma_realized = max(sigma_realized, 1e-6)
                            if not math.isfinite(sigma_realized):
                                sigma_realized = 1e-6
                            f_vol = float(np.clip(sigma_star / sigma_realized, 0.5, 2.0))

                            # –í—ã—á–∏—Å–ª—è–µ–º –≤–∏–Ω—Ä–µ–π—Ç –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –∫–∞–ø–∞
                            recent_wr = rolling_winrate_laplace(CSV_PATH, n=100, max_epoch_exclusive=epoch)
                            if recent_wr is None:
                                recent_wr = 0.53  # –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π fallback

                            # ============================================
                            # === Kelly/10 —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –∫–∞–ø–æ–º ===
                            # ============================================
                            
                            KELLY_DIVISOR = 10  # –±—ã–ª–æ 16
                            
                            # –í—ã—á–∏—Å–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π Kelly (base * calibration)
                            f_eff = f_kelly_base * f_calib
                            if not math.isfinite(f_eff):
                                f_eff = 0.0
                            
                            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–µ–ª–∏—Ç–µ–ª—å (Kelly/10)
                            f_eff_scaled = f_eff * (1.0 / float(KELLY_DIVISOR))
                            
                            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∫–∞–ø —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é
                            edge = p_side - (1.0 / r_hat)
                            f_cap = adaptive_kelly_cap(
                                edge=edge,
                                recent_wr=recent_wr,
                                calib_error=calib_err,
                                vol_scale=f_vol
                            )
                            f_eff_scaled = min(f_eff_scaled, f_cap)
                            
                            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                            frac = float(np.clip(f_eff_scaled, 0.001, 0.025))  # –º–∞–∫—Å 2.5% (–æ–±–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ 1.5%)
                            frac *= f_vol
                            
                            # –ú–∞—Å—à—Ç–∞–± –≤ –ø—Ä–æ—Å–∞–¥–∫–µ (–±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è 0.5)
                            try:
                                dd_scale = _dd_scale_factor(CSV_PATH)
                                frac *= dd_scale
                                print(f"[kelly] f_base={f_kelly_base:.5f}, f_eff={f_eff:.5f}, "
                                    f"f_scaled={f_eff_scaled:.5f}, edge={edge:.4f}, f_cap={f_cap:.5f}, "
                                    f"recent_wr={recent_wr:.3f}, dd_scale={dd_scale:.3f}, final frac={frac:.5f}")
                            except Exception:
                                print(f"[kelly] f_base={f_kelly_base:.5f}, f_eff={f_eff:.5f}, "
                                    f"f_scaled={f_eff_scaled:.5f}, edge={edge:.4f}, f_cap={f_cap:.5f}, "
                                    f"recent_wr={recent_wr:.3f}, final frac={frac:.5f}")
                            
                            # Kelly –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º –∫–æ–¥–æ–º)
                            kelly_half = f_eff_scaled  # –¥–ª—è –ª–æ–≥–æ–≤
                            
                            stake = max(min_bet_bnb, frac * capital)
                            stake = min(stake, cap3)


                        if stake <= 0 or capital < min_bet_bnb * 1.0:
                            bets[epoch] = dict(skipped=True, reason="small_cap", wait_polls=0, settled=False)
                            print(f"[skip] epoch={epoch} (capital too small) cap={capital:.6f} minBet={min_bet_bnb:.6f}")
                            send_round_snapshot(
                                prefix=f"‚õî <b>Skip</b> epoch={epoch} (–º–∞–ª—ã–π –∫–∞–ø–∏—Ç–∞–ª)",
                                extra_lines=[f"capital={capital:.6f} BNB, minBet={min_bet_bnb:.6f} BNB"]
                            )
                            notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, False, meta.mode)
                            continue

                        # === –ü–†–û–í–ï–†–ö–ê –ë–ê–õ–ê–ù–°–ê (PAPER/REAL MODE) ===
                        wallet_balance = get_wallet_balance(w3, WALLET_ADDRESS, paper_capital=capital)
                        
                        # –†–µ–∑–µ—Ä–≤ –Ω–∞ —Ñ–ª—É–∫—Ç—É–∞—Ü–∏–∏ –≥–∞–∑–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è REAL mode)
                        BALANCE_RESERVE = 0.005 if not PAPER_TRADING else 0.0
                        required_total = stake + gas_bet_bnb_cur + gas_claim_bnb_cur + BALANCE_RESERVE
                        
                        mode_label = "paper" if PAPER_TRADING else "real"
                        
                        if wallet_balance < required_total:
                            bets[epoch] = dict(skipped=True, reason="insufficient_balance", wait_polls=0, settled=False)
                            print(f"[skip] epoch={epoch} insufficient {mode_label} balance: need={required_total:.6f} have={wallet_balance:.6f}")
                            send_round_snapshot(
                                prefix=f"‚õî <b>Skip</b> epoch={epoch} (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ {mode_label} –±–∞–ª–∞–Ω—Å–∞)",
                                extra_lines=[
                                    f"–¢—Ä–µ–±—É–µ—Ç—Å—è: {required_total:.6f} BNB",
                                    f"–î–æ—Å—Ç—É–ø–Ω–æ: {wallet_balance:.6f} BNB",
                                    f"–ù–µ—Ö–≤–∞—Ç–∫–∞: {(required_total - wallet_balance):.6f} BNB",
                                    f"–†–µ–∂–∏–º: {'üìÑ PAPER' if PAPER_TRADING else 'üí∞ REAL'}"
                                ]
                            )
                            notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, False, meta.mode)
                            continue
                        
                        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º stake –≤–Ω–∏–∑, –µ—Å–ª–∏ –±–∞–ª–∞–Ω—Å –±–ª–∏–∑–æ–∫ –∫ –º–∏–Ω–∏–º—É–º—É
                        safe_stake = wallet_balance - gas_bet_bnb_cur - gas_claim_bnb_cur - BALANCE_RESERVE
                        if safe_stake < stake:
                            print(f"[balance] stake adjusted: {stake:.6f} ‚Üí {safe_stake:.6f} ({mode_label} mode)")
                            stake = safe_stake
                        
                        if stake < min_bet_bnb:
                            bets[epoch] = dict(skipped=True, reason="stake_too_small_after_balance_check", wait_polls=0, settled=False)
                            print(f"[skip] epoch={epoch} stake too small after {mode_label} balance adjustment: {stake:.6f} < {min_bet_bnb:.6f}")
                            send_round_snapshot(
                                prefix=f"‚õî <b>Skip</b> epoch={epoch} (—Å—Ç–∞–≤–∫–∞ –º–∞–ª–∞ –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ {mode_label} –±–∞–ª–∞–Ω—Å–∞)",
                                extra_lines=[
                                    f"–°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞–≤–∫–∞: {stake:.6f} BNB",
                                    f"–ú–∏–Ω–∏–º—É–º: {min_bet_bnb:.6f} BNB",
                                    f"–†–µ–∂–∏–º: {'üìÑ PAPER' if PAPER_TRADING else 'üí∞ REAL'}"
                                ]
                            )
                            notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, False, meta.mode)
                            continue


                        override_reasons = []
                        if bootstrap_phase:
                            override_reasons.append("bootstrap –º–µ–Ω—å—à–µ —á–µ–º 500")
                        if not has_recent:
                            override_reasons.append("idle‚â•1h")
                        if meta.mode != "ACTIVE":
                            override_reasons.append("meta‚â†ACTIVE")

                        # === –ê–î–ê–ü–¢–ò–í–ù–ê–Ø Œ¥: –º–Ω–æ–≥–æ—Ñ–∞–∫—Ç–æ—Ä–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è ===
                        if not bootstrap_phase and has_recent and meta.mode == "ACTIVE":
                            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                            recent_wr = rolling_winrate_laplace(CSV_PATH, n=100, max_epoch_exclusive=epoch)
                            calib_err = rolling_calib_error(CSV_PATH, n=200)
                            n_trades_hour = count_trades_last_hour(CSV_PATH)
                            
                            # –í—ã—á–∏—Å–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é –¥–µ–ª—å—Ç—É
                            delta_eff = adaptive_delta_protect(
                                recent_wr=recent_wr or 0.53,
                                calib_error=calib_err or 0.05,
                                n_trades=n_trades_hour or 25
                            )
                            
                            print(f"[delta] adaptive: Œ¥={delta_eff:.3f} | wr={recent_wr or 0.53:.2%} | calib_err={calib_err or 0.05:.3f} | trades/h={n_trades_hour or 25}")
                        else:
                            delta_eff = DELTA_PROTECT
                            print(f"[delta] base: Œ¥={delta_eff:.3f} (override mode)")

                        # —É—Å—Ç–æ–π—á–∏–≤–µ–µ –ø—Ä–æ–≤–µ—Ä–∫–∞ override-—É—Å–ª–æ–≤–∏–π (—á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
                        critical_flags = ("bootstrap –º–µ–Ω—å—à–µ —á–µ–º 500", "idle‚â•1h")
                        has_critical_override = bool(
                            override_reasons and any(flag in r for r in override_reasons for flag in critical_flags)
                        )

                        # ============================================================
                        # === EV-GATE: OR-–ª–æ–≥–∏–∫–∞ —Å —Ç—Ä–µ–º—è –ø—É—Ç—è–º–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞ ===
                        # ============================================================
                        
                        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –≤–µ—Ç–æ–∫
                        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –≤–µ—Ç–æ–∫
                        q70_loss = 0.0
                        q50_loss = 0.0
                        margin_vs_market = 0.0
                        p_thr = 0.0
                        p_thr_ev = 0.0
                        pass_reason = "NA"

                        if has_critical_override:
                            # === –†–ï–ñ–ò–ú OVERRIDE: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ ===
                            p_thr = 0.51
                            p_thr_src = f"fixed(0.51; {' & '.join(override_reasons)})"
                            
                            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è override
                            if p_side < p_thr:
                                bets[epoch] = dict(
                                    skipped=True, reason="ev_gate_override",
                                    p_side=p_side, p_thr=p_thr, p_thr_src=p_thr_src,
                                    r_hat=r_hat, r_hat_source=r_hat_source,
                                    gb_hat=gb_hat, gc_hat=gc_hat, stake=stake,
                                    delta15=(_as_float(locals().get('delta15'), None) if USE_STRESS_R15 else None),
                                    wait_polls=0, settled=False,
                                    p_meta_raw=float(p_meta_raw) if 'p_meta_raw' in locals() else float('nan'),
                                    calib_src=str(calib_src) if 'calib_src' in locals() else "calib[off]"
                                )
                                
                                side_txt = "UP" if bet_up else "DOWN"
                                print(f"[skip] epoch={epoch} side={side_txt} override p={p_side:.4f} < p_thr={p_thr:.4f} [{p_thr_src}]")
                                
                                # === Telegram notification ===
                                try:
                                    notify_ev_decision(
                                        title="‚õî Skip (override)",
                                        epoch=epoch,
                                        side_txt=side_txt,
                                        p_side=p_side,
                                        p_thr=p_thr,
                                        p_thr_src=p_thr_src,
                                        r_hat=r_hat,
                                        gb_hat=gb_hat,
                                        gc_hat=gc_hat,
                                        stake=stake,
                                        delta15=(_as_float(locals().get('delta15'), None) if USE_STRESS_R15 else None),
                                        extra_lines=[],
                                        delta_eff=0.0,
                                    )
                                except Exception as e:
                                    print(f"[tg ] notify skip failed: {e}")
                                
                                # === Snapshot ===
                                send_round_snapshot(
                                    prefix=f"‚õî <b>Skip</b> epoch={epoch} (override)",
                                    extra_lines=[
                                        f"side=<b>{side_txt}</b>, p={p_side:.4f} < p_thr={p_thr:.4f}",
                                        f"–ü—Ä–∏—á–∏–Ω–∞: {' & '.join(override_reasons)}"
                                    ]
                                )
                                
                                notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, False, meta.mode)
                                continue

                        else:
                            # === –†–ï–ñ–ò–ú –ü–û–õ–ù–û–¶–ï–ù–ù–û–ô –ü–†–û–í–ï–†–ö–ò: OR-–ª–æ–≥–∏–∫–∞ ===
                            
                            # –í—ã—á–∏—Å–ª—è–µ–º –í–°–ï –º–µ—Ç—Ä–∏–∫–∏ –∑–∞—Ä–∞–Ω–µ–µ
                            # –í—ã—á–∏—Å–ª—è–µ–º –í–°–ï –º–µ—Ç—Ä–∏–∫–∏ –∑–∞—Ä–∞–Ω–µ–µ (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç None)
                            try:
                                q70_loss = loss_margin_q(csv_path=CSV_PATH, max_epoch_exclusive=epoch, q=0.70)
                                q70_loss = _as_float(q70_loss, 0.0)
                            except Exception:
                                q70_loss = 0.0
                            
                            try:
                                q50_loss = loss_margin_q(csv_path=CSV_PATH, max_epoch_exclusive=epoch, q=0.50)
                                q50_loss = _as_float(q50_loss, 0.0)
                            except Exception:
                                q50_loss = 0.0
                            
                            try:
                                margin_vs_market = _as_float(p_side, 0.5) - (1.0 / max(1e-9, _as_float(r_hat, 1.9)))
                            except Exception:
                                margin_vs_market = 0.0
                            
                            try:
                                p_thr_ev = p_thr_from_ev(
                                    r_hat=_as_float(r_hat, 1.9),
                                    stake=max(1e-9, _as_float(stake, 0.001)),
                                    gb_hat=_as_float(gb_hat, 0.0),
                                    gc_hat=_as_float(gc_hat, 0.0),
                                    delta=_as_float(delta_eff, 0.0)
                                )
                                p_thr_ev = _as_float(p_thr_ev, 0.51)
                            except Exception as e:
                                print(f"[ev_gate] p_thr_from_ev failed: {e}")
                                p_thr_ev = 0.51
                            
                            # p_thr –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: p_thr + Œ¥ = p_thr_ev
                            p_thr = float(max(0.0, p_thr_ev - float(delta_eff)))
                            
                            # –¢—Ä–∏ –ø—É—Ç–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞ (OR-–ª–æ–≥–∏–∫–∞):
                            pass_ev_strong = (p_side >= (p_thr + delta_eff))
                            pass_margin_q70 = (margin_vs_market >= q70_loss) and (p_side >= (p_thr + 0.5 * delta_eff))
                            pass_margin_q50 = (margin_vs_market >= q50_loss) and (p_side >= (p_thr + delta_eff))
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                            if pass_ev_strong:
                                pass_reason = "EV_strong"
                            elif pass_margin_q70:
                                pass_reason = "margin_q70"
                            elif pass_margin_q50:
                                pass_reason = "margin_q50"
                            else:
                                pass_reason = "FAIL"
                            
                            # bnbusdrt6.py  (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ pass_reason ‚Äî –±–µ–∑–æ–ø–∞—Å–Ω–æ –∫ –Ω–µ–∑–∞–¥–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º)
                            _safe_q70 = float(q70_loss) if isinstance(q70_loss, (int, float)) and math.isfinite(float(q70_loss)) else 0.0
                            _safe_q50 = float(q50_loss) if isinstance(q50_loss, (int, float)) and math.isfinite(float(q50_loss)) else 0.0
                            _safe_margin = float(margin_vs_market) if isinstance(margin_vs_market, (int, float)) and math.isfinite(float(margin_vs_market)) else 0.0
                            _safe_r = float(r_hat) if isinstance(r_hat, (int, float)) and math.isfinite(float(r_hat)) else 1.0
                            _safe_reason = pass_reason if isinstance(pass_reason, str) else "NA"

                            p_thr_src = (f"EV|Œ¥+gas; q70={_safe_q70:.4f}, q50={_safe_q50:.4f}; "
                                        f"margin={_safe_margin:+.4f}; rÃÇ={_safe_r:.3f}; "
                                        f"pass={_safe_reason}")

                            
                            # === –ü–†–û–í–ï–†–ö–ê: —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —É—Å–ª–æ–≤–∏–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–π—Ç–∏ ===
                            if not (pass_ev_strong or pass_margin_q70 or pass_margin_q50):
                                # SKIP: –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø—Ä–æ–≤–∞–ª–µ–Ω—ã
                                
                                bets[epoch] = dict(
                                    skipped=True, reason="ev_gate",
                                    p_side=p_side, p_thr=p_thr, p_thr_src=p_thr_src,
                                    r_hat=r_hat, r_hat_source=r_hat_source,
                                    gb_hat=gb_hat, gc_hat=gc_hat, stake=stake,
                                    delta15=(_as_float(locals().get('delta15'), None) if USE_STRESS_R15 else None),
                                    wait_polls=0, settled=False,
                                    p_meta_raw=float(p_meta_raw) if 'p_meta_raw' in locals() else float('nan'),
                                    calib_src=str(calib_src) if 'calib_src' in locals() else "calib[off]"
                                )
                                
                                side_txt = "UP" if bet_up else "DOWN"
                                kelly_txt = ("‚Äî" if (kelly_half is None or not (isinstance(kelly_half, (int, float)) and math.isfinite(kelly_half)))
                                             else f"{kelly_half:.3f}")
                                
                                # === Telegram notification ===
                                # === Telegram notification ===
                                try:
                                    _safe_margin = float(margin_vs_market) if isinstance(margin_vs_market, (int, float)) and math.isfinite(float(margin_vs_market)) else 0.0
                                    _safe_q70 = float(q70_loss) if isinstance(q70_loss, (int, float)) and math.isfinite(float(q70_loss)) else 0.0
                                    _safe_q50 = float(q50_loss) if isinstance(q50_loss, (int, float)) and math.isfinite(float(q50_loss)) else 0.0

                                    notify_ev_decision(
                                        title="‚õî Skip by EV gate",
                                        epoch=epoch,
                                        side_txt=side_txt,
                                        p_side=p_side,
                                        p_thr=p_thr,
                                        p_thr_src=p_thr_src,
                                        r_hat=r_hat,
                                        gb_hat=gb_hat,
                                        gc_hat=gc_hat,
                                        stake=stake,
                                        delta15=(_as_float(locals().get('delta15'), None) if USE_STRESS_R15 else None),
                                        extra_lines=[
                                            f"Kelly/2:   {kelly_txt}",
                                            f"‚ùå EV strong: p={_as_float(p_side,0.0):.4f} < p_thr+Œ¥={(_as_float(p_thr)+_as_float(delta_eff,0.0)):.4f}",
                                            f"‚ùå Margin q70: margin={_safe_margin:+.4f} < q70={_safe_q70:.4f}",
                                            f"‚ùå Margin q50: margin={_safe_margin:+.4f} < q50={_safe_q50:.4f}",
                                        ],
                                        delta_eff=delta_eff,
                                    )
                                except Exception as e:
                                    print(f"[tg ] notify skip failed: {e}")

                                
                                # === Console log ===
                                print(f"[skip] epoch={epoch} side={side_txt} EV-gate ALL FAIL | "
                                    f"p={_as_float(p_side,0.0):.4f} p_thr+Œ¥={(_as_float(p_thr)+_as_float(delta_eff,0.0)):.4f} | "
                                    f"margin={float(margin_vs_market):+.4f} q70={float(q70_loss):.4f} q50={float(q50_loss):.4f} | "
                                    f"rÃÇ={float(r_hat):.3f} S={float(stake):.6f}")

                                
                                # === Snapshot ===
                                # === Snapshot ===
                                _delta15_str = None
                                if USE_STRESS_R15 and (('delta15' in locals()) or ('delta15' in globals())):
                                    _d15 = _as_float(delta15, float("nan"))
                                    if math.isfinite(_d15):
                                        _delta15_str = f"Œî15_med={(_d15/1e18 if _d15 > 1e6 else _d15):.4f} BNB"


                                _safe_margin = float(margin_vs_market) if isinstance(margin_vs_market, (int, float)) and math.isfinite(float(margin_vs_market)) else 0.0
                                _safe_q70 = float(q70_loss) if isinstance(q70_loss, (int, float)) and math.isfinite(float(q70_loss)) else 0.0
                                _safe_q50 = float(q50_loss) if isinstance(q50_loss, (int, float)) and math.isfinite(float(q50_loss)) else 0.0
                                extra = [
                                    f"p_ctx={p_side:.4f} vs p_thr_ev={(p_thr + delta_eff):.4f} [{p_thr_src}]",
                                    f"‚ùå EV strong: {p_side:.4f} < {(p_thr + delta_eff):.4f}",
                                    f"‚ùå Margin q70: {_safe_margin:+.4f} < {_safe_q70:.4f}",
                                    f"‚ùå Margin q50: {_safe_margin:+.4f} < {_safe_q50:.4f}",
                                    f"rÃÇ={r_hat:.3f} [{r_hat_source}], S={stake:.6f}, gbÃÇ={gb_hat:.8f}, gƒâ={gc_hat:.8f}",
                                    _delta15_str,
                                    f"gas_bet‚âà{gas_bet_bnb_cur:.8f} BNB",
                                    (f"–ø–æ—Ä–æ–≥-–æ–≤–µ—Ä—Ä–∞–π–¥—ã: {', '.join(override_reasons)}" if override_reasons else None),
                                    f"Kelly/8={kelly_txt}",
                                ]
                                
                                extra = [x for x in extra if x is not None]
                                
                                send_round_snapshot(
                                    prefix=f"‚õî <b>Skip</b> epoch={epoch} (EV-gate)",
                                    extra_lines=extra
                                )
                                
                                notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, False, meta.mode)
                                
                                # === –¢–µ–Ω–µ–≤–æ–π –ª–æ–≥ ===
                                try:
                                    gas_gwei_for_log = float(gas_gwei_now) if 'gas_gwei_now' in locals() else float(get_gas_price_wei(w3)) / 1e9
                                    append_shadow_row(CSV_SHADOW_PATH, {
                                        "settled_ts": "",
                                        "epoch": epoch,
                                        "side": side_txt,
                                        "p_up": float(p_side if side_txt == "UP" else 1.0 - p_side),
                                        "p_thr_used": float(p_thr),
                                        "p_thr_src": str(p_thr_src),
                                        "edge_at_entry": float("nan"),
                                        "stake": float(stake),
                                        "gas_bet_bnb": float(gas_bet_bnb_cur),
                                        "gas_claim_bnb": float(gas_claim_bnb_cur),
                                        "gas_price_bet_gwei": gas_gwei_for_log,
                                        "gas_price_claim_gwei": gas_gwei_for_log,
                                        "outcome": "", "pnl": "",
                                        "capital_before": float(capital),
                                        "capital_after": float(capital),
                                        "lock_ts": "", "close_ts": "",
                                        "lock_price": "", "close_price": "",
                                        "payout_ratio": "", "up_won": ""
                                    })
                                except Exception as e:
                                    print(f"[shadow] append failed: {e}")
                                
                                continue  # ‚Üê –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É epoch

                        # ============================================================
                        # === –ï–°–õ–ò –î–û–®–õ–ò –°–Æ–î–ê: –§–ò–õ–¨–¢–† –ü–†–û–ô–î–ï–ù, –†–ê–ó–ú–ï–©–ê–ï–ú –°–¢–ê–í–ö–£ ===
                        # ============================================================
                        
                        # --- —Å—á–∏—Ç–∞–µ–º –∑–∞–ø–∞—Å –Ω–∞ –≤—Ö–æ–¥–µ
                        # --- —Å—á–∏—Ç–∞–µ–º –∑–∞–ø–∞—Å –Ω–∞ –≤—Ö–æ–¥–µ
                        edge_at_entry = float(p_side - (p_thr + delta_eff))

                        _safe_margin = float(margin_vs_market) if isinstance(margin_vs_market, (int, float)) and math.isfinite(float(margin_vs_market)) else 0.0
                        print(f"[bet ] epoch={epoch} side={side} "
                            f"p_side={_as_float(p_side,0.0):.3f} ‚â• p_thr+Œ¥={(_as_float(p_thr)+_as_float(delta_eff,0.0)):.3f} "
                            f"edge@entry={edge_at_entry:+.4f} "
                            f"Kelly/2={kelly_txt if 'kelly_txt' in locals() else '‚Äî'} rÃÇ={r_hat:.3f} S={stake:.6f}")



                        # --- —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç–∞–≤–∫–∏
                        phi_wf = np.array([
                            wf_phi_dict.get("phi_wf0", 0.0),
                            wf_phi_dict.get("phi_wf1", 0.0),
                            wf_phi_dict.get("phi_wf2", 0.0),
                            wf_phi_dict.get("phi_wf3", 0.0),
                        ], dtype=float)

                        # –±—ã—Å—Ç—Ä—ã–π —Ä–µ—Ñ—Ä–µ—à REST-–ª–æ–≥–∏–∫–∏ (–≤–∞–∂–Ω–æ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ö/—Ä–µ—Å—Ç–æ—Ä–∞—Ö)
                        rest.update_from_stats(stats, cfg=rest_cfg)
                        # –ø–µ—Ä–µ–¥ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π —Å—Ç–∞–≤–∫–∏ ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º REST
                        if not rest.can_trade_now():
                            print(f"[rest] ‚è∏ –¥–æ {rest.rest_until_utc}")
                            continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç —ç–ø–∏–∑–æ–¥/–∏—Ç–µ—Ä–∞—Ü–∏—é



                        # --- —Å—á–∏—Ç–∞–µ–º –∑–∞–ø–∞—Å –Ω–∞ –≤—Ö–æ–¥–µ
                        # –ø—Ä–∏ ENTER:
                        edge_at_entry = float(p_side - (p_thr + delta_eff))   # –∑–¥–µ—Å—å p_thr+Œ¥ == p_thr_ev
                        # –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                        _safe_margin = float(margin_vs_market) if isinstance(margin_vs_market, (int, float)) and math.isfinite(margin_vs_market) else 0.0
                        _safe_q90 = float(q90_loss) if (('q90_loss' in locals()) or ('q90_loss' in globals())) and isinstance(q90_loss, (int, float)) and math.isfinite(q90_loss) else 0.0
                        # –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º p_thr_ev, –µ—Å–ª–∏ –µ—Å—Ç—å; –∏–Ω–∞—á–µ p_thr; –∏–Ω–∞—á–µ 0.0
                        _safe_pthr = None
                        if 'p_thr_ev' in locals() or 'p_thr_ev' in globals():
                            _safe_pthr = p_thr_ev
                        elif 'p_thr' in locals() or 'p_thr' in globals():
                            _safe_pthr = p_thr
                        _safe_pthr = float(_safe_pthr) if isinstance(_safe_pthr, (int, float)) and math.isfinite(_safe_pthr) else 0.0

                        _safe_p = float(p_side) if isinstance(p_side, (int, float)) and math.isfinite(p_side) else 0.0
                        _side_str = (str(side).upper() if ('side' in locals() or 'side' in globals()) else "NA")

                        _safe_p = _as_float(p_side, 0.0)
                        _safe_q70 = _as_float(q70_loss, 0.0)
                        _safe_margin = _as_float(margin_vs_market, 0.0)
                        print(f"[enter] side={_side_str} "
                            f"p_ctx={_safe_p:.4f} ‚â• p_thr+Œ¥={_as_float(p_thr) + _as_float(delta_eff, 0.0):.4f} | "
                            f"margin={_safe_margin:+.4f} ‚â• q70={_safe_q70:.4f}")
                        bets[epoch] = dict(
                            placed=True, settled=False, wait_polls=0,
                            time=now, t_lock=rd.lock_ts,
                            bet_up=bool(bet_up),
                            p_up=_as_float(P_up),
                            p_side=_as_float(p_side),
                            p_thr=_as_float(p_thr),
                            p_thr_src=str(p_thr_src),
                            r_hat=_as_float(r_hat, 1.0),
                            r_hat_source=str(r_hat_source),
                            gb_hat=_as_float(gb_hat, 0.0),
                            gc_hat=_as_float(gc_hat, 0.0),
                            kelly_half=(None if bootstrap_phase else _as_float(kelly_half, 0.0)),
                            stake=_as_float(stake, 0.0),
                            p_meta_raw=_as_float(locals().get("p_meta_raw")),
                            p_meta2_raw=_as_float(locals().get("p_meta2_raw")),
                            p_blend=_as_float(locals().get("p_blend")),
                            blend_w=_as_float(locals().get("blend_w")),
                            calib_src=str(locals().get("calib_src", "calib[off]")),
                            gas_price_bet_wei=gas_price_wei, gas_bet_bnb=gas_bet_bnb_cur,
                            edge_at_entry=edge_at_entry,
                            delta15=(_as_float(delta15, None) if (USE_STRESS_R15 and 'delta15' in locals()) else None),
                            delta_eff=_as_float(delta_eff, 0.0),
                            phi=phi, phi_wf=phi_wf,
                            ens=dict(
                                x=x_ml.tolist(),
                                p_xgb=(None if p_xgb is None else float(p_xgb)),
                                p_rf=(None if p_rf is None else float(p_rf)),
                                p_arf=(None if p_arf is None else float(p_arf)),
                                p_nn=(None if p_nn is None else float(p_nn)),
                                p_final=float(p_final) if p_final is not None else None,
                                used=bool(ens_used),
                                meta_mode=meta.mode,
                                p_base=float(p_base_before_ens),
                                reg_ctx=reg_ctx,
                            ),
                        )

                        side = "UP" if bet_up else "DOWN"
                        kelly_txt = ("‚Äî" if bootstrap_phase else f"{kelly_half:.3f}")

                        print(f"[bet ] epoch={epoch} side={side} "
                            f"... p_side={_as_float(p_side,0.0):.3f} ‚â• p_thr+Œ¥={(_as_float(p_thr)+_as_float(delta_eff,0.0)):.3f} ..."
                            f"edge@entry={_as_float(edge_at_entry,0.0):+.4f} "
                            f"Kelly/2={kelly_txt} rÃÇ={_as_float(r_hat,1.0):.3f} S={_as_float(stake,0.0):.6f} gas_bet={_as_float(gas_bet_bnb_cur,0.0):.8f}BNB "
                            f"(lock in {int(_as_float(rd.lock_ts,0)-_as_float(now,0))}s)")

                        _delta15_str = None
                        if USE_STRESS_R15 and 'delta15' in locals():
                            _d15 = _as_float(delta15, float("nan"))
                            if math.isfinite(_d15):
                                _delta15_str = f"Œî15_med={(_d15/1e18 if _d15 > 1e6 else _d15):.4f} BNB"

                        extra = [
                            f"side=<b>{side}</b>, p={_as_float(p_side,0.0):.4f} ‚â• p_thr+Œ¥={(_as_float(p_thr)+_as_float(delta_eff,0.0)):.4f} [{p_thr_src}]",
                            f"edge@entry={edge_at_entry:+.4f}",
                            f"S={stake:.6f} BNB (–∫—ç–ø {MAX_STAKE_FRACTION*100:.0f}% –æ—Ç –∫–∞–ø–∏—Ç–∞–ª–∞), gas_bet‚âà{gas_bet_bnb_cur:.8f} BNB",
                            (_delta15_str if USE_STRESS_R15 else None),
                        ]
                        if override_reasons:
                            extra.append(f"p_thr override: {', '.join(override_reasons)}")
                        if not bootstrap_phase:
                            extra.append(f"Kelly/2={kelly_half:.3f}")
                        else:
                            extra.append("Stake=1% bootstrap")

                        extra = [x for x in extra if x is not None]
                        send_round_snapshot(prefix=f"‚úÖ <b>Bet</b> epoch={epoch}", extra_lines=extra)

                        # ========== –í–°–¢–ê–í–ò–¢–¨ –°–Æ–î–ê ==========
                        # === –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–ë–™–Ø–°–ù–ï–ù–ò–Ø –†–ï–®–ï–ù–ò–Ø META ===
                        try:
                            from meta_explainer import create_explanation_for_bet
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞—Å UTC –¥–ª—è time_of_day
                            from datetime import datetime, timezone
                            hour_utc = datetime.now(timezone.utc).hour
                            if 0 <= hour_utc < 8:
                                time_of_day = "asian"
                            elif 8 <= hour_utc < 16:
                                time_of_day = "european"
                            elif 16 <= hour_utc < 24:
                                time_of_day = "us"
                            else:
                                time_of_day = "quiet"
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â–∏–π streak –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
                            try:
                                df_recent = _read_csv_df(CSV_PATH).tail(10)
                                outcomes = df_recent[df_recent["outcome"].isin(["win", "loss"])]["outcome"].tolist()
                                if outcomes:
                                    last_outcome = outcomes[-1]
                                    streak_count = 1
                                    for i in range(len(outcomes)-2, -1, -1):
                                        if outcomes[i] == last_outcome:
                                            streak_count += 1
                                        else:
                                            break
                                    current_streak = f"{streak_count}{'W' if last_outcome=='win' else 'L'}"
                                else:
                                    current_streak = "0"
                            except Exception:
                                current_streak = "0"
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥ –∏–∑ —Ñ–∏—á
                            try:
                                mom = feats.get("momentum_1h", 0) if hasattr(feats, 'get') else 0
                                if mom > 0.02:
                                    trend = "strong_up"
                                elif mom > 0.005:
                                    trend = "weak_up"
                                elif mom < -0.02:
                                    trend = "strong_down"
                                elif mom < -0.005:
                                    trend = "weak_down"
                                else:
                                    trend = "sideways"
                            except Exception:
                                trend = "sideways"
                            
                            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                            context_for_explainer = {
                                "volatility": "high" if feats.get("atr_norm", 0) > 0.015 else ("low" if feats.get("atr_norm", 0) < 0.005 else "medium"),
                                "trend": trend,
                                "volume": "high" if feats.get("volume_ratio", 1) > 1.5 else "normal",
                                "time_of_day": time_of_day,
                                "recent_streak": current_streak
                            }
                            
                            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ META (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
                            meta_weights_dict = None
                            if meta and hasattr(meta, 'w'):
                                try:
                                    weights_array = meta.w if isinstance(meta.w, np.ndarray) else np.array(meta.w)
                                    if len(weights_array) >= 4:
                                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞ –∫ —Å—É–º–º–µ 1.0
                                        weights_sum = weights_array[:4].sum()
                                        if weights_sum > 0:
                                            norm_weights = weights_array[:4] / weights_sum
                                            meta_weights_dict = {
                                                "xgb": float(norm_weights[0]),
                                                "rf": float(norm_weights[1]),
                                                "arf": float(norm_weights[2]),
                                                "nn": float(norm_weights[3]),
                                            }
                                except Exception:
                                    pass
                            
                            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º feats –≤ dict (–µ—Å–ª–∏ —ç—Ç–æ pandas Series)
                            feats_dict = {}
                            try:
                                if hasattr(feats, 'to_dict'):
                                    feats_dict = feats.to_dict()
                                elif isinstance(feats, dict):
                                    feats_dict = feats
                                else:
                                    feats_dict = dict(feats)
                            except Exception:
                                feats_dict = {}
                            
                            explanation = create_explanation_for_bet(
                                p_final=float(p_final) if p_final is not None else float(p_side),
                                p_xgb=float(p_xgb) if p_xgb is not None else None,
                                p_rf=float(p_rf) if p_rf is not None else None,
                                p_arf=float(p_arf) if p_arf is not None else None,
                                p_nn=float(p_nn) if p_nn is not None else None,
                                meta_weights=meta_weights_dict,
                                features=feats_dict,
                                context=context_for_explainer
                            )
                            
                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤ Telegram
                            tg_send(f"üìä <b>–ê–Ω–∞–ª–∏–∑ —Ä–µ—à–µ–Ω–∏—è (epoch {epoch})</b>\n\n{explanation}")
                            
                        except Exception as e:
                            print(f"[explainer] failed: {e}")
                        # ========== –ö–û–ù–ï–¶ –í–°–¢–ê–í–ö–ò ==========

                        notify_ens_used(p_base_before_ens, p_xgb, p_rf, p_arf, p_nn, p_final, ens_used, meta.mode)

                    elif now >= rd.lock_ts:
                        bets[epoch] = dict(skipped=True, reason="late", wait_polls=0, settled=False)
                        print(f"[late] epoch={epoch} missed betting window")
                        send_round_snapshot(
                            prefix=f"‚õî <b>Skip</b> epoch={epoch} (late)",
                            extra_lines=["–ü—Ä–∏—á–∏–Ω–∞: –æ–∫–Ω–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –∑–∞–∫—Ä—ã—Ç–æ."]
                        )
                        notify_ens_used(None, None, None, None, None, None, False, meta.mode)

                # --- –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è/—Å–µ—Ç—Ç–ª–∞
                b = bets.get(epoch)
                if not b or b.get("settled"):
                    continue

                # –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å—á–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ close_ts
                if b.get("skipped") and now > rd.close_ts:
                    b["settled"] = True
                    b["outcome"] = "skipped"
                    send_round_snapshot(
                        prefix=f"‚ÑπÔ∏è <b>Round</b> epoch={epoch} finalized (skip).",
                        extra_lines=["–†–∞—É–Ω–¥ –∑–∞–≤–µ—Ä—à—ë–Ω, –ø—Ä–æ–ø—É—Å–∫ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω."]
                    )
                    continue

                # –æ–±—ã—á–Ω—ã–π —Å–µ—Ç—Ç–ª ‚Äî –∫–æ–≥–¥–∞ oracleCalled
                # –æ–±—ã—á–Ω—ã–π —Å–µ—Ç—Ç–ª ‚Äî –∫–æ–≥–¥–∞ oracleCalled
                if rd.oracle_called:
                    # –æ–±–Ω–æ–≤–∏–º –∏—Å—Ç–æ—Ä–∏—é ¬´–ø–æ–∑–¥–Ω–∏—Ö –¥–µ–Ω–µ–≥¬ª –ø–æ —Ç–æ–ª—å–∫–æ —á—Ç–æ –∑–∞–∫—Ä—ã—Ç–æ–º—É —Ä–∞—É–Ω–¥—É
                    # –æ–±–Ω–æ–≤–∏–º –∏—Å—Ç–æ—Ä–∏—é ¬´–ø–æ–∑–¥–Ω–∏—Ö –¥–µ–Ω–µ–≥¬ª –ø–æ —Ç–æ–ª—å–∫–æ —á—Ç–æ –∑–∞–∫—Ä—ã—Ç–æ–º—É —Ä–∞—É–Ω–¥—É
                    try:
                        # ‚ú≥Ô∏è –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–Ω–∏–º–æ–∫ –Ω–∞ —Å–∞–º–æ–º lock_ts (–ø–æ—Å–ª–µ —Ä–µ—Å—Ç–∞—Ä—Ç–æ–≤/–ª–∞–≥–æ–≤ –µ–≥–æ –º–æ–≥–ª–æ –Ω–µ –±—ã—Ç—å)
                        pool.observe(epoch, rd.lock_ts, rd.bull_amount, rd.bear_amount)
                        pool.finalize_epoch(epoch, rd.lock_ts)
                    except Exception:
                        pass
                    # –§–æ–ª–±—ç–∫ –¥–ª—è –≥–∞–∑–∞ –Ω–∞ —Å–ª—É—á–∞–π —Å–±–æ—è RPC ‚Äî –ù–ï –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Å–µ—Ç—Ç–ª –∏–∑-–∑–∞ –≥–∞–∑–∞
                    fallback_wei = 0
                    try:
                        fallback_wei = int(float(b.get("gas_price_bet_wei", 0)) or 0)
                    except Exception:
                        fallback_wei = 0
                    if fallback_wei <= 0:
                        try:
                            # –µ—Å–ª–∏ —Ä–∞–Ω–µ–µ –≥–¥–µ-—Ç–æ —É–∂–µ –±—Ä–∞–ª–∏ –≥–∞–∑ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                            fallback_wei = int(gas_price_wei)  # –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –æ–∫
                        except Exception:
                            fallback_wei = 0

                    try:
                        gas_price_claim_wei = get_gas_price_wei(w3)
                        rpc_fail_streak = 0
                    except Exception as e:
                        print(f"[rpc ] gas_price (claim) failed: {e}")
                        rpc_fail_streak += 1
                        # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ–ª–±—ç–∫ –≤–º–µ—Å—Ç–æ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
                        gas_price_claim_wei = fallback_wei if fallback_wei > 0 else 3_000_000_000
                        if rpc_fail_streak >= RPC_FAIL_MAX:
                            try:
                                w3 = connect_web3()
                                c = get_prediction_contract(w3)
                                rpc_fail_streak = 0
                                print("[rpc ] reconnected")
                            except Exception as ee:
                                print(f"[rpc ] reconnect failed: {ee}")
                        # –í–ê–ñ–ù–û: –±–µ–∑ continue ‚Äî –∏–¥—ë–º –¥–∞–ª—å—à–µ –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ –∏—Å—Ö–æ–¥–∞
                    # ... –¥–∞–ª–µ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ outcome/pnl –∏ send_round_snapshot(...)


                    outcome = None
                    pnl = 0.0
                    gas_claim_bnb = 0.0

                    bet_up = bool(b.get("bet_up", False))
                    stake = _as_float(b.get("stake", 0.0), 0.0)
                    gas_bet_bnb = _as_float(b.get("gas_bet_bnb", 0.0), 0.0)

                    lock_price = _as_float(getattr(rd, "lock_price", None), 0.0)
                    close_price = _as_float(getattr(rd, "close_price", None), 0.0)

                    up_won = close_price > lock_price
                    down_won = close_price < lock_price
                    draw = close_price == lock_price

                    if NN_USE and logreg is not None and (not draw) and ("phi" in b):
                        try:
                            logreg.update(np.array(b["phi"], dtype=float), 1 if up_won else 0)
                            logreg.save()
                        except Exception:
                            pass

                    capital_before = capital
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–π –∫–∞–ø–∏—Ç–∞–ª –ë–ï–ó –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π capital
                    if draw:
                        gas_claim_bnb = _as_float(GAS_USED_CLAIM * gas_price_claim_wei / 1e18, 0.0)
                        new_capital = capital - (gas_bet_bnb + gas_claim_bnb)
                        pnl = -(gas_bet_bnb + gas_claim_bnb)
                        outcome = "draw"
                    else:
                        ratio = _as_float(getattr(rd, "payout_ratio", None), 1.9)
                        if ratio <= 1.0:
                            ratio = 1.9
                        
                        if (bet_up and up_won) or ((not bet_up) and down_won):
                            profit = stake * (ratio - 1.0)
                            gas_claim_bnb = _as_float(GAS_USED_CLAIM * gas_price_claim_wei / 1e18, 0.0)
                            new_capital = capital + profit - (gas_bet_bnb + gas_claim_bnb)
                            pnl = profit - (gas_bet_bnb + gas_claim_bnb)
                            outcome = "win"
                        else:
                            new_capital = capital - stake - gas_bet_bnb
                            pnl = -stake - gas_bet_bnb
                            outcome = "loss"

                    b.update(dict(
                        settled=True, outcome=outcome, pnl=pnl,
                        gas_price_claim_wei=gas_price_claim_wei, gas_claim_bnb=gas_claim_bnb,
                        capital_after=new_capital, payout_ratio=rd.payout_ratio
                    ))
                    side = "UP" if bet_up else "DOWN"
                    print(f"[setl] epoch={epoch} side={side} outcome={outcome} pnl={pnl:+.6f} "
                          f"cap={capital:.6f} ratio={rd.payout_ratio if rd.payout_ratio else float('nan'):.3f} up_won={up_won}")

                    # Walk-Forward –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (–∑–∞–º–æ—Ä–æ–∑–∫–∞ –¥–æ 500 —Å–¥–µ–ª–æ–∫)
                    try:
                        if WF_USE and ("phi_wf" in b) and (not draw):
                            n_trades = _settled_trades_count(CSV_PATH)  # —É–∂–µ –µ—Å—Ç—å –≤ —Ñ–∞–π–ª–µ
                            if n_trades >= MIN_TRADES_FOR_DELTA:        # MIN_TRADES_FOR_DELTA = 500
                                y_up = 1.0 if up_won else 0.0
                                wf.update(np.array(b["phi_wf"], dtype=float), y_up)
                                wf.save()
                                print(f"[wf  ] updated weights = {wf.w}")
                            else:
                                # –¥–æ 500 —Å–¥–µ–ª–æ–∫ WF –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
                                pass
                    except Exception:
                        pass


                    # –ê–Ω—Å–∞–º–±–ª—å: –∞–ø–¥–µ–π—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –∏ –º–µ—Ç—ã
                    try:
                        ens_info = b.get("ens") or {}   # ‚Üê –µ—Å–ª–∏ None ‚Üí {}
                        x_ml = np.array(ens_info.get("x", []), dtype=float)
                        p_xgb = ens_info.get("p_xgb", None)
                        p_rf  = ens_info.get("p_rf", None)
                        p_arf = ens_info.get("p_arf", None)
                        p_nn  = ens_info.get("p_nn", None)
                        p_fin = ens_info.get("p_final", None)
                        p_base = ens_info.get("p_base", None)
                        used_flag = bool(ens_info.get("used", False))

                        reg_ctx = (ens_info.get("reg_ctx", {}) or {})
                        reg_ctx = dict(reg_ctx, epoch=int(epoch))  # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–∞—É–Ω–¥–∞

                        if not draw:
                            y_up_int = 1 if up_won else 0

                            # –°–Ω–∞—á–∞–ª–∞ ‚Äî –ú–ï–¢–ê (–Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç x_ml, —á—Ç–æ–±—ã –æ–ø—ã—Ç —Ä–æ—Å –≤—Å–µ–≥–¥–∞)
                            try:
                                meta.settle(
                                    p_xgb, p_rf, p_arf, p_nn,
                                    p_base=p_base,
                                    y_up=y_up_int,
                                    used_in_live=used_flag,
                                    p_final_used=p_fin,
                                    reg_ctx=reg_ctx
                                )
                            except Exception as e:
                                print(f"[ens ] meta.settle error: {e}")

                            # –ó–∞—Ç–µ–º ‚Äî —ç–∫—Å–ø–µ—Ä—Ç—ã (–ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ x_ml –≤–∞–ª–∏–¥–µ–Ω)
                            try:
                                x_ok = hasattr(x_ml, "size") and isinstance(x_ml.size, (int,)) and x_ml.size > 0

                                if x_ok and xgb_exp.enabled:
                                    xgb_exp.record_result(x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_xgb, reg_ctx=reg_ctx)
                                    xgb_exp.maybe_train()

                                if x_ok and rf_exp.enabled:
                                    rf_exp.record_result( x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_rf,  reg_ctx=reg_ctx)
                                    rf_exp.maybe_train()

                                if x_ok and arf_exp.enabled:
                                    arf_exp.record_result(x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_arf, reg_ctx=reg_ctx)

                                if x_ok and nn_exp.enabled:
                                    nn_exp.record_result( x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_nn,  reg_ctx=reg_ctx)
                                    nn_exp.maybe_train()

                            except Exception as e:
                                print(f"[ens ] experts update error: {e}")



                            # –£–ü–†–û–©–ï–ù–û: –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä
                            try:
                                CM1 = globals().get("_CALIB_MGR")
                                if CM1 and ("p_meta_raw" in b) and _is_finite_num(b["p_meta_raw"]):
                                    CM1.update(_as_float(b["p_meta_raw"]), int(y_up_int), int(time.time()))
                            except Exception:
                                pass





                            s_x = xgb_exp.status(); s_r = rf_exp.status(); s_a = arf_exp.status(); s_n = nn_exp.status(); s_m = meta.status()
                            tg_send("üß† ENS updated:\n" +
                                    _status_line("XGB", s_x) + "\n" +
                                    _status_line("RF ", s_r) + "\n" +
                                    _status_line("ARF", s_a) + "\n" +
                                    _status_line("NN ",  s_n) + "\n" +
                                    _status_line("META", s_m))
                    except Exception as _e:
                        print(f"[ens ] update error: {_e}")

                    
                    # –ø–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è outcome/pnl
                    try:
                        side_txt = "UP" if bool(b.get("bet_up", False)) else "DOWN"
                        status = "üèÜ WIN" if up_won or down_won else "‚Äî"
                        p_side = float(b.get("p_side", 0.0))
                        p_thr  = float(b.get("p_thr",  0.0))
                        p_thr_src = b.get("p_thr_src", "‚Äî")
                        r_hat  = float(b.get("r_hat",  0.0))
                        gb_hat = float(b.get("gb_hat", 0.0))
                        gc_hat = float(b.get("gc_hat", 0.0))
                        stake  = float(b.get("stake",  0.0))
                        delta15 = b.get("delta15", None)
                        delta_eff = float(b.get("delta_eff", 0.0))

                        notify_ev_decision(
                            title=f"{status} Settle",
                            epoch=epoch,
                            side_txt=side_txt,
                            p_side=p_side,
                            p_thr=p_thr,
                            p_thr_src=p_thr_src,
                            r_hat=r_hat,
                            gb_hat=gb_hat,
                            gc_hat=gc_hat,
                            stake=stake,
                            delta15=(delta15 if delta15 is not None else None),
                            extra_lines=[
                                f"outcome:   {'win' if (up_won or down_won) else 'draw'}",
                                f"pnl:       {pnl:+.6f}  (BNB)",
                            ],
                            delta_eff=delta_eff,
                        )
                    except Exception as e:
                        print(f"[tg ] notify settle failed: {e}")

                    # CSV-–ª–æ–≥
                    row = {
                        "settled_ts": int(time.time()),
                        "epoch": epoch,
                        "side": side,
                        "p_up":           _as_float(b.get("p_up")),
                        "p_meta_raw":     _as_float(b.get("p_meta_raw")),     # ‚Üê –î–û–ë–ê–í–ò–õ–ò
                        "p_meta2_raw":    _as_float(b.get("p_meta2_raw")),    # ‚Üê NEW
                        "p_blend":        _as_float(b.get("p_blend")),        # ‚Üê NEW
                        "blend_w":        _as_float(b.get("blend_w")),        # ‚Üê NEW
                        "calib_src":      str(b.get("calib_src", "")),
                        "p_thr_used":     _as_float(b.get("p_thr")),
                        "p_thr_src":      str(b.get("p_thr_src", "")),
                        "edge_at_entry":  _as_float(b.get("edge_at_entry")),
                        "stake":          _as_float(stake, 0.0),
                        "gas_bet_bnb":    _as_float(gas_bet_bnb, 0.0),
                        "gas_claim_bnb":  _as_float(gas_claim_bnb, 0.0),
                        "gas_price_bet_gwei":   (_as_float(b.get("gas_price_bet_wei"), 0.0) / 1e9),
                        "gas_price_claim_gwei": (_as_float(gas_price_claim_wei, 0.0) / 1e9),
                        "outcome": outcome,
                        "pnl": pnl,
                        "capital_before": capital_before,
                        "capital_after": capital,
                        "lock_ts": rd.lock_ts,
                        "close_ts": rd.close_ts,
                        "lock_price": rd.lock_price,
                        "close_price": rd.close_price,
                        "payout_ratio": rd.payout_ratio if rd.payout_ratio else float('nan'),
                        "up_won": bool(up_won),
                        "r_hat_used": float(b.get("r_hat", float('nan'))),              # ‚Üê –ù–û–í–û–ï
                        "r_hat_source": str(b.get("r_hat_source", "")),                 # ‚Üê –ù–û–í–û–ï
                        "r_hat_error_pct": float('nan')                                 # ‚Üê –∑–∞–ø–æ–ª–Ω–∏–º –Ω–∏–∂–µ
                    }
                    
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –æ—Ü–µ–Ω–∫–∏ rÃÇ
                    try:
                        if rd.payout_ratio and b.get("r_hat"):
                            r_actual = float(rd.payout_ratio)
                            r_pred = float(b["r_hat"])
                            if math.isfinite(r_actual) and math.isfinite(r_pred) and r_actual > 0:
                                error_pct = abs(r_actual - r_pred) / r_actual * 100.0
                                row["r_hat_error_pct"] = float(error_pct)
                    except Exception:
                        pass

                    capital = update_capital_atomic(capital_state, new_capital, now, row)

                    # --- Performance monitor: –ø—Ä–æ–∫–∏–Ω–µ–º —Å–¥–µ–ª–∫—É
                    try:
                        if perf is not None:
                            perf.on_trade_settled(row)
                    except Exception as e:
                        print(f"[perf] on_trade_settled failed: {e}")


                    # –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ REST

                    stats.reload()

                    # --- Performance monitor: –ø–æ—á–∞—Å–æ–≤–æ–π –æ—Ç—á—ë—Ç (–±–µ–∑ –¥—É–±–ª–µ–π)
                    try:
                        if perf is not None:
                            perf.maybe_hourly_report(now_ts=int(time.time()), tg_send_fn=tg_send)
                    except Exception as e:
                        print(f"[perf] hourly report failed: {e}")

                    # --- –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á—ë—Ç (–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–µ —á–∞—â–µ 1—Ä/—Å—É—Ç–∫–∏, –æ–∫–æ–ª–æ –ø–æ–ª—É–Ω–æ—á–∏ –ø–æ UTC) ---
                    # --- –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á—ë—Ç (–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–µ —á–∞—â–µ 1—Ä/—Å—É—Ç–∫–∏, –æ–∫–æ–ª–æ –ø–æ–ª—É–Ω–æ—á–∏ –ø–æ UTC) ---
                    # –ó–∞–ø—É—Å–∫ —Å–ª—É—à–∞—Ç–µ–ª—è /report (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –æ–¥–∏–Ω —Ä–∞–∑)
                    try:
                        if (TG_TOKEN and TG_CHAT_ID):
                            global _REPORT_THREAD
                            if (_REPORT_THREAD is None) or (not _REPORT_THREAD.is_alive()):
                                _REPORT_THREAD = start_report_listener(SESSION, TG_TOKEN, TG_CHAT_ID, CSV_PATH, tg_send)
                                print("[tg] /report listener started")
                        else:
                            print("[tg] /report listener disabled (no TG_TOKEN/TG_CHAT_ID)")
                    except Exception as e:
                        print(f"[tg] /report listener failed: {e}")



                    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å—É—Ç–æ—á–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ (–∫–∞–∫ –±—ã–ª–æ)
                    try:
                        try_send_daily(CSV_PATH, tg_send)  # —Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥/–≤—Ä–µ–º—è –≤–Ω—É—Ç—Ä–∏
                    except Exception as e:
                        print(f"[warn] daily_report failed: {e}")


                    # –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è –≤ 00:05 Europe/Berlin, –Ω–µ —á–∞—â–µ 1 —Ä–∞–∑–∞ –≤ –¥–µ–Ω—å
                    try:
                        tm = datetime.now(PROJ_TZ)  # —Ç—Ä–µ–±—É–µ—Ç—Å—è: from datetime import datetime
                        if tm.hour == 0 and tm.minute < 10 and _proj_mark_once(PROJ_STATE_PATH, tm.strftime("%Y-%m-%d")):
                            txt = try_send_projection(
                                CSV_PATH,
                                tg_send,
                                horizons=(30, 90, 365),
                                start_cap=capital,
                                threshold=35.0,
                                lookback_days=30,
                                n_paths=8000,
                                block_len=3,
                            )
                            if not txt:
                                print("[proj] send failed (tg_send returned falsy)")
                    except Exception as e:
                        print(f"[warn] projection failed: {e}")





                    rest.notify_trade_executed()
                    rest.update_from_stats(stats, cfg=rest_cfg)
                    rest.save("rest_state.json")



                    emo = "üü¢" if outcome == "win" else ("üü°" if outcome == "draw" else "üî¥")
                    send_round_snapshot(
                        prefix=f"{emo} <b>Settled</b> epoch={epoch}",
                        extra_lines=[
                            f"side=<b>{side}</b>, outcome=<b>{outcome}</b>, pnl={pnl:+.6f} BNB",
                            f"cap_after={capital:.6f} BNB, ratio={rd.payout_ratio if rd.payout_ratio else float('nan'):.3f}"
                        ]
                    )
                    stats_dict = compute_extended_stats_from_csv(CSV_PATH)
                    print_stats(stats_dict)
                    continue

                # —Ñ–æ—Ä—Å-—Å–µ—Ç—Ç–ª –ø–æ —Ç–∞–π–º–∞—É—Ç—É oracleCalled
                if now > rd.close_ts:
                    b["wait_polls"] = int(b.get("wait_polls", 0)) + 1
                    wp = b["wait_polls"]
                    if wp % WAIT_PRINT_EVERY == 0:
                        print(f"[wait] epoch={epoch} waiting oracleCalled (closed, not finalized) polls={wp}/{MAX_WAIT_POLLS}")

                    if wp >= MAX_WAIT_POLLS and b.get("placed"):
                        lock_price_est = rd.lock_price
                        if (not math.isfinite(lock_price_est)) or lock_price_est == 0:
                            lock_price_est = nearest_close_price_ms(SYMBOL, (rd.lock_ts - 1) * 1000)

                        close_price_est = nearest_close_price_ms(SYMBOL, rd.close_ts * 1000)
                        if lock_price_est is None or close_price_est is None:
                            print(f"[wait] epoch={epoch} forced settle postponed (no market price).")
                            continue

                        # —Ñ–æ—Ä—Å-—Å–µ—Ç—Ç–ª –ø–æ—Å–ª–µ —Ç–∞–π–º–∞—É—Ç–∞ –æ–∂–∏–¥–∞–Ω–∏—è oracleCalled
                        fallback_wei = 0
                        try:
                            fallback_wei = int(float(b.get("gas_price_bet_wei", 0)) or 0)
                        except Exception:
                            fallback_wei = 0

                        try:
                            gas_price_claim_wei = get_gas_price_wei(w3)
                            rpc_fail_streak = 0
                        except Exception as e:
                            print(f"[rpc ] gas_price (claim) failed: {e}")
                            rpc_fail_streak += 1
                            # –±–µ—Ä—ë–º —Ñ–æ–ª–±—ç–∫ –∏ –ù–ï –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                            gas_price_claim_wei = fallback_wei if fallback_wei > 0 else 3_000_000_000
                            if rpc_fail_streak >= RPC_FAIL_MAX:
                                try:
                                    w3 = connect_web3()
                                    c = get_prediction_contract(w3)
                                    rpc_fail_streak = 0
                                    print("[rpc ] reconnected")
                                except Exception as ee:
                                    print(f"[rpc ] reconnect failed: {ee}")
                        # –í–ê–ñ–ù–û: –±–µ–∑ continue ‚Äî –∏–¥—ë–º –¥–∞–ª—å—à–µ –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ –∏—Å—Ö–æ–¥–∞
                        # ... –¥–∞–ª–µ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ outcome/pnl –∏ send_round_snapshot("Forced settle", ...)


                        bet_up = bool(b.get("bet_up", False))
                        stake = float(b.get("stake", 0.0))
                        gas_bet_bnb = float(b.get("gas_bet_bnb", 0.0))

                        up_won = close_price_est > lock_price_est
                        down_won = close_price_est < lock_price_est
                        draw = close_price_est == lock_price_est

                        if NN_USE and logreg is not None and (not draw) and ("phi" in b):
                            try:
                                logreg.update(np.array(b["phi"], dtype=float), 1 if up_won else 0)
                                logreg.save()
                            except Exception:
                                pass

                        ratio_imp = implied_payout_ratio(bet_up, rd, TREASURY_FEE)
                        ratio_use = ratio_imp if (ratio_imp is not None and math.isfinite(ratio_imp) and ratio_imp > 1.0) else 1.90

                        capital_before = capital
                        gas_claim_bnb = GAS_USED_CLAIM * gas_price_claim_wei / 1e18

                        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–π –∫–∞–ø–∏—Ç–∞–ª –ë–ï–ó –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π capital
                        if draw:
                            new_capital = capital - (gas_bet_bnb + gas_claim_bnb)
                            pnl = -(gas_bet_bnb + gas_claim_bnb)
                            outcome = "draw"
                        else:
                            if (bet_up and up_won) or ((not bet_up) and down_won):
                                profit = stake * (ratio_use - 1.0)
                                new_capital = capital + profit - (gas_bet_bnb + gas_claim_bnb)
                                pnl = profit - (gas_bet_bnb + gas_claim_bnb)
                                outcome = "win"
                            else:
                                new_capital = capital - stake - gas_bet_bnb
                                pnl = -stake - gas_bet_bnb
                                outcome = "loss"

                        b.update(dict(
                            settled=True, outcome=outcome, pnl=pnl,
                            gas_price_claim_wei=gas_price_claim_wei, gas_claim_bnb=gas_claim_bnb,
                            capital_after=new_capital, payout_ratio=ratio_use, forced=True
                        ))
                        side = "UP" if bet_up else "DOWN"
                        print(f"[FORC] epoch={epoch} side={side} outcome={outcome} pnl={pnl:+.6f} cap={capital:.6f} "
                              f"ratio_imp={ratio_use:.3f} lock_est={lock_price_est:.4f} close_est={close_price_est:.4f}")

                        try:
                            if WF_USE and ("phi_wf" in b) and (not draw):
                                y_up = 1.0 if up_won else 0.0
                                wf.update(np.array(b["phi_wf"], dtype=float), y_up)
                                wf.save()
                                print(f"[wf  ] updated weights = {wf.w}")
                        except Exception:
                            pass

                        try:
                            ens_info = b.get("ens") or {}
                            x_ml = np.array(ens_info.get("x", []), dtype=float)
                            p_xgb = ens_info.get("p_xgb", None)
                            p_rf  = ens_info.get("p_rf", None)
                            p_arf = ens_info.get("p_arf", None)
                            p_nn  = ens_info.get("p_nn", None)
                            p_fin = ens_info.get("p_final", None)
                            p_base = ens_info.get("p_base", None)
                            used_flag = bool(ens_info.get("used", False))

                            reg_ctx = (ens_info.get("reg_ctx", {}) or {})
                            reg_ctx = dict(reg_ctx, epoch=int(epoch))

                            # ... –≤–Ω—É—Ç—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ settle
                            if not draw:
                                y_up_int = 1 if up_won else 0

                                # 1) –°–ù–ê–ß–ê–õ–ê ‚Äî –ú–ï–¢–ê. –í—Å–µ–≥–¥–∞ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞—Å–µ–ª–∏—Ç—å, –¥–∞–∂–µ –µ—Å–ª–∏ x_ml –ø—É—Å—Ç–æ–π –∏–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç—ã —É–ø–∞–¥—É—Ç.
                                try:
                                    meta.settle(
                                        p_xgb, p_rf, p_arf, p_nn,
                                        p_base=p_base,                 # –ú–ï–¢–ê —Å–∞–º–∞ —Ñ–æ—Ä—Å–∏—Ä—É–µ—Ç œÜ –ø—Ä–∏ None
                                        y_up=y_up_int,
                                        used_in_live=used_flag,
                                        p_final_used=p_fin,
                                        reg_ctx=reg_ctx
                                    )
                                except Exception as e:
                                    print(f"[ens ] meta.settle error: {e}")

                                # 2) –ü–û–¢–û–ú ‚Äî —ç–∫—Å–ø–µ—Ä—Ç—ã. –û—à–∏–±–∫–∏ –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç –ú–ï–¢–£.
                                try:
                                    if xgb_exp.enabled and x_ml.size > 0:
                                        xgb_exp.record_result(x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_xgb, reg_ctx=reg_ctx)
                                        xgb_exp.maybe_train(reg_ctx=reg_ctx)

                                    if rf_exp.enabled and x_ml.size > 0:
                                        rf_exp.record_result(x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_rf, reg_ctx=reg_ctx)
                                        rf_exp.maybe_train(reg_ctx=reg_ctx)

                                    if arf_exp.enabled and x_ml.size > 0:
                                        arf_exp.record_result(x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_arf, reg_ctx=reg_ctx)
                                        # –æ–±—É—á–µ–Ω–∏–µ ARF ‚Äî –≤–Ω—É—Ç—Ä–∏ record_result()

                                    if nn_exp.enabled and x_ml.size > 0:
                                        nn_exp.record_result(x_ml, y_up=y_up_int, used_in_live=used_flag, p_pred=p_nn, reg_ctx=reg_ctx)
                                        nn_exp.maybe_train(reg_ctx=reg_ctx)

                                except Exception as e:
                                    print(f"[ens ] experts update error: {e}")


                                try:
                                    LM = globals().get("_LM_META")
                                    if LM:
                                        LM.record_result(
                                            p_xgb,
                                            p_rf,
                                            p_arf,
                                            p_nn,
                                            p_base=p_base,
                                            y_up=y_up_int,
                                            reg_ctx=reg_ctx,
                                            used_in_live=used_flag
                                        )
                                except Exception:
                                    pass


                                # –£–ü–†–û–©–ï–ù–û: –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä
                                try:
                                    CM1 = globals().get("_CALIB_MGR")
                                    if CM1 and ("p_meta_raw" in b) and _is_finite_num(b["p_meta_raw"]):
                                        CM1.update(_as_float(b["p_meta_raw"]), int(y_up_int), int(time.time()))
                                except Exception:
                                    pass


                        except Exception as _e:
                            print(f"[ens ] forced-settle update error: {_e}")

                        row = {
                            "settled_ts": int(time.time()),
                            "epoch": epoch,
                            "side": side,
                            "p_up": float(b.get("p_up", float('nan'))),
                            "p_meta_raw": float(b.get("p_meta_raw", float('nan'))),   # ‚Üê –î–û–ë–ê–í–ò–õ–ò
                            "p_meta2_raw": float(b.get("p_meta2_raw", float('nan'))),  # ‚Üê NEW
                            "p_blend":     float(b.get("p_blend",     float('nan'))),  # ‚Üê NEW
                            "blend_w":     float(b.get("blend_w",     float('nan'))),  # ‚Üê NEW
                            "calib_src":  str(b.get("calib_src", "")), 
                            "p_thr_used": float(b.get("p_thr", float('nan'))),
                            "p_thr_src":  str(b.get("p_thr_src", "")),
                            "edge_at_entry": float(b.get("edge_at_entry", float('nan'))),                            
                            "stake": stake,
                            "gas_bet_bnb": gas_bet_bnb,
                            "gas_claim_bnb": gas_claim_bnb,
                            "gas_price_bet_gwei": float(b.get("gas_price_bet_wei", 0.0)) / 1e9,
                            "gas_price_claim_gwei": gas_price_claim_wei / 1e9,
                            "outcome": outcome,
                            "pnl": pnl,
                            "capital_before": capital_before,
                            "capital_after": capital,
                            "lock_ts": rd.lock_ts,
                            "close_ts": rd.close_ts,
                            "lock_price": lock_price_est if rd.lock_price == 0 else rd.lock_price,
                            "close_price": close_price_est,
                            "payout_ratio": ratio_use,
                            "payout_ratio": ratio_use,
                            "up_won": bool(up_won),
                            "r_hat_used": float(b.get("r_hat", float('nan'))),
                            "r_hat_source": str(b.get("r_hat_source", "")),
                            "r_hat_error_pct": float('nan')
                        }
                        
                        # –û—à–∏–±–∫–∞ –¥–ª—è forced settlement
                        try:
                            if ratio_use and b.get("r_hat"):
                                r_actual = float(ratio_use)
                                r_pred = float(b["r_hat"])
                                if math.isfinite(r_actual) and math.isfinite(r_pred) and r_actual > 0:
                                    error_pct = abs(r_actual - r_pred) / r_actual * 100.0
                                    row["r_hat_error_pct"] = float(error_pct)
                        except Exception:
                            pass

                        capital = update_capital_atomic(capital_state, new_capital, now, row)

                        # --- Performance monitor: –ø—Ä–æ–∫–∏–Ω–µ–º —Å–¥–µ–ª–∫—É
                        try:
                            if perf is not None:
                                perf.on_trade_settled(row)
                        except Exception as e:
                            print(f"[perf] on_trade_settled failed: {e}")


                        # –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ REST

                        stats.reload()

                        # --- Performance monitor: –ø–æ—á–∞—Å–æ–≤–æ–π –æ—Ç—á—ë—Ç (–±–µ–∑ –¥—É–±–ª–µ–π)
                        try:
                            if perf is not None:
                                perf.maybe_hourly_report(now_ts=int(time.time()), tg_send_fn=tg_send)
                        except Exception as e:
                            print(f"[perf] hourly report failed: {e}")

                        # --- –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á—ë—Ç (–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–µ —á–∞—â–µ 1—Ä/—Å—É—Ç–∫–∏, –æ–∫–æ–ª–æ –ø–æ–ª—É–Ω–æ—á–∏ –ø–æ UTC) ---
                        try:
                            try_send_daily(CSV_PATH, tg_send)  # —Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥/–≤—Ä–µ–º—è –≤–Ω—É—Ç—Ä–∏
                        except Exception as e:
                            print(f"[warn] daily_report failed: {e}")

                        try:
                            # —à–ª—ë–º —Ä–µ–∂–µ: –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞–º –≤ 00:05 UTC
                            tm = datetime.now(timezone.utc) 
                            if tm.weekday() == 0 and tm.hour == 0 and tm.minute < 10:
                                try_send_projection(CSV_PATH, tg_send,
                                                    horizons=(30, 90, 365),
                                                    start_cap=capital,  # –µ—Å–ª–∏ –∑–Ω–∞–µ—à—å —Ç–µ–∫—É—â–∏–π
                                                    threshold=35.0,
                                                    lookback_days=30,
                                                    n_paths=8000,
                                                    block_len=3)
                        except Exception as e:
                            print(f"[warn] projection failed: {e}")

                        rest.notify_trade_executed()
                        rest.update_from_stats(stats, cfg=rest_cfg)
                        rest.save("rest_state.json")



                        send_round_snapshot(
                            prefix=f"‚ö†Ô∏è <b>Forced settle</b> epoch={epoch}",
                            extra_lines=[
                                f"–ü—Ä–∏—á–∏–Ω–∞: oracleCalled –Ω–µ—Ç {wp} –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–æ–¥—Ä—è–¥.",
                                f"side=<b>{side}</b>, outcome=<b>{outcome}</b>, pnl={pnl:+.6f} BNB",
                                f"lock‚âà{(lock_price_est if rd.lock_price == 0 else rd.lock_price):.4f}, close‚âà{close_price_est:.4f}, ratio‚âà{ratio_use:.3f}"
                            ]
                        )

                        stats_dict = compute_extended_stats_from_csv(CSV_PATH)
                        print_stats(stats_dict)
                        continue

            _prune_bets(bets, keep_settled_last=500, keep_other_last=200)

            # –º—è–≥–∫–∏–π —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞ —Ä–∞–∑ –≤ ~10 –º–∏–Ω—É—Ç (—Å–Ω–∏–∂–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é)
            try:
                import gc
                if (now - _last_gc) >= 600:
                    gc.collect()
                    _last_gc = now
            except Exception:
                pass

            time.sleep(1.0)


        except KeyboardInterrupt:
            print("\n[stop] Ctrl+C")  # –Ω–µ –¥–µ—Ä–≥–∞–µ–º —Å–µ—Ç—å –∑–¥–µ—Å—å, –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º
            break
        except Exception as e:
            print(f"[warn] {type(e).__name__}: {e}")
            time.sleep(2.0)


def _normalize_existing_csvs():
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –æ–±–∞ —Ñ–∞–π–ª–∞ –∫ –Ω—É–∂–Ω–æ–π —Å—Ö–µ–º–µ"""
    for _p in (CSV_PATH, CSV_SHADOW_PATH):
        if os.path.exists(_p):
            try:
                # ‚úÖ –£–±—Ä–∞–ª–∏ dtype="string" - —á–∏—Ç–∞–µ–º —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–æ–≤
                raw = pd.read_csv(_p, encoding="utf-8-sig", keep_default_na=True)
                
                # ‚úÖ –°—Ä–∞–∑—É –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã NA –Ω–∞ np.nan
                raw = raw.fillna(np.nan)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
                for col in raw.select_dtypes(include=["object"]).columns:
                    raw[col] = raw[col].replace({
                        "<NA>": np.nan, "NaN": np.nan, "nan": np.nan, 
                        "None": np.nan, "": np.nan
                    })
                
                # –ú—è–≥–∫–æ –ø—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã –∫ —Ü–µ–ª–µ–≤–æ–π —Å—Ö–µ–º–µ
                _df = _coerce_csv_dtypes(raw)
                
                # –§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞—á–∏—Å—Ç–∫–∞ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                _df = _df.fillna(np.nan)
                
                _df.to_csv(_p, index=False, encoding="utf-8-sig")
            except Exception as e:
                print(f"[warn] CSV normalize failed for {_p}: {e!r}")



if __name__ == "__main__":
    ensure_csv_header(CSV_PATH)
    _normalize_existing_csvs()

    upgrade_csv_schema_if_needed(CSV_PATH)
    upgrade_csv_schema_if_needed(CSV_SHADOW_PATH)

    try:
        main_loop()
    except KeyboardInterrupt:
        print("‚ö†Ô∏è Bot stopped (KeyboardInterrupt).")
        try:
            tg_send("‚ö†Ô∏è Bot stopped (KeyboardInterrupt).", html=False)
        except Exception:
            pass
    except Exception as e:
        # –ø–∏—à–µ–º —Å—Ç–µ–∫ –≤ GGG/errors.log –∏ –¥–∞—ë–º –ø—Ä–æ—Ü–µ—Å—Å—É –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è —Å –∫–æ–¥–æ–º –æ—à–∏–±–∫–∏
        log_exception("Fatal error in main()")
        try:
            tg_send("üî¥ Bot crashed: —Å–º. GGG/errors.log", html=False)
        except Exception:
            pass
        raise


